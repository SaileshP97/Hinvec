{
  "dataset_revision": "8f95949846bb9e33c6aaf730ccfdb8fe6bcfb7a9",
  "task_name": "MultiHateClassification",
  "mteb_version": "1.36.26",
  "scores": {
    "test": [
      {
        "accuracy": 0.596,
        "f1": 0.544876,
        "f1_weighted": 0.596104,
        "ap": 0.340132,
        "ap_weighted": 0.340132,
        "scores_per_experiment": [
          {
            "accuracy": 0.65,
            "f1": 0.595863,
            "f1_weighted": 0.654437,
            "ap": 0.361109,
            "ap_weighted": 0.361109
          },
          {
            "accuracy": 0.559,
            "f1": 0.516964,
            "f1_weighted": 0.573392,
            "ap": 0.313165,
            "ap_weighted": 0.313165
          },
          {
            "accuracy": 0.645,
            "f1": 0.60191,
            "f1_weighted": 0.653775,
            "ap": 0.368017,
            "ap_weighted": 0.368017
          },
          {
            "accuracy": 0.443,
            "f1": 0.442875,
            "f1_weighted": 0.446184,
            "ap": 0.310024,
            "ap_weighted": 0.310024
          },
          {
            "accuracy": 0.693,
            "f1": 0.567288,
            "f1_weighted": 0.659648,
            "ap": 0.348475,
            "ap_weighted": 0.348475
          },
          {
            "accuracy": 0.681,
            "f1": 0.626162,
            "f1_weighted": 0.682861,
            "ap": 0.386375,
            "ap_weighted": 0.386375
          },
          {
            "accuracy": 0.635,
            "f1": 0.578899,
            "f1_weighted": 0.639765,
            "ap": 0.348224,
            "ap_weighted": 0.348224
          },
          {
            "accuracy": 0.588,
            "f1": 0.520162,
            "f1_weighted": 0.591608,
            "ap": 0.311544,
            "ap_weighted": 0.311544
          },
          {
            "accuracy": 0.606,
            "f1": 0.539504,
            "f1_weighted": 0.6088,
            "ap": 0.321961,
            "ap_weighted": 0.321961
          },
          {
            "accuracy": 0.46,
            "f1": 0.459135,
            "f1_weighted": 0.450567,
            "ap": 0.332425,
            "ap_weighted": 0.332425
          }
        ],
        "main_score": 0.596,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 7.030735969543457,
  "kg_co2_emissions": null
}