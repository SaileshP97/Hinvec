{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "task_name": "IN22ConvBitextMining",
  "mteb_version": "1.36.26",
  "scores": {
    "test": [
      {
        "precision": 4.3e-05,
        "recall": 0.001996,
        "f1": 8.1e-05,
        "accuracy": 0.001996,
        "main_score": 8.1e-05,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 3.5e-05,
        "recall": 0.001996,
        "f1": 6.7e-05,
        "accuracy": 0.001996,
        "main_score": 6.7e-05,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003781,
        "recall": 0.007984,
        "f1": 0.00407,
        "accuracy": 0.007984,
        "main_score": 0.00407,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.085506,
        "recall": 0.103792,
        "f1": 0.088331,
        "accuracy": 0.103792,
        "main_score": 0.088331,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.308831,
        "recall": 0.355289,
        "f1": 0.319635,
        "accuracy": 0.355289,
        "main_score": 0.319635,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.029418,
        "recall": 0.037259,
        "f1": 0.030626,
        "accuracy": 0.037259,
        "main_score": 0.030626,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 5.6e-05,
        "recall": 0.001331,
        "f1": 0.000103,
        "accuracy": 0.001331,
        "main_score": 0.000103,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000665,
        "f1": 1e-06,
        "accuracy": 0.000665,
        "main_score": 1e-06,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 2.3e-05,
        "recall": 0.001996,
        "f1": 4.4e-05,
        "accuracy": 0.001996,
        "main_score": 4.4e-05,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.017159,
        "recall": 0.031936,
        "f1": 0.019169,
        "accuracy": 0.031936,
        "main_score": 0.019169,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.145642,
        "recall": 0.202262,
        "f1": 0.157625,
        "accuracy": 0.202262,
        "main_score": 0.157625,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.044839,
        "recall": 0.053892,
        "f1": 0.046147,
        "accuracy": 0.053892,
        "main_score": 0.046147,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.040016,
        "recall": 0.061876,
        "f1": 0.043609,
        "accuracy": 0.061876,
        "main_score": 0.043609,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 3e-05,
        "recall": 0.001331,
        "f1": 5.8e-05,
        "accuracy": 0.001331,
        "main_score": 5.8e-05,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001331,
        "f1": 5e-06,
        "accuracy": 0.001331,
        "main_score": 5e-06,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 9.6e-05,
        "recall": 0.001331,
        "f1": 0.000169,
        "accuracy": 0.001331,
        "main_score": 0.000169,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.108637,
        "recall": 0.162342,
        "f1": 0.118145,
        "accuracy": 0.162342,
        "main_score": 0.118145,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.000215,
        "recall": 0.002661,
        "f1": 0.000359,
        "accuracy": 0.002661,
        "main_score": 0.000359,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.04598,
        "recall": 0.075848,
        "f1": 0.051397,
        "accuracy": 0.075848,
        "main_score": 0.051397,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.076399,
        "recall": 0.112442,
        "f1": 0.083065,
        "accuracy": 0.112442,
        "main_score": 0.083065,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 6.2e-05,
        "recall": 0.001331,
        "f1": 0.000118,
        "accuracy": 0.001331,
        "main_score": 0.000118,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.000464,
        "recall": 0.003992,
        "f1": 0.000685,
        "accuracy": 0.003992,
        "main_score": 0.000685,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.025866,
        "recall": 0.041916,
        "f1": 0.028614,
        "accuracy": 0.041916,
        "main_score": 0.028614,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000665,
        "f1": 3e-06,
        "accuracy": 0.000665,
        "main_score": 3e-06,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.107894,
        "recall": 0.149701,
        "f1": 0.115266,
        "accuracy": 0.149701,
        "main_score": 0.115266,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.000375,
        "recall": 0.001996,
        "f1": 0.000523,
        "accuracy": 0.001996,
        "main_score": 0.000523,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000342,
        "recall": 0.001331,
        "f1": 0.000461,
        "accuracy": 0.001331,
        "main_score": 0.000461,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000665,
        "f1": 1e-06,
        "accuracy": 0.000665,
        "main_score": 1e-06,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 1e-05,
        "recall": 0.001331,
        "f1": 1.9e-05,
        "accuracy": 0.001331,
        "main_score": 1.9e-05,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.1e-05,
        "recall": 0.001331,
        "f1": 2.1e-05,
        "accuracy": 0.001331,
        "main_score": 2.1e-05,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.118118,
        "recall": 0.139055,
        "f1": 0.12186,
        "accuracy": 0.139055,
        "main_score": 0.12186,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000179,
        "recall": 0.001996,
        "f1": 0.000291,
        "accuracy": 0.001996,
        "main_score": 0.000291,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.049524,
        "recall": 0.062542,
        "f1": 0.051771,
        "accuracy": 0.062542,
        "main_score": 0.051771,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 3.8e-05,
        "recall": 0.001996,
        "f1": 7.2e-05,
        "accuracy": 0.001996,
        "main_score": 7.2e-05,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.067208,
        "recall": 0.081836,
        "f1": 0.070047,
        "accuracy": 0.081836,
        "main_score": 0.070047,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 4.8e-05,
        "recall": 0.001331,
        "f1": 9e-05,
        "accuracy": 0.001331,
        "main_score": 9e-05,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 5.6e-05,
        "recall": 0.001996,
        "f1": 0.000106,
        "accuracy": 0.001996,
        "main_score": 0.000106,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.024794,
        "recall": 0.039255,
        "f1": 0.026954,
        "accuracy": 0.039255,
        "main_score": 0.026954,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 5.2e-05,
        "recall": 0.001331,
        "f1": 9.6e-05,
        "accuracy": 0.001331,
        "main_score": 9.6e-05,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.06064,
        "recall": 0.076514,
        "f1": 0.063038,
        "accuracy": 0.076514,
        "main_score": 0.063038,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 5.9e-05,
        "recall": 0.001331,
        "f1": 0.000111,
        "accuracy": 0.001331,
        "main_score": 0.000111,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 6.9e-05,
        "recall": 0.001996,
        "f1": 0.00013,
        "accuracy": 0.001996,
        "main_score": 0.00013,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000176,
        "recall": 0.001996,
        "f1": 0.000285,
        "accuracy": 0.001996,
        "main_score": 0.000285,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 155.7704815864563,
  "kg_co2_emissions": null
}