{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "1.36.26",
  "scores": {
    "test": [
      {
        "precision": 0.000178,
        "recall": 0.004883,
        "f1": 0.000325,
        "accuracy": 0.004883,
        "main_score": 0.000325,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000256,
        "recall": 0.001953,
        "f1": 0.000415,
        "accuracy": 0.001953,
        "main_score": 0.000415,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.111599,
        "recall": 0.136719,
        "f1": 0.116803,
        "accuracy": 0.136719,
        "main_score": 0.116803,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.262046,
        "recall": 0.318359,
        "f1": 0.275431,
        "accuracy": 0.318359,
        "main_score": 0.275431,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.009986,
        "recall": 0.03418,
        "f1": 0.013069,
        "accuracy": 0.03418,
        "main_score": 0.013069,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.187826,
        "recall": 0.236328,
        "f1": 0.19854,
        "accuracy": 0.236328,
        "main_score": 0.19854,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.010123,
        "recall": 0.016602,
        "f1": 0.010806,
        "accuracy": 0.016602,
        "main_score": 0.010806,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 8.5e-05,
        "recall": 0.001953,
        "f1": 0.000163,
        "accuracy": 0.001953,
        "main_score": 0.000163,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 5.1e-05,
        "recall": 0.000977,
        "f1": 9.8e-05,
        "accuracy": 0.000977,
        "main_score": 9.8e-05,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.111267,
        "recall": 0.158203,
        "f1": 0.121097,
        "accuracy": 0.158203,
        "main_score": 0.121097,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.272099,
        "recall": 0.334961,
        "f1": 0.287006,
        "accuracy": 0.334961,
        "main_score": 0.287006,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002052,
        "recall": 0.004883,
        "f1": 0.002458,
        "accuracy": 0.004883,
        "main_score": 0.002458,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.211701,
        "recall": 0.259766,
        "f1": 0.224085,
        "accuracy": 0.259766,
        "main_score": 0.224085,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.014773,
        "recall": 0.032227,
        "f1": 0.017471,
        "accuracy": 0.032227,
        "main_score": 0.017471,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000246,
        "recall": 0.001953,
        "f1": 0.000394,
        "accuracy": 0.001953,
        "main_score": 0.000394,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.026723,
        "recall": 0.044922,
        "f1": 0.029742,
        "accuracy": 0.044922,
        "main_score": 0.029742,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.294652,
        "recall": 0.375,
        "f1": 0.315618,
        "accuracy": 0.375,
        "main_score": 0.315618,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.054981,
        "recall": 0.083984,
        "f1": 0.060871,
        "accuracy": 0.083984,
        "main_score": 0.060871,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.117015,
        "recall": 0.163086,
        "f1": 0.127381,
        "accuracy": 0.163086,
        "main_score": 0.127381,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 9.8e-05,
        "recall": 0.00293,
        "f1": 0.000185,
        "accuracy": 0.00293,
        "main_score": 0.000185,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.173598,
        "recall": 0.250977,
        "f1": 0.193572,
        "accuracy": 0.250977,
        "main_score": 0.193572,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 9.7e-05,
        "recall": 0.00293,
        "f1": 0.000186,
        "accuracy": 0.00293,
        "main_score": 0.000186,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.082987,
        "recall": 0.102539,
        "f1": 0.087743,
        "accuracy": 0.102539,
        "main_score": 0.087743,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.046673,
        "recall": 0.082031,
        "f1": 0.053651,
        "accuracy": 0.082031,
        "main_score": 0.053651,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.196672,
        "recall": 0.24707,
        "f1": 0.207908,
        "accuracy": 0.24707,
        "main_score": 0.207908,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.049973,
        "recall": 0.073242,
        "f1": 0.054998,
        "accuracy": 0.073242,
        "main_score": 0.054998,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.071349,
        "recall": 0.09375,
        "f1": 0.076034,
        "accuracy": 0.09375,
        "main_score": 0.076034,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.039511,
        "recall": 0.058594,
        "f1": 0.042775,
        "accuracy": 0.058594,
        "main_score": 0.042775,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.000403,
        "recall": 0.005859,
        "f1": 0.00071,
        "accuracy": 0.005859,
        "main_score": 0.00071,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.033131,
        "recall": 0.042969,
        "f1": 0.034807,
        "accuracy": 0.042969,
        "main_score": 0.034807,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.243314,
        "recall": 0.331055,
        "f1": 0.264154,
        "accuracy": 0.331055,
        "main_score": 0.264154,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.019683,
        "recall": 0.041992,
        "f1": 0.023683,
        "accuracy": 0.041992,
        "main_score": 0.023683,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.083879,
        "recall": 0.121094,
        "f1": 0.091636,
        "accuracy": 0.121094,
        "main_score": 0.091636,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 9.3e-05,
        "recall": 0.003906,
        "f1": 0.000173,
        "accuracy": 0.003906,
        "main_score": 0.000173,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.137094,
        "recall": 0.197266,
        "f1": 0.15226,
        "accuracy": 0.197266,
        "main_score": 0.15226,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.3e-05,
        "recall": 0.00293,
        "f1": 2.6e-05,
        "accuracy": 0.00293,
        "main_score": 2.6e-05,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.042386,
        "recall": 0.075195,
        "f1": 0.047644,
        "accuracy": 0.075195,
        "main_score": 0.047644,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.043022,
        "recall": 0.073242,
        "f1": 0.048911,
        "accuracy": 0.073242,
        "main_score": 0.048911,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001058,
        "recall": 0.004883,
        "f1": 0.001131,
        "accuracy": 0.004883,
        "main_score": 0.001131,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.18327,
        "recall": 0.217773,
        "f1": 0.191536,
        "accuracy": 0.217773,
        "main_score": 0.191536,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.042544,
        "recall": 0.0625,
        "f1": 0.046625,
        "accuracy": 0.0625,
        "main_score": 0.046625,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.027345,
        "recall": 0.054688,
        "f1": 0.032041,
        "accuracy": 0.054688,
        "main_score": 0.032041,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.037415,
        "recall": 0.046875,
        "f1": 0.039125,
        "accuracy": 0.046875,
        "main_score": 0.039125,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 5.4623682498931885,
  "kg_co2_emissions": null
}