{
  "dataset_revision": "8f95949846bb9e33c6aaf730ccfdb8fe6bcfb7a9",
  "task_name": "MultiHateClassification",
  "mteb_version": "1.36.26",
  "scores": {
    "test": [
      {
        "accuracy": 0.5497,
        "f1": 0.521191,
        "f1_weighted": 0.563205,
        "ap": 0.324765,
        "ap_weighted": 0.324765,
        "scores_per_experiment": [
          {
            "accuracy": 0.537,
            "f1": 0.514561,
            "f1_weighted": 0.555891,
            "ap": 0.318704,
            "ap_weighted": 0.318704
          },
          {
            "accuracy": 0.452,
            "f1": 0.451208,
            "f1_weighted": 0.459466,
            "ap": 0.309976,
            "ap_weighted": 0.309976
          },
          {
            "accuracy": 0.559,
            "f1": 0.522921,
            "f1_weighted": 0.574875,
            "ap": 0.317844,
            "ap_weighted": 0.317844
          },
          {
            "accuracy": 0.531,
            "f1": 0.520057,
            "f1_weighted": 0.548755,
            "ap": 0.330531,
            "ap_weighted": 0.330531
          },
          {
            "accuracy": 0.522,
            "f1": 0.497221,
            "f1_weighted": 0.541421,
            "ap": 0.30852,
            "ap_weighted": 0.30852
          },
          {
            "accuracy": 0.566,
            "f1": 0.553084,
            "f1_weighted": 0.583171,
            "ap": 0.349861,
            "ap_weighted": 0.349861
          },
          {
            "accuracy": 0.624,
            "f1": 0.549789,
            "f1_weighted": 0.622172,
            "ap": 0.32773,
            "ap_weighted": 0.32773
          },
          {
            "accuracy": 0.526,
            "f1": 0.505836,
            "f1_weighted": 0.545365,
            "ap": 0.315203,
            "ap_weighted": 0.315203
          },
          {
            "accuracy": 0.641,
            "f1": 0.579286,
            "f1_weighted": 0.643095,
            "ap": 0.347929,
            "ap_weighted": 0.347929
          },
          {
            "accuracy": 0.539,
            "f1": 0.517943,
            "f1_weighted": 0.55784,
            "ap": 0.321354,
            "ap_weighted": 0.321354
          }
        ],
        "main_score": 0.5497,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 5.290190696716309,
  "kg_co2_emissions": null
}