{
  "dataset_revision": "d522bb117c32f5e0207344f69f7075fc9941168b",
  "task_name": "TweetSentimentClassification",
  "mteb_version": "1.38.8",
  "scores": {
    "test": [
      {
        "accuracy": 0.360547,
        "f1": 0.352331,
        "f1_weighted": 0.352364,
        "scores_per_experiment": [
          {
            "accuracy": 0.289062,
            "f1": 0.277616,
            "f1_weighted": 0.277326
          },
          {
            "accuracy": 0.386719,
            "f1": 0.383065,
            "f1_weighted": 0.383218
          },
          {
            "accuracy": 0.320312,
            "f1": 0.318096,
            "f1_weighted": 0.318223
          },
          {
            "accuracy": 0.410156,
            "f1": 0.407734,
            "f1_weighted": 0.407662
          },
          {
            "accuracy": 0.394531,
            "f1": 0.391305,
            "f1_weighted": 0.391399
          },
          {
            "accuracy": 0.300781,
            "f1": 0.285187,
            "f1_weighted": 0.285202
          },
          {
            "accuracy": 0.292969,
            "f1": 0.280262,
            "f1_weighted": 0.280057
          },
          {
            "accuracy": 0.351562,
            "f1": 0.329593,
            "f1_weighted": 0.330018
          },
          {
            "accuracy": 0.46875,
            "f1": 0.471804,
            "f1_weighted": 0.471684
          },
          {
            "accuracy": 0.390625,
            "f1": 0.378643,
            "f1_weighted": 0.378853
          }
        ],
        "main_score": 0.360547,
        "hf_subset": "hindi",
        "languages": [
          "hin-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 7.240355491638184,
  "kg_co2_emissions": null
}