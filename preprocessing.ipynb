{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saileshpanda/miniconda3/envs/AI/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "import json\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LingoIITGN/ganga-2-1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"token_per_language.json\", 'r') as f:\n",
    "    token_per_language = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitext Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: CrossSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_hindi = []\n",
    "with open(\"./Data/Bitext Mining/CrossSum/english-hindi_CrossSum/english-hindi_test.jsonl\", \"r\") as f:\n",
    "    for sample in f:\n",
    "        english_hindi.append(json.loads(sample))\n",
    "\n",
    "hindi_english = []\n",
    "with open(\"./Data/Bitext Mining/CrossSum/hindi-english_CrossSum/hindi-english_test.jsonl\", \"r\") as f:\n",
    "    for sample in f:\n",
    "        hindi_english.append(json.loads(sample))\n",
    "\n",
    "hindi_hindi = []\n",
    "with open(\"./Data/Bitext Mining/CrossSum/hindi-hindi_CrossSum/hindi-hindi_test.jsonl\", \"r\") as f:\n",
    "    for sample in f:\n",
    "        hindi_hindi.append(json.loads(sample))\n",
    "\n",
    "english_english = []\n",
    "with open(\"./Data/Bitext Mining/CrossSum/english-english_CrossSum/english-english_test.jsonl\", \"r\") as f:\n",
    "    for sample in f:\n",
    "        english_english.append(json.loads(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "\n",
    "for sample in english_hindi:\n",
    "    eng = tokenizer.encode(sample['text'])\n",
    "    hin = tokenizer.encode(sample['summary'])\n",
    "\n",
    "    total_english_tokens+= len(eng)\n",
    "    total_hindi_tokens+= len(hin)\n",
    "\n",
    "token_per_language['english_hindi_crosssum'] = {'Hindi': total_hindi_tokens,\n",
    "                                                'English': total_english_tokens,\n",
    "                                                'Romanised_Hindi': 0}\n",
    "\n",
    "total_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in hindi_english:\n",
    "    hin = tokenizer.encode(sample['text'])\n",
    "    eng = tokenizer.encode(sample['summary'])\n",
    "\n",
    "    total_english_tokens+= len(eng)\n",
    "    total_hindi_tokens+= len(hin)\n",
    "\n",
    "token_per_language['hindi_english_crosssum'] = {'Hindi': total_hindi_tokens,\n",
    "                                                'English': total_english_tokens,\n",
    "                                                'Romanised_Hindi': 0}\n",
    "\n",
    "total_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in hindi_hindi:\n",
    "    hin_text = tokenizer.encode(sample['text'])\n",
    "    hin = tokenizer.encode(sample['summary'])\n",
    "\n",
    "    total_hindi_tokens+= len(hin_text)\n",
    "    total_hindi_tokens+= len(hin)\n",
    "\n",
    "token_per_language['hindi_hindi_crosssum'] = {'Hindi': total_hindi_tokens,\n",
    "                                                'English': 0,\n",
    "                                                'Romanised_Hindi': 0}\n",
    "\n",
    "total_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in english_english:\n",
    "    english_text = tokenizer.encode(sample['text'])\n",
    "    english = tokenizer.encode(sample['summary'])\n",
    "\n",
    "    total_english_tokens+= len(english_text)\n",
    "    total_english_tokens+= len(english)\n",
    "\n",
    "token_per_language['english_english_crosssum'] = {'Hindi': 0,\n",
    "                                                'English': total_english_tokens,\n",
    "                                                'Romanised_Hindi': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_url = []\n",
    "english_url = []\n",
    "\n",
    "hindi_url.extend([sample['target_url'] for sample in english_hindi])\n",
    "hindi_url.extend([sample['target_url'] for sample in hindi_hindi])\n",
    "hindi_url.extend([sample['source_url'] for sample in hindi_hindi])\n",
    "hindi_url.extend([sample['source_url'] for sample in hindi_english])\n",
    "\n",
    "english_url.extend([sample['source_url'] for sample in english_hindi])\n",
    "english_url.extend([sample['target_url'] for sample in english_english])\n",
    "english_url.extend([sample['source_url'] for sample in english_english])\n",
    "english_url.extend([sample['target_url'] for sample in hindi_english])\n",
    "\n",
    "hindi_url = set(hindi_url)\n",
    "english_url = set(english_url)\n",
    "\n",
    "hindi_url_dict = {url: f\"hi_{idx}\" for idx, url in enumerate(hindi_url)}\n",
    "english_url_dict = {url: f\"en_{idx}\" for idx, url in enumerate(english_url)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n",
      "469\n",
      "8571\n",
      "32507\n"
     ]
    }
   ],
   "source": [
    "print(len(english_hindi))\n",
    "print(len(hindi_english))\n",
    "print(len(hindi_hindi))\n",
    "print(len(english_english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_url': 'https://www.bbc.com/news/uk-england-cornwall-54689463',\n",
       " 'target_url': 'https://www.bbc.com/news/uk-england-cornwall-54689463',\n",
       " 'text': 'Recently, six of the metre-wide, heavy metal mines have been caught off Looe in Cornwall. Fisherman Ivan Toms said the mines are resulting in lost fishing time and are \"polluting the sea\". The Royal Navy says warnings were issued when the mines were placed on the seabed and it will review the compensation claims. Mr Toms said he lost a \"whole day fishing\" when he and his son came across two mines on Friday night. His son cut the mines free from the trawl and narrowly missed being crushed as it crashed on to the deck, he told the BBC. \"It\\'s not just us, the other boats are catching them.\" Mr Toms said fishermen have hauled up six mines in the last few weeks. Despite being inert and not containing any explosives, the mines can cause damage to the boats at sea. Mr Toms wants compensation for the damage to his boat and fishing gear and for the Royal Navy to use another area for training, away from winter fishing grounds. There is a telephone number on the mines for finders to ring and Mr Toms says he has called it several times. A Royal Navy spokesperson said: \"A number of dummy mines containing no explosives were laid for a recent trial, and mariners were informed via local notices and warnings.\"',\n",
       " 'summary': 'Fishermen are calling on the Royal Navy for help after dummy mines have damaged their boats and nets.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_english[317]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosssum_hindi_hindi = []\n",
    "summary_instruction = \"निर्देश: दिए गए पाठ के लिए सबसे प्रासंगिक सारांश प्राप्त करें। पाठ:\"\n",
    "query_instruction = \"निर्देश: किसी दिए गए सारांश के लिए सबसे प्रासंगिक पैराग्राफ़ प्राप्त करें। सारांश: \"\n",
    "\n",
    "for idx, sample in enumerate(hindi_hindi):\n",
    "\n",
    "    if idx%2==0:\n",
    "        data = {'id': f\"crosssum_hindi_hindi_{hindi_url_dict[sample['target_url']]}\",\n",
    "                'source': summary_instruction + sample['text'],\n",
    "                'target': sample['summary']}\n",
    "    else:\n",
    "        data = {'id': f\"crosssum_hindi_hindi_{hindi_url_dict[sample['source_url']]}\",\n",
    "                'source': query_instruction + sample['summary'],\n",
    "                'target': sample['text']}\n",
    "\n",
    "\n",
    "    crosssum_hindi_hindi.append(data)\n",
    "\n",
    "with open(\"Processed_data/crosssum_hindi_hindi_test.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for sample in crosssum_hindi_hindi:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_url': 'https://www.bbc.com/hindi/international-43204196',\n",
       " 'target_url': 'https://www.bbc.com/news/world-middle-east-43205593',\n",
       " 'text': 'जिन अधिकारियों को बर्खास्त किया गया है उनमें वायुसेना और थल सेना के आला अधिकारी शामिल हैं. इसके अलावा कई उप-मंत्रियों की भी नियुक्तियां की गई हैं. इन नए नामों में तमादुर बिंत यूसुफ़ अल-रमाह नाम की महिला उप-मंत्री भी शामिल हैं. सऊदी क्राउन प्रिंस मोहम्मद बिन सलमान सऊदी अरब में किसी महिला का उप-मंत्री बनना आम बात नहीं है. ये फ़ैसला ऐसे वक्त आया है जब यमन में सऊदी नेतृत्व में गठबंधन सेना की विद्रोहियों के साथ लड़ाई के लगभग तीन साल पूरे होने वाले हैं. यमन में सऊदी हस्तक्षेप के कारण हूथी विद्रोही देश के दक्षिण की तरफ सीमित हो गए हैं, लेकिन अभी भी वो राजधानी सना और कई इलाकों में मज़बूती से डटे हुए हैं. लगभग तीन सालों से लड़ रही सऊदी सेना का सीधा असर देश की अर्थव्यवस्था पर अतिरिक्त बोझ की शक्ल में पड़ा है. साथ ही हूथी विद्रोहियों ने देश की राजधानी रियाद पर मिसाइल दाग़ने की धमकी दी है. (बीबीसी हिन्दी के एंड्रॉएड ऐप के लिए आप यहां क्लिक कर सकते हैं. आप हमें फ़ेसबुक और ट्विटर पर फ़ॉलो भी कर सकते हैं.)',\n",
       " 'summary': 'Saudi Arabia has sacked its top military commanders, including the chief of staff, in a series of late-night royal decrees.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_english[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosssum_hindi_english = []\n",
    "\n",
    "summary_instruction = \"निर्देश: दिए गए पाठ के लिए सबसे प्रासंगिक सारांश प्राप्त करें। पाठ:\"\n",
    "query_instruction = \"Instructions: Retrieve the most relevant paragraph for a given summary. Summary: \"\n",
    "\n",
    "for idx, sample in enumerate(hindi_english):\n",
    "\n",
    "    if idx%2==0:\n",
    "        data = {'id': f\"crosssum_hindi_english_{english_url_dict[sample['target_url']]}\",\n",
    "                'source': summary_instruction + sample['text'],\n",
    "                'target': sample['summary']}\n",
    "    else:\n",
    "        data = {'id': f\"crosssum_hindi_english_{hindi_url_dict[sample['source_url']]}\",\n",
    "                'source': query_instruction + sample['summary'],\n",
    "                'target': sample['text']}\n",
    "\n",
    "\n",
    "    crosssum_hindi_english.append(data)\n",
    "\n",
    "with open(f\"Processed_data/crosssum_hindi_english_test.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for sample in crosssum_hindi_english:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_url': 'https://www.bbc.com/news/science-environment-51019798',\n",
       " 'target_url': 'https://www.bbc.com/hindi/science-51048786',\n",
       " 'text': 'By Roger HarrabinBBC environment analyst The protein is produced from soil bacteria fed on hydrogen split from water by electricity. The researchers say if the electricity comes from solar and wind power, the food can be grown with near-zero greenhouse gas emissions. If their dreams are realised, it could help the world tackle many of the problems associated with farming. When I visited Solar Foods\\' pilot plant on the outskirts of Helsinki last year the researchers were raising funds for expansion. Now they say they have attracted 5.5m euros of investment, and they predict – depending on the price of electricity – that their costs will roughly match those for soya production by the end of the decade - perhaps even by 2025. Lacking in taste? I ate a few grains of the precious protein flour - called Solein - and tasted nothing, which is what the scientists have planned. They want it to be a neutral additive to all sorts of foods. It could mimic palm oil by reinforcing pies, ice cream, biscuits, pasta, noodles, sauces or bread. The inventors say it can be used as a medium for growing cultured meat or fish. It could also nourish cattle to save them eating soya raised on rainforest land. Even if things go according to plan – which, of course, they may not – it will be many years before the protein production is scaled up to meet global demand. But this is one of many projects looking towards a future of synthesised food. The firm’s CEO is Pasi Vainikka, who studied at Cranfield University in the UK and is now adjunct professor at Lappeenranta University. Space age ideas He told me the ideas behind the technology were originally developed for the space industry in the 1960s. He admits his demonstrator plant is running some months behind time but says it will be ready by 2022. A full investment decision will come in 2023, and if all goes according to plan, the first factory will appear in 2025. He said: “We are doing pretty well so far. Once we scale the factory from the first one by adding reactors (to ferment protein) and take into account the amazing improvements in other clean technologies like wind and solar power, we think we can compete with soya possibly as early as 2025.” To make Solein, water is \"split\", using electrolysis to make hydrogen. The hydrogen, carbon dioxide from the air and minerals are fed to bacteria, which then produce the protein. A key determinant, he said, would be the price of electricity. The firm anticipates that as more renewables come on-stream, the cost will fall. The progress of this extraordinary technology has been hailed by the environmental campaigner George Monbiot, who has made a TV documentary, Apocalypse Cow, broadcast on Channel 4 in the UK at 22:00 GMT on Wednesday. Hope for the future? Monbiot is generally pessimistic about the future of the planet, but says Solar Foods has given him hope. He said: “Food production is ripping the living world apart. Fishing and farming are, by a long way, the greatest cause of extinction and loss of the diversity and abundance of wildlife. Farming is a major cause of climate breakdown. “But just as hope appeared to be evaporating, ‘farmfree food’ creates astonishing possibilities to save both people and planet. “By temporarily shifting towards a plant-based diet, we can help buy the time to save species and places. “But farmfree food offers hope where hope was missing. We will soon be able to feed the world without devouring it.” Research by the think tank RethinkX, which forecasts the implications of technology-driven disruption of many kinds, suggests that proteins from precision fermentation will be around 10 times cheaper than animal protein by 2035. It forecasts the result will be the near-complete collapse of the livestock industry - although critics will complain that this doesn’t take into account the ability of meat producers to harness the novel proteins to feed their own stock . A consortium of leading scientific research and academic institutions has been formed to identify innovative solutions to tackle climate change linked to the agri-food sector. A paper last year concluded that microbial protein was several times more efficient than soya in terms of land use, and required just a tenth as much water. Another factor, though, will be cultural. Many people will still want to eat lamb chops that look like lamb chops. Professor Leon Terry from Cranfield University told BBC News there was growing interest from investors in novel foods. “There is increased momentum and investment round synthetic foods,” he said. But he asked: \"Is there really an appetite for their consumption?” Follow Roger on Twitter.',\n",
       " 'summary': 'फ़िनलैंड के वैज्ञानिक हवा से प्रोटीन बना रहे हैं. उनका दावा है कि इस दशक में ये सोयाबीन के दामों को टक्कर देगा.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_hindi[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosssum_english_hindi = []\n",
    "\n",
    "summary_instruction = \"Instructions: Retrieve the most relevant summary for the given paragraph. Text: \"\n",
    "query_instruction = \"निर्देश: किसी दिए गए सारांश के लिए सबसे प्रासंगिक पैराग्राफ़ प्राप्त करें। सारांश: \"\n",
    "\n",
    "for idx, sample in enumerate(english_hindi):\n",
    "\n",
    "    if idx%2==0:\n",
    "        data = {'id': f\"crosssum_english_hindi_{hindi_url_dict[sample['target_url']]}\",\n",
    "                'source': summary_instruction + sample['text'],\n",
    "                'target': sample['summary']}\n",
    "    else:\n",
    "        data = {'id': f\"crosssum_english_hindi_{english_url_dict[sample['source_url']]}\",\n",
    "                'source': query_instruction + sample['summary'],\n",
    "                'target': sample['text']}\n",
    "\n",
    "\n",
    "    crosssum_english_hindi.append(data)\n",
    "\n",
    "with open(f\"Processed_data/crosssum_english_hindi_test.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for sample in crosssum_english_hindi:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English article length: 892.2878464818764\n",
      "Hindi summary length: 33.330490405117274\n",
      "Hindi article length: 604.6759061833689\n",
      "English summary length: 35.498933901918974\n"
     ]
    }
   ],
   "source": [
    "length = np.array([len(tokenizer.encode(sample['text'])) for sample in english_hindi])\n",
    "print(f\"English article length: {length.mean()}\")\n",
    "length = np.array([len(tokenizer.encode(sample['summary'])) for sample in english_hindi])\n",
    "print(f\"Hindi summary length: {length.mean()}\")\n",
    "length = np.array([len(tokenizer.encode(sample['text'])) for sample in hindi_english])\n",
    "print(f\"Hindi article length: {length.mean()}\")\n",
    "length = np.array([len(tokenizer.encode(sample['summary'])) for sample in hindi_english])\n",
    "print(f\"English summary length: {length.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosssum_english_english = []\n",
    "summary_instruction = \"Instructions: Retrieve the most relevant summary from a set of options for the given paragraph. Text: \"\n",
    "query_instruction = \"Instructions: Retrieve the most relevant paragraph from a set of options for a given summary. Summary: \"\n",
    "\n",
    "for idx, sample in enumerate(english_english):\n",
    "\n",
    "    if idx%2==0:\n",
    "        data = {'id': f\"crosssum_english_english_{english_url_dict[sample['target_url']]}\",\n",
    "                'source': summary_instruction + sample['text'],\n",
    "                'target': sample['summary']}\n",
    "    else:\n",
    "        data = {'id': f\"crosssum_english_english_{english_url_dict[sample['source_url']]}\",\n",
    "                'source': query_instruction + sample['summary'],\n",
    "                'target': sample['text']}\n",
    "\n",
    "\n",
    "    crosssum_english_english.append(data)\n",
    "\n",
    "with open(\"Processed_data/crosssum_english_english_test.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for sample in crosssum_english_english:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Flores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Data/Bitext Mining/Flores/flores_hi_en_test.json\", 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'जैसे-जैसे ग्रीक का ज्ञान घटता गया, पश्चिम ने खुद को अपनी ग्रीक दार्शनिक और वैज्ञानिक जड़ों से कटा हुआ पाया.',\n",
       " 'target': 'As knowledge of Greek declined, the West found itself cut off from its Greek philosophical and scientific roots.',\n",
       " 'lang': 'hi',\n",
       " 'translation_direction': 'xxen'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['examples'][230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in data['examples']:\n",
    "    hindi = tokenizer.encode(sample['source'])\n",
    "    english = tokenizer.encode(sample['target'])\n",
    "\n",
    "    total_hindi_tokens+= len(hindi)\n",
    "    total_english_tokens+= len(english)\n",
    "\n",
    "token_per_language['flores'] = {'Hindi': total_hindi_tokens,\n",
    "                                                'English': total_english_tokens,\n",
    "                                                'Romanised_Hindi': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flores = []\n",
    "\n",
    "hindi_instruction = \"निर्देश: दिए गए हिंदी पाठ के लिए अर्थ की दृष्टि से सर्वाधिक समान अंग्रेजी पाठ प्राप्त करें। पाठ: \"\n",
    "english_instruction = \"Instructions: Retrieve the most semantically similar Hindi text for the given English text. Text: \"\n",
    "\n",
    "for idx, sample in enumerate(data['examples']):\n",
    "\n",
    "    if idx%2==0:\n",
    "        data_ = {'id': f\"flores_{idx}\",\n",
    "                'source': hindi_instruction + sample['source'],\n",
    "                'target': sample['target']}\n",
    "    else:\n",
    "        data_ = {'id': f\"flores_{idx}\",\n",
    "                'source': english_instruction + sample['target'],\n",
    "                'target': sample['source']}\n",
    "\n",
    "    flores.append(data_)\n",
    "\n",
    "with open(f\"Processed_data/flores_test.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for sample in flores:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_of_texts = np.array([])\n",
    "for sample in data['examples']:\n",
    "    len_of_texts = np.append(len_of_texts, len(tokenizer.encode(sample['source'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(32.42885375494071)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_of_texts.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: LASER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of english sentences: 9.642\n",
      "Average length of hindi sentences: 8.965\n"
     ]
    }
   ],
   "source": [
    "english = []\n",
    "with open(\"./Data/Bitext Mining/LASER/tatoeba.hin-eng.eng\", \"r\") as f:\n",
    "    for sample in f:\n",
    "        english.append(sample)\n",
    "\n",
    "hindi = []\n",
    "with open(\"./Data/Bitext Mining/LASER/tatoeba.hin-eng.hin\", \"r\") as f:\n",
    "    for sample in f:\n",
    "        hindi.append(sample)\n",
    "\n",
    "length = np.array([len(tokenizer.encode(sample)) for sample in english])\n",
    "print(f\"Average length of english sentences: {length.mean()}\")\n",
    "length = np.array([len(tokenizer.encode(sample)) for sample in hindi])\n",
    "print(f\"Average length of hindi sentences: {length.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मेरे दादा ओसाका के हैं।\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My grandfather is from Osaka.\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'discourse': {'Hindi': 877126, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865425, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 180829, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 739292},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 744875},\n",
       " 'sentiment_review': {'Hindi': 52581, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35121615, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84594240,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for idx in range(len(hindi)):\n",
    "    hin = tokenizer.encode(hindi[idx])\n",
    "    eng = tokenizer.encode(english[idx])\n",
    "\n",
    "    total_hindi_tokens+= len(hin)\n",
    "    total_english_tokens+= len(eng)\n",
    "\n",
    "token_per_language['laser'] = {'Hindi': total_hindi_tokens,\n",
    "                                                'English': total_english_tokens,\n",
    "                                                'Romanised_Hindi': 0}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser = []\n",
    "\n",
    "hindi_instruction = \"निर्देश: दिए गए हिंदी पाठ के लिए अर्थ की दृष्टि से सर्वाधिक समान अंग्रेजी पाठ प्राप्त करें। पाठ: \"\n",
    "english_instruction = \"Instructions: Retrieve the most semantically similar Hindi text for the given English text. Text: \"\n",
    "\n",
    "for idx, (hin, eng) in enumerate(zip(hindi, english)):\n",
    "\n",
    "    if idx%2==0:\n",
    "        data = {'id': f\"laser_{idx}\",\n",
    "                'source': hindi_instruction + hin,\n",
    "                'target': eng}\n",
    "    else:\n",
    "        data = {'id': f\"laser_{idx}\",\n",
    "                'source': english_instruction + eng,\n",
    "                'target': hin}\n",
    "\n",
    "    laser.append(data)\n",
    "\n",
    "with open(f\"Processed_data/laser.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "    for sample in laser:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Mintaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Data/Bitext Mining/Mintaka/mintaka_test.json\", 'r') as f:\n",
    "    samples = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of english questions: 18.11875\n",
      "Average length of hindi questions: 15.969\n"
     ]
    }
   ],
   "source": [
    "length = np.array([len(tokenizer.encode(sample['question'])) for sample in samples])\n",
    "print(f\"Average length of english questions: {length.mean()}\")\n",
    "length = np.array([len(tokenizer.encode(sample['translations']['hi'])) for sample in samples])\n",
    "print(f\"Average length of hindi questions: {length.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '08a4f6d8',\n",
       " 'question': 'Who is older, Chris Pratt or Chris Evans?',\n",
       " 'translations': {'ar': 'من هو الأكبر عمرًا، كريس برات أم كريس إيفانز؟',\n",
       "  'de': 'Wer ist älter, Chris Pratt oder Chris Evans?',\n",
       "  'ja': '\"クリス・プラットとクリス・エヴァンス、どっちが年上?\"',\n",
       "  'hi': 'किसकी उम्र अधिक है, क्रिस प्रेट या क्रिस इवांस?',\n",
       "  'pt': 'Quem é mais velho, Chris Pratt ou Chris Evans?',\n",
       "  'es': '¿Quién es mayor: Chris Pratt o Chris Evans?',\n",
       "  'it': 'Chi è più grande, Chris Pratt o Chris Evans?',\n",
       "  'fr': 'Qui est plus âgé : Chris Pratt ou Chris Evans ?'},\n",
       " 'questionEntity': [{'name': 'Q178348',\n",
       "   'entityType': 'entity',\n",
       "   'label': 'Chris Evans',\n",
       "   'mention': 'Chris Evans',\n",
       "   'span': [29, 40]},\n",
       "  {'name': 'Q503706',\n",
       "   'entityType': 'entity',\n",
       "   'label': 'Chris Pratt',\n",
       "   'mention': 'Chris Pratt',\n",
       "   'span': [14, 25]}],\n",
       " 'answer': {'answerType': 'entity',\n",
       "  'answer': [{'name': 'Q503706',\n",
       "    'label': {'en': 'Chris Pratt',\n",
       "     'ar': 'كريس برات',\n",
       "     'de': 'Chris Pratt',\n",
       "     'es': 'Chris Pratt',\n",
       "     'fr': 'Chris Pratt',\n",
       "     'hi': 'क्रिस प्रैट',\n",
       "     'it': 'Chris Pratt',\n",
       "     'ja': 'クリス・プラット',\n",
       "     'pt': 'Chris Pratt'}}],\n",
       "  'mention': 'Chris Pratt'},\n",
       " 'category': 'movies',\n",
       " 'complexityType': 'comparative'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 63876, 'English': 72475, 'Romanised_Hindi': 0},\n",
       " 'discourse': {'Hindi': 877126, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865425, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 180829, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 739292},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 744875},\n",
       " 'sentiment_review': {'Hindi': 52581, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35121615, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84594240,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for idx in range(len(samples)):\n",
    "    eng = tokenizer.encode(samples[idx]['question'])\n",
    "    hin = tokenizer.encode(samples[idx]['translations']['hi'])\n",
    "\n",
    "    total_hindi_tokens+= len(hin)\n",
    "    total_english_tokens+= len(eng)\n",
    "\n",
    "token_per_language['Mintaka'] = {'Hindi': total_hindi_tokens,\n",
    "                                                'English': total_english_tokens,\n",
    "                                                'Romanised_Hindi': 0}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mintaka = []\n",
    "\n",
    "hindi_instruction = \"निर्देश: हिंदी प्रश्न के लिए शब्दार्थ की दृष्टि से सर्वाधिक समान अंग्रेजी प्रश्न को पुनः प्राप्त करें। \"\n",
    "english_instruction = \"Instructions: Retrieve the most semantically similar Hindi question for the English question. Question: \"\n",
    "\n",
    "for idx, sample in enumerate(samples):\n",
    "\n",
    "    if idx%2==0:\n",
    "        data = {'id': f\"mintaka_{idx}\",\n",
    "                'source': english_instruction + sample['question'],\n",
    "                'target': sample['translations']['hi']}\n",
    "    else:\n",
    "        data = {'id': f\"mintaka_{idx}\",\n",
    "                'source': hindi_instruction + sample['translations']['hi'],\n",
    "                'target': sample['question']}\n",
    "\n",
    "    mintaka.append(data)\n",
    "\n",
    "with open(f\"Processed_data/mintaka_test.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in mintaka:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: PHINC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>English_Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@someUSER congratulations on you celebrating b...</td>\n",
       "      <td>@some users congratulate you for celebrating B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@LoKarDi_RT uske liye toh bahot kuch karna pad...</td>\n",
       "      <td>@Lokardi_ rat we should a lot more for that, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@slimswamy yehi to hum semjhane ki koshish kar...</td>\n",
       "      <td>@Slimswami ehi, this is what i'm expecting you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  @someUSER congratulations on you celebrating b...   \n",
       "1  @LoKarDi_RT uske liye toh bahot kuch karna pad...   \n",
       "2  @slimswamy yehi to hum semjhane ki koshish kar...   \n",
       "\n",
       "                                 English_Translation  \n",
       "0  @some users congratulate you for celebrating B...  \n",
       "1  @Lokardi_ rat we should a lot more for that, b...  \n",
       "2  @Slimswami ehi, this is what i'm expecting you...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Data/Bitext Mining/PHINC/filtered_data.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of english questions: 32.44225399780015\n",
      "Average length of hindi questions: 24.490989085371012\n"
     ]
    }
   ],
   "source": [
    "length = np.array([len(tokenizer.encode(sample)) for sample in df['Sentence']])\n",
    "print(f\"Average length of english questions: {length.mean()}\")\n",
    "length = np.array([len(tokenizer.encode(sample)) for sample in df['English_Translation']])\n",
    "print(f\"Average length of hindi questions: {length.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@GhantaGuy is rishtewaad se azaadi'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[23,'Sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@Gantagay freedom from relations'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[23, 'English_Translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877126, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865425, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 180829, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 739292},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 744875},\n",
       " 'sentiment_review': {'Hindi': 52581, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35121615, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84594240,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "for sample in df.itertuples():\n",
    "    r_eng = tokenizer.encode(sample.Sentence)\n",
    "    eng = tokenizer.encode(sample.English_Translation)\n",
    "\n",
    "    total_r_english_tokens+= len(r_eng)\n",
    "    total_english_tokens+= len(eng)\n",
    "\n",
    "token_per_language['Mintaka'] = {'Hindi': 0,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "phinc = []\n",
    "\n",
    "hindi_instruction = \"nirdesh: die gae romanakrt hindi paath ke lie arth kee drshti se sabase adhik samaan angrejee paath praapt karen. paath: \"\n",
    "english_instruction = \"Instructions: Retrieve the most semantically similar romanized Hindi text for the given English text. Text: \"\n",
    "\n",
    "for idx in range(len(df)):\n",
    "\n",
    "    if idx%2==0:\n",
    "        data = {'id': f\"phinc_{idx}\",\n",
    "                'source': hindi_instruction + df.loc[idx, 'Sentence'],\n",
    "                'target': df.loc[idx, 'English_Translation']}\n",
    "    else:\n",
    "        data = {'id': f\"phinc_{idx}\",\n",
    "                'source': english_instruction + df.loc[idx, 'English_Translation'],\n",
    "                'target': df.loc[idx, 'Sentence']}\n",
    "\n",
    "    phinc.append(data)\n",
    "\n",
    "with open(f\"Processed_data/phinc.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in phinc:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: HindiDiscourseClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Data/Classification/HindiDiscourseClassification/discourse_dataset.json\", 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9968"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of hindi text: 21.421147672552166\n"
     ]
    }
   ],
   "source": [
    "length = np.array([len(tokenizer.encode(data[key]['Sentence'])) for key in data.keys()])\n",
    "print(f\"Average length of hindi text: {length.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Story_no': 0,\n",
       " 'Sentence': 'चेहरे पर इस की आँखें बहुत अजीब थीं।',\n",
       " 'Discourse Mode': 'Descriptive'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Story_no': 0,\n",
       " 'Sentence': 'चेहरे पर इस की आँखें बहुत अजीब थीं।',\n",
       " 'Discourse Mode': 'Descriptive'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse = []\n",
    "label_groups = {}\n",
    "\n",
    "instruction = \"निर्देश: दिए गए हिंदी पाठ को निम्नलिखित में से किसी एक श्रेणी में वर्गीकृत करें: 'वर्णनात्मक', 'कथात्मक', 'संवाद', 'तर्कपूर्ण', 'सूचनात्मक', या 'अन्य'। पाठ: \"\n",
    "\n",
    "for key in data.keys():\n",
    "    label = data[key][\"Discourse Mode\"]\n",
    "    if label not in label_groups:\n",
    "        label_groups[label] = []\n",
    "    label_groups[label].append(data[key][\"Sentence\"])\n",
    "\n",
    "for key in label_groups.keys():\n",
    "\n",
    "    for idx, sent in enumerate(label_groups[key]):\n",
    "\n",
    "        pos_idx = list(range(0, len(label_groups[key])))\n",
    "        pos_idx.remove(idx)\n",
    "        discourse.append({'id': f'discourse_{key}',\n",
    "                        'source': instruction + sent,\n",
    "                        'target': label_groups[key][random.choice(pos_idx)]})\n",
    "        \n",
    "random.shuffle(discourse)\n",
    "        \n",
    "with open(f\"Processed_data/discourse.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in discourse:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Descriptive', 'Narrative', 'Dialogue', 'Argumentative', 'Informative', 'Other'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865425, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 180829, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 739292},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 744875},\n",
       " 'sentiment_review': {'Hindi': 52581, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35121615, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84594240,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in discourse:\n",
    "    hin_1 = tokenizer.encode(sample['source'])\n",
    "    hin_2 = tokenizer.encode(sample['target'])\n",
    "\n",
    "    total_hindi_tokens+= len(hin_1)\n",
    "    total_hindi_tokens+= len(hin_2)\n",
    "\n",
    "token_per_language['discourse'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Massive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(\"./Data/Classification/Massive/hi-IN.jsonl\", 'r') as f:\n",
    "    for sample in f:\n",
    "        data.append(json.loads(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16521"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '2',\n",
       " 'locale': 'hi-IN',\n",
       " 'partition': 'train',\n",
       " 'scenario': 'alarm',\n",
       " 'intent': 'alarm_set',\n",
       " 'utt': 'अभी से दो घंटे के लिए अलार्म लगाओ',\n",
       " 'annot_utt': '[time : अभी से दो घंटे] के लिए अलार्म लगाओ',\n",
       " 'worker_id': '42',\n",
       " 'slot_method': [{'slot': 'time', 'method': 'translation'}],\n",
       " 'judgments': [{'worker_id': '3',\n",
       "   'intent_score': 1,\n",
       "   'slots_score': 1,\n",
       "   'grammar_score': 3,\n",
       "   'spelling_score': 2,\n",
       "   'language_identification': 'target'},\n",
       "  {'worker_id': '42',\n",
       "   'intent_score': 1,\n",
       "   'slots_score': 1,\n",
       "   'grammar_score': 4,\n",
       "   'spelling_score': 2,\n",
       "   'language_identification': 'target'},\n",
       "  {'worker_id': '46',\n",
       "   'intent_score': 0,\n",
       "   'slots_score': 1,\n",
       "   'grammar_score': 4,\n",
       "   'spelling_score': 2,\n",
       "   'language_identification': 'target'}]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "massive = []\n",
    "label_groups = {}\n",
    "\n",
    "instruction = \"निर्देश: दिए गए आदेश को निम्नलिखित में से किसी एक आशय श्रेणी में वर्गीकृत करें: 'अलार्म', 'ऑडियो', 'आईओटी', 'कैलेंडर', 'प्ले', 'सामान्य', 'डेटटाइम', 'टेकअवे', 'समाचार', 'संगीत', 'मौसम', 'क्यूए', 'सामाजिक', 'सिफारिश', 'खाना पकाना', 'परिवहन', 'ईमेल', 'सूचियाँ'। पाठ: \"\n",
    "\n",
    "for item in data:\n",
    "    label = item[\"scenario\"]\n",
    "    if label not in label_groups:\n",
    "        label_groups[label] = []\n",
    "    label_groups[label].append(item[\"utt\"])\n",
    "\n",
    "for key in label_groups.keys():\n",
    "\n",
    "    for idx, sent in enumerate(label_groups[key]):\n",
    "\n",
    "        pos_idx = list(range(0, len(label_groups[key])))\n",
    "        pos_idx.remove(idx)\n",
    "        massive.append({'id': f'massive_{key}',\n",
    "                        'source': instruction + sent,\n",
    "                        'target': label_groups[key][random.choice(pos_idx)]})\n",
    "        \n",
    "random.shuffle(massive)\n",
    "        \n",
    "with open(f\"Processed_data/massive.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in massive:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alarm', 'audio', 'iot', 'calendar', 'play', 'general', 'datetime', 'takeaway', 'news', 'music', 'weather', 'qa', 'social', 'recommendation', 'cooking', 'transport', 'email', 'lists'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of hindi text: 9.21747437901685\n"
     ]
    }
   ],
   "source": [
    "train_data = [sample for sample in data if sample['partition']=='train']\n",
    "length = np.array([len(tokenizer.encode(sample['utt'])) for sample in train_data])\n",
    "print(f\"Average length of hindi text: {length.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 180829, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 739292},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 744875},\n",
       " 'sentiment_review': {'Hindi': 52581, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35121615, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84594240,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in massive:\n",
    "    hin_1 = tokenizer.encode(sample['source'])\n",
    "    hin_2 = tokenizer.encode(sample['target'])\n",
    "\n",
    "    total_hindi_tokens+= len(hin_1)\n",
    "    total_hindi_tokens+= len(hin_2)\n",
    "\n",
    "token_per_language['massive'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: SentimentAnalysisHindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"./Data/Classification/SentimentAnalysisHindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of hindi text: 22.835402482979575\n"
     ]
    }
   ],
   "source": [
    "length = np.array([len(tokenizer.encode(sample['text'])) for sample in ds['train']])\n",
    "print(f\"Average length of hindi text: {length.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'pos',\n",
       " 'text': 'इस कैमरे से डिफरेंट मोड्स तथा ब्राइटनेस एडजस्ट करके अच्छी फोटोज ली जा सकती है।'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][287]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = []\n",
    "label_groups = {}\n",
    "\n",
    "instruction = \"निर्देश: दिए गए पाठ को निम्नलिखित भावना श्रेणियों में से किसी एक में वर्गीकृत करें: सकारात्मक, नकारात्मक, या तटस्थ। पाठ: \"\n",
    "\n",
    "for item in ds['train']:\n",
    "    label = item[\"label\"]\n",
    "    if label not in label_groups:\n",
    "        label_groups[label] = []\n",
    "    label_groups[label].append(item[\"text\"])\n",
    "\n",
    "for key in label_groups.keys():\n",
    "\n",
    "    for idx, sent in enumerate(label_groups[key]):\n",
    "\n",
    "        pos_idx = list(range(0, len(label_groups[key])))\n",
    "        pos_idx.remove(idx)\n",
    "        sentiment.append({'id': f'sentiment_{key}',\n",
    "                        'source': instruction + sent,\n",
    "                        'target': label_groups[key][random.choice(pos_idx)]})\n",
    "        \n",
    "random.shuffle(sentiment)\n",
    "        \n",
    "with open(f\"Processed_data/sentiment.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in sentiment:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['neg', 'pos', 'neu'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 179859, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 739292},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 744875},\n",
       " 'sentiment_review': {'Hindi': 52581, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35121615, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84594240,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in sentiment:\n",
    "    hin_1 = tokenizer.encode(sample['source'])\n",
    "    hin_2 = tokenizer.encode(sample['target'])\n",
    "\n",
    "    total_hindi_tokens+= len(hin_1)\n",
    "    total_hindi_tokens+= len(hin_2)\n",
    "\n",
    "token_per_language['sentiment'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Sentiment Analysis Joshi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_csv = pd.read_csv(\"./Data/Classification/sent_hineng_joshi/sentiment_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = []\n",
    "label_groups = {}\n",
    "\n",
    "instruction = \"निर्देश: दिए गए पाठ को निम्नलिखित भावना श्रेणियों में से किसी एक में वर्गीकृत करें: नकारात्मक (-1), तटस्थ (0), या सकारात्मक (1)। पाठ:\"\n",
    "\n",
    "for (_,item) in data_csv.iterrows():\n",
    "    label = item.iloc[1]\n",
    "    if label not in label_groups:\n",
    "        label_groups[label] = []\n",
    "    label_groups[label].append(item.iloc[0])\n",
    "\n",
    "for key in label_groups.keys():\n",
    "\n",
    "    for idx, sent in enumerate(label_groups[key]):\n",
    "\n",
    "        pos_idx = list(range(0, len(label_groups[key])))\n",
    "        pos_idx.remove(idx)\n",
    "        sentiment.append({'id': f'sentiment_joshi_{key}',\n",
    "                        'source': instruction + sent,\n",
    "                        'target': label_groups[key][random.choice(pos_idx)]})\n",
    "        \n",
    "random.shuffle(sentiment)\n",
    "        \n",
    "with open(f\"Processed_data/sentiment_joshi.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in sentiment:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'sentiment_joshi_1',\n",
       " 'source': 'निर्देश: दिए गए पाठ को निम्नलिखित भावना श्रेणियों में से किसी एक में वर्गीकृत करें: नकारात्मक (-1), तटस्थ (0), या सकारात्मक (1)। पाठ:Modi ji agar 10 sal pahle pm bane hote to aaj india ki tasbeer dusari hoti sayad india china ke barabar me hota.',\n",
       " 'target': 'Salman g meri asiqi sirf tumse hai'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 179859, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 309757},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 744875},\n",
       " 'sentiment_review': {'Hindi': 52581, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35121615, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84594240,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in sentiment:\n",
    "    hin_1 = tokenizer.encode(sample['source'])\n",
    "    hin_2 = tokenizer.encode(sample['target'])\n",
    "\n",
    "    total_r_english_tokens+= len(hin_1)\n",
    "    total_r_english_tokens+= len(hin_2)\n",
    "\n",
    "token_per_language['sentiment_joshi'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Sentiment Shete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7663\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_csv = pd.read_csv(\"./Data/Classification/sent_hineng_shete/data.csv\")\n",
    "print(len(data_csv))\n",
    "data_csv = data_csv.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = []\n",
    "label_groups = {}\n",
    "\n",
    "instruction = \"निर्देश: दिए गए पाठ को निम्नलिखित भावना श्रेणियों में से किसी एक में वर्गीकृत करें: नकारात्मक (-1), तटस्थ (0), या सकारात्मक (1)। पाठ:\"\n",
    "label_dict = {-1: 'neg',\n",
    "              0: 'neu',\n",
    "              1: 'pos'}\n",
    "for (_,item) in data_csv.iterrows():\n",
    "    label = label_dict[item.iloc[1]]\n",
    "    if label not in label_groups:\n",
    "        label_groups[label] = []\n",
    "    label_groups[label].append(item.iloc[0])\n",
    "\n",
    "for key in label_groups.keys():\n",
    "\n",
    "    for idx, sent in enumerate(label_groups[key]):\n",
    "\n",
    "        pos_idx = list(range(0, len(label_groups[key])))\n",
    "        pos_idx.remove(idx)\n",
    "        sentiment.append({'id': f'sentiment_shete_{key}',\n",
    "                        'source': instruction + sent,\n",
    "                        'target': label_groups[key][random.choice(pos_idx)]})\n",
    "        \n",
    "random.shuffle(sentiment)\n",
    "        \n",
    "with open(f\"Processed_data/sentiment_shete.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in sentiment:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 179859, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 309757},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 740551},\n",
       " 'sentiment_review': {'Hindi': 52581, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35121615, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84594240,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in sentiment:\n",
    "    hin_1 = tokenizer.encode(sample['source'])\n",
    "    hin_2 = tokenizer.encode(sample['target'])\n",
    "\n",
    "    total_r_english_tokens+= len(hin_1)\n",
    "    total_r_english_tokens+= len(hin_2)\n",
    "\n",
    "token_per_language['sentiment_shete'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Sentiment Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_csv = pd.read_csv(\"Data/Classification/sent_review/sentiment_reviews.csv\")\n",
    "data_csv = data_csv.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = []\n",
    "label_groups = {}\n",
    "\n",
    "instruction = \"निर्देश: दिए गए पाठ को निम्नलिखित भावना श्रेणियों में से किसी एक में वर्गीकृत करें: नकारात्मक (-1), या सकारात्मक (1)। पाठ:\"\n",
    "\n",
    "for (_,item) in data_csv.iterrows():\n",
    "    label = item.iloc[1]\n",
    "    if label not in label_groups:\n",
    "        label_groups[label] = []\n",
    "    label_groups[label].append(item.iloc[0])\n",
    "\n",
    "for key in label_groups.keys():\n",
    "\n",
    "    for idx, sent in enumerate(label_groups[key]):\n",
    "\n",
    "        pos_idx = list(range(0, len(label_groups[key])))\n",
    "        pos_idx.remove(idx)\n",
    "        sentiment.append({'id': f'sentiment_review_{key}',\n",
    "                        'source': instruction + sent,\n",
    "                        'target': label_groups[key][random.choice(pos_idx)]})\n",
    "        \n",
    "random.shuffle(sentiment)\n",
    "        \n",
    "with open(f\"Processed_data/sentiment_review.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in sentiment:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 179859, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 309757},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 740551},\n",
       " 'sentiment_review': {'Hindi': 52821, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35121615, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84594240,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in sentiment:\n",
    "    hin_1 = tokenizer.encode(sample['source'])\n",
    "    hin_2 = tokenizer.encode(sample['target'])\n",
    "\n",
    "    total_hindi_tokens+= len(hin_1)\n",
    "    total_hindi_tokens+= len(hin_2)\n",
    "\n",
    "token_per_language['sentiment_review'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Amazon Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"mteb/amazon_reviews_multi\", \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'en_0311558',\n",
       " 'text': \"The product is junk.\\n\\nI received my first order of this product and it was broke so I ordered it again. The second one was broke in more places than the first. I can't blame the shipping process as it's shrink wrapped and boxed.\",\n",
       " 'label': 0,\n",
       " 'label_text': '0'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([sample['label'] for sample in ds['train']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_review = []\n",
    "label_groups = {}\n",
    "\n",
    "instruction = \"Instruction: Classify the sentiment of the following Amazon product review into one of the following labels:\\n0 - Very Negative  \\n1 - Negative \\n2 - Neutral  \\n3 - Positive  \\n4 - Very Positive \\nReview: \"\n",
    "\n",
    "for item in ds['train']:\n",
    "    label = item['label']\n",
    "    if label not in label_groups:\n",
    "        label_groups[label] = []\n",
    "    label_groups[label].append(item['text'])\n",
    "\n",
    "for key in label_groups.keys():\n",
    "\n",
    "    for idx, sent in enumerate(label_groups[key]):\n",
    "\n",
    "        pos_idx = list(range(0, len(label_groups[key])))\n",
    "        pos_idx.remove(idx)\n",
    "        amazon_review.append({'id': f'amazon_review_{key}',\n",
    "                        'source': instruction + sent,\n",
    "                        'target': label_groups[key][random.choice(pos_idx)]})\n",
    "        \n",
    "random.shuffle(amazon_review)\n",
    "        \n",
    "with open(f\"Processed_data/amazon_review.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in amazon_review:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'amazon_review_0',\n",
       " 'source': \"Instruction: Classify the sentiment of the following Amazon product review into one of the following labels:\\n0 - Very Negative  \\n1 - Negative \\n2 - Neutral  \\n3 - Positive  \\n4 - Very Positive \\nReview: Deceiving description -- it's NOT real leather.\\n\\nNOT genuine leather, it's cheap PU. Nice looking bag, however has awful, strong, chemical smell. Immediate headaches.\",\n",
       " 'target': 'Leaking\\n\\nCame leaking in package and so sticky. Smells gross also.'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_review[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_review_test = []\n",
    "label_groups = {}\n",
    "\n",
    "instruction = \"Instruction: Classify the sentiment of the following Amazon product review into one of the following labels:\\n0 - Very Negative  \\n1 - Negative \\n2 - Neutral  \\n3 - Positive  \\n4 - Very Positive \\nReview: \"\n",
    "\n",
    "for item in ds['validation']:\n",
    "    label = item['label']\n",
    "    if label not in label_groups:\n",
    "        label_groups[label] = []\n",
    "    label_groups[label].append(item['text'])\n",
    "\n",
    "for key in label_groups.keys():\n",
    "\n",
    "    for idx, sent in enumerate(label_groups[key]):\n",
    "\n",
    "        pos_idx = list(range(0, len(label_groups[key])))\n",
    "        pos_idx.remove(idx)\n",
    "        amazon_review_test.append({'id': f'amazon_review_val{key}',\n",
    "                        'source': instruction + sent,\n",
    "                        'target': label_groups[key][random.choice(pos_idx)]})\n",
    "        \n",
    "random.shuffle(amazon_review_test)\n",
    "        \n",
    "with open(f\"Processed_data/amazon_review_test.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in amazon_review_test:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 179859, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 309757},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 740551},\n",
       " 'sentiment_review': {'Hindi': 52821, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35130924, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84594240,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in amazon_review:\n",
    "    eng_1 = tokenizer.encode(sample['source'])\n",
    "    eng_2 = tokenizer.encode(sample['target'])\n",
    "\n",
    "    total_english_tokens+= len(eng_1)\n",
    "    total_english_tokens+= len(eng_2)\n",
    "\n",
    "token_per_language['amazon_review'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: ABP news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"Data/Classification/ABP_News/ABP_News_classification.json\", \"r\") as f:\n",
    "    abp_news = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "abp_news_classification = []\n",
    "label_groups = {}\n",
    "\n",
    "instruction = \"निर्देश: निम्नलिखित समाचार लेख को दिए गए श्रेणियों में से किसी एक में वर्गीकृत करें: श्रेणियाँ: gk, technology, business, entertainment, agriculture, astro, lifestyle, sports, education, states. समाचार लेख:\"\n",
    "\n",
    "for key, val in abp_news.items():\n",
    "    label = val['domain']\n",
    "    if label not in label_groups:\n",
    "        label_groups[label] = []\n",
    "    label_groups[label].append(val['article'])\n",
    "\n",
    "for key in label_groups.keys():\n",
    "\n",
    "    for idx, sent in enumerate(label_groups[key]):\n",
    "\n",
    "        pos_idx = list(range(0, len(label_groups[key])))\n",
    "        pos_idx.remove(idx)\n",
    "        abp_news_classification.append({'id': f'abp_news_classification_{key}',\n",
    "                        'source': instruction + sent,\n",
    "                        'target': label_groups[key][random.choice(pos_idx)]})\n",
    "        \n",
    "random.shuffle(abp_news_classification)\n",
    "        \n",
    "with open(f\"Processed_data/abp_news_classification.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in abp_news_classification:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'abp_news_classification_lifestyle',\n",
       " 'source': 'निर्देश: निम्नलिखित समाचार लेख को दिए गए श्रेणियों में से किसी एक में वर्गीकृत करें: श्रेणियाँ: gk, technology, business, entertainment, agriculture, astro, lifestyle, sports, education, states. समाचार लेख:Happy Diwali 2024 Wishes: दिवाली आ गई है और हर घर जगमगा रहा है. पूजा की तैयारियां हो रही हैं और लोग मां लक्ष्मी के आगमन का इंतजार कर रहे हैं. हर साल कार्तिक माह के कृष्ण पक्ष की अमावस्या को दिवाली मनाई जाती है. दिवाली पर पूजा पाठ के साथ साथ लोग एक दूसरे को मिठाई खिलाते हैं और दिवाली की शुभकामनाएं देते हैं. अगर आप भी अपने परिवार, परिचितों और दोस्तों को दिवाली की शुभकामनाएं भेजना चाहते हैं तो यहां दिवाली के लिए कोट्स, विशेज और व्हाट्सएप संदेश दिए जा रहे हैं.\\nयह भी पढ़ें:\\xa0देश के लगभग 88% लोग हैं एंग्जायटी के शिकार, अगर आप भी हैं उनमें से एक तो करें ये काम\\nHappy Diwali 2024 Wishes दिवाली 2024 शुभकामनाएं और संदेश\\nइस दीपावली, आपके घर में लक्ष्मी का स्वागत हो, गणेश की कृपा से सभी कठिनाइयों का निवारण हो. दिवाली की मंगलमय शुभकामनाएं.\\nदीप जलाना, पटाखे फोड़ना, मिठाई बांटना,सब मिलकर दिवाली का उत्सव बनाता है . दिवाली की मंगलमय शुभकामनाएं\\nआपके घर में लक्ष्मी गणेश का वास हो,जीवन से अंधेरा दूर हो,हर खुशी आपके द्वार पर दस्तक दे,और आपकी जिंदगी में खुशियों की महफ़िल सज जाए.दीपावली की मंगलमय शुभकामनाएं!\\nआंगन में रंगोली बनाएं, घर के द्वार पर दीये जलाएंसुख-समृद्धि आपके घर को आएदिवाली की मंगलमय शुभकामनाएं.\\nलक्ष्मी जी विराजें आपके द्वार, सोने-चांदी से भर जाए आपका घर-बारजीवन में आएं खुशियां अपार, शुभकामना करो हमारी ये स्वीकार.दीपावली की मंगलमय शुभकामनाएं.\\nदीप जगमगाते रहें,सबके घर झिलमिलाते रहें, साथ हों सब अपने सब यूं ही मुस्कुराते रहें.दीये की रोशनी से सब अंधेरा दूर हो जाए, दुआ है कि जो चाहो आप वो खुशी मंजूर हो जाए.दिवाली की मंगलमय शुभकामनाएं.\\nयह भी पढ़ें:\\xa0अब 40 पर्सेंट तक कम हो जाएगा सर्वाइकल कैंसर से मौत का खतरा, 10 साल की टेस्टिंग के बाद तैयार हुआ खास ट्रीटमेंट\\nमाता लक्ष्मी और भगवान गणेश की कृपा से आपके जीवन में सुख, समृद्धि और सफलता का दीप जलता रहे, दिवाली की मंगलमय शुभकामनाएं.\\nरंगोली और दीयों से सजे घरों में,भगवान राम के आगमन की खुशी छा जाए,और आपके जीवन में सुख, समृद्धि और खुशहाली की बहार आए।दीपावली की मंगलमय शुभकामनाएं.\\nदिवाली की ज्योति आपके जीवन को रोशन करेमाता लक्ष्मी का आशीर्वाद आपके ऊपर बरस जाएआपके घर में खुशियाँ और समृद्धि का वास हो.आपका जीवन सफलता से भरा होदिवाली की मंगलमय शुभकामनाएं.\\nदिवाली का यह पावन त्यौहार,आपके जीवन में खुशियां लाये अपार, लक्ष्मी विराजमान हों आपके द्वारशुभकामनाएं आप हमारी करें स्वीकार.दिवाली की मंगलमय शुभकामनाएं.\\nयह भी पढ़ें :शहरों में रहने वाली लड़कियों में कॉमन हो रही है सारा अली खान वाली ये बीमारी, इग्नोर करना हो सकता है खतरनाक',\n",
       " 'target': \"World Organ Donation 2024: 'वर्ल्ड ऑर्गन डोनेशन 2024' हर साल की तरह इस साल भी 13 अगस्त को मनाया जाएगा. इस मौके पर हम आपको एक रिपोर्ट पेश करने जा रहे हैं. इस रिपोर्ट के मुताबिक अंग दान में भी भारी लैंगिग असमानता देखने को मिली है. शुरुआत करते हैं जब लालू यादव की बेटी रोहिणी आचार्य ने पिछले साल अपने 74 साल के पिता लालू प्रसाद यादव के लिए किडनी दान की थी. तो इसे शानदार निस्वार्थ प्रेम से तुलना की गई थी. उन्हें हीरो तक कहा गया.\\nहमने जब इसी मामले पर और भी कुछ रिसर्च किया तो पता चला मुंबई की एक सास की, जिसने अपनी एक किडनी अपनी 43 वर्षीय बहू को दान कर दी. इस खास रिसर्च के दौरान कई औरतों के नाम सामने जिसने अपने रिश्तेदार, फैमिली में ऑर्गन डोनेट किया.\\xa0 हमने फिल्म आसपास के टेली शॉप शो में देखा है कि घर में अगर किसी को ऑर्गन की जरूरत पड़ती है तो घर की महिला हंसते हुए दान कर देती है.\\nयह देखते ही हम लोग इमोशनल हो जाते हैं. क्योंकि महिलाओं को देवी, करुणा और ममता की मूर्ती कहा गया है. जब हम इमोशन हटाकर लॉजिक के साथ सोचते हैं तो एक गंभीर समाज की सच्चाई हमारे सामने आती है. जिसे जानकर आप एक पल के लिए थोड़े असहज जरूर हो जाएंगे. हाल ही में सामने आई रिसर्च के मुताबिक अंगदान में लैंगिग असमानता न केवल भारत में बल्कि पूरी दुनिया भर में है.\\xa0\\nनेशनल ऑर्गन एंड सेल्स ट्रांसप्लांट ऑर्गेनाइजेशन (NOTTO) की रिपोर्ट के मुताबिक\\nनेशनल ऑर्गन एंड सेल्स ट्रांसप्लांट ऑर्गेनाइजेशन (NOTTO) के अनुसार, भारत में अंग प्रत्यारोपण 2013 में 4,990 से बढ़कर 2022 में 16,041 हो गया है. यह अभी भी देश की 1.4 बिलियन से अधिक आबादी का एक छोटा सा हिस्सा है. इनमें से, मृतक दाताओं की संख्या जीवित दाताओं की संख्या से थोड़ी भी नहीं है. और इन जीवित अंग दाताओं में महिलाओं की संख्या पुरुषों से अधिक है.\\nअंगदान में लैंगिक असमानताहाल के दिनों में, भारत में विभिन्न अस्पतालों और राज्य-स्तरीय संगठनों ने अंगदान में लैंगिक असमानता के बारे में आंकड़े पेश किए हैं. बिहार में, जो लालू प्रसाद यादव का गृह राज्य है, 2016 से राज्य में रिपोर्ट किए गए कुल 170 से ज़्यादा किडनी प्रत्यारोपण में से 120 से ज़्यादा महिलाओं ने अपने प्रियजन के लिए किडनी दान की, जबकि सिर्फ़ 50 पुरुषों ने किडनी दान की थी.\\xa0\\nनई दिल्ली और मुंबई जैसे महानगरों से कई मीडिया रिपोर्ट्स में डॉक्टरों के हवाले से बताया गया है कि महिला अंग दाताओं और पुरुष अंग प्राप्तकर्ताओं में लिंग असमानता है. यह महिलाओं के लिए प्रत्यारोपण तक पहुंच में लिंग-आधारित असमानताओं को भी प्रभावित करता है.\\nलिपिंकॉट विलियम्स एंड विल्किंस जर्नल में 2021 में पब्लिश एक रिपोर्ट के किडनी रोग से पीड़ित महिलाओं को प्रत्यारोपण मूल्यांकन के लिए रेफर किए जाने और इसलिए किडनी प्रत्यारोपण करवाने की संभावना कम होती है, और फिर भी वे जीवित किडनी दाताओं में बहुसंख्यक होती हैं.\\nआखिर क्या कारण है जो पुरुष के मुकाबले महिलाएं अंगदान ज्यादा करती है?\\nपुरुषों की तुलना में महिलाएं ज़्यादा अंगदान क्यों करती हैं? इसके कई कारण और परिकल्पनाएं हो सकती हैं. नेशनल मेडिकल जर्नल ऑफ़ इंडिया में 2022 के एक लेख के मुताबिक आर्थिक निहितार्थ, महिलाओं में आत्म-बलिदान की भावना, साथ ही संचार के माध्यम से संस्थानों या विशेषज्ञों में लैंगिक पूर्वाग्रह, ऐसे कारण हो सकते हैं जिनकी वजह से ज़्यादा महिलाएं जीवित दाता बन जाती हैं. चाहे वे माँ हों, पत्नी हों, बेटी हों या बहनें.\\nपितृसत्तात्मक समाज का असर\\nलिवर ट्रांसप्लांट विशेषज्ञ डॉ. अंकुर गर्ग के अनुसार, इस बात पर कोई बहस नहीं है कि जीवित अंगदान में लैंगिक असमानता मौजूद है. डॉ. गर्ग ने हेल्थ शॉट्स को बताया, इसका एक बड़ा हिस्सा हमारे समाज की मानसिकता और कुछ हद तक इस तथ्य के कारण है कि यह एक पितृसत्तात्मक समाज है. ज़्यादा पुरुष शराबी लिवर रोग से पीड़ित हैं और पुरुषों में शराब पीना ज़्यादा आम है, और पत्नियां दाता बन जाती हैं.\\nमहिलाएं अपनी घर-समाज से होती हैं काफी ज्यादा प्रभावित\\nहमारी सामाजिक मानसिकता ऐसी है कि हमारे समाज में अक्सर महिलाओं को फैमिली, रिश्तेदार, आसपास के लोग को देखभाल करने वाली और पालन-पोषण करने वाली के रूप में देखा गया है. कुरुणा और बलिदान की मूर्ति माना गया है. हमारे समाज में महिलाओं की परवरिश ऐसी की जाती है कि उन्हें दूसरे के लिए जीना पहले सिखाया जाता है.\\xa0\\nDisclaimer: खबर में दी गई कुछ जानकारी मीडिया रिपोर्ट्स पर आधारित है. आप किसी भी सुझाव को अमल में लाने से पहले संबंधित विशेषज्ञ से सलाह जरूर लें.\\nयह भी पढ़ें:\\xa0Weight Loss: एक महीने में कितना वजन कम करना है सही? कहीं आप भी तो नहीं कर रहे ये गलती\\nCheck out below Health Tools-Calculate Your Body Mass Index ( BMI )\\nCalculate The Age Through Age Calculator\"}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abp_news_classification[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 179859, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 309757},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 740551},\n",
       " 'sentiment_review': {'Hindi': 52821, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35130924, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84599189,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in abp_news_classification:\n",
    "    hin_1 = tokenizer.encode(sample['source'])\n",
    "    hin_2 = tokenizer.encode(sample['target'])\n",
    "\n",
    "    total_hindi_tokens+= len(hin_1)\n",
    "    total_hindi_tokens+= len(hin_2)\n",
    "\n",
    "token_per_language['abp_news_classification'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: MTOP Intent Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mteb.tasks import MTOPIntentClassification\n",
    "\n",
    "task = MTOPIntentClassification()\n",
    "task.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 3232353139323338,\n",
       " 'text': 'क्या ओसवाल्डो ऑनलाइन है?',\n",
       " 'label': 5,\n",
       " 'label_text': 'GET_AVAILABILITY'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.dataset['hi']['train'][23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "intent = []\n",
    "label_groups = {}\n",
    "\n",
    "instruction = \"निर्देश: दिए गए पाठ को उसके उद्देश्य के आधार पर वर्गीकृत करें। पाठ: \"\n",
    "\n",
    "for item in task.dataset['hi']['train']:\n",
    "    label = item[\"label\"]\n",
    "    if label not in label_groups:\n",
    "        label_groups[label] = []\n",
    "    label_groups[label].append(item[\"text\"])\n",
    "\n",
    "drop_key = []\n",
    "for key in label_groups.keys():\n",
    "\n",
    "    if len(label_groups[key]) < 2:\n",
    "        drop_key.append(key)\n",
    "    \n",
    "\n",
    "for key in label_groups.keys():\n",
    "\n",
    "    if key not in drop_key:\n",
    "\n",
    "        for idx, sent in enumerate(label_groups[key]):\n",
    "\n",
    "            pos_idx = list(range(0, len(label_groups[key])))\n",
    "            pos_idx.remove(idx)\n",
    "            intent.append({'id': f'intent_{key}',\n",
    "                            'source': instruction + sent,\n",
    "                            'target': label_groups[key][random.choice(pos_idx)]})\n",
    "        \n",
    "random.shuffle(intent)\n",
    "        \n",
    "with open(f\"Processed_data/mtop_intent.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in intent:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 179859, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 309757},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 740551},\n",
       " 'sentiment_review': {'Hindi': 52821, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35130924, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84599189,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in intent:\n",
    "    hin_1 = tokenizer.encode(sample['source'])\n",
    "    hin_2 = tokenizer.encode(sample['target'])\n",
    "\n",
    "    total_hindi_tokens+= len(hin_1)\n",
    "    total_hindi_tokens+= len(hin_2)\n",
    "\n",
    "token_per_language['intent'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: XNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"mteb/xnli\", \"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'lang'],\n",
       "        num_rows: 5010\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'lang'],\n",
       "        num_rows: 392702\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'lang'],\n",
       "        num_rows: 2490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'खैर यह बहुत रोचक हो गया है',\n",
       " 'hypothesis': 'यह बहुत ही दिलचस ् प है .',\n",
       " 'label': 0,\n",
       " 'lang': 'hi'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "xnli = []\n",
    "label_groups = {}\n",
    "\n",
    "instruction = \"निर्देश: दिए गए प्रेज़म और हाइपोथेसिस के आधार पर निर्धारित करें कि संबंध 'अनुकूलन (entailment)', 'तटस्थ (neutral)', या 'विरोधाभासी (contradiction)' है। \"\n",
    "\n",
    "for idx in range(392702):\n",
    "    label = ds['train'][idx][\"label\"]\n",
    "    if label not in label_groups:\n",
    "        label_groups[label] = []\n",
    "    label_groups[label].append(f\"आधार: {ds['train'][idx]['premise']} परिकल्पना: {ds['train'][idx]['hypothesis']} \")\n",
    "\n",
    "for key in label_groups.keys():\n",
    "\n",
    "    for idx, sent in enumerate(label_groups[key]):\n",
    "\n",
    "        pos_idx = list(range(0, len(label_groups[key])))\n",
    "        pos_idx.remove(idx)\n",
    "        xnli.append({'id': f'xnli_{key}',\n",
    "                        'source': instruction + sent,\n",
    "                        'target': label_groups[key][random.choice(pos_idx)]})\n",
    "        \n",
    "random.shuffle(xnli)\n",
    "        \n",
    "with open(f\"Processed_data/xnli.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in xnli:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'xnli_2',\n",
       " 'source': \"निर्देश: दिए गए प्रेज़म और हाइपोथेसिस के आधार पर निर्धारित करें कि संबंध 'अनुकूलन (entailment)', 'तटस्थ (neutral)', या 'विरोधाभासी (contradiction)' है। आधार: आदमी को तुरंत मर जाना चाहिए . परिकल्पना: आदमी पूरी तरह से ठीक था . \",\n",
       " 'target': 'आधार: अधिक लिंक पर क ् लिक करें ( दायें-हाथ के नीचे की ओर ) , और से परिकल्पना: विविध के अंतर ् गत क ् लिक करने के लिए कोई लिंक नहीं है . '}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xnli[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 129183,\n",
       "  'English': 3931068,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 2737249,\n",
       "  'English': 142367,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 47993978,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 200745412,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 31515, 'English': 32821, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'discourse': {'Hindi': 877126, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865425, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 180829, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 739292},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 744875},\n",
       " 'sentiment_review': {'Hindi': 52581, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35121615, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84594240,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'xnli': {'Hindi': 73407016, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in xnli:\n",
    "    hin_1 = tokenizer.encode(sample['source'])\n",
    "    hin_2 = tokenizer.encode(sample['target'])\n",
    "\n",
    "    total_hindi_tokens+= len(hin_1)\n",
    "    total_hindi_tokens+= len(hin_2)\n",
    "\n",
    "token_per_language['xnli'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: ai4bharat/samanantar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = {}\n",
    "\n",
    "for language in ['as', 'bn', 'gu', 'hi', 'kn', 'ml', 'mr', 'or', 'pa', 'ta', 'te']:\n",
    "    data[language] = load_dataset(\"ai4bharat/samanantar\", language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_as = load_dataset(\"ai4bharat/samanantar\", \"as\")\n",
    "ds_bn = load_dataset(\"ai4bharat/samanantar\", \"bn\")\n",
    "ds_gu = load_dataset(\"ai4bharat/samanantar\", \"gu\")\n",
    "ds_hi = load_dataset(\"ai4bharat/samanantar\", \"hi\")\n",
    "ds_kn = load_dataset(\"ai4bharat/samanantar\", \"kn\")\n",
    "ds_ml = load_dataset(\"ai4bharat/samanantar\", \"ml\")\n",
    "ds_mr = load_dataset(\"ai4bharat/samanantar\", \"mr\")\n",
    "ds_or = load_dataset(\"ai4bharat/samanantar\", \"or\")\n",
    "ds_pa = load_dataset(\"ai4bharat/samanantar\", \"pa\")\n",
    "ds_ta = load_dataset(\"ai4bharat/samanantar\", \"ta\")\n",
    "ds_te = load_dataset(\"ai4bharat/samanantar\", \"te\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 0, 'src': 'Tie up long hair.', 'tgt': 'মেলি থোৱা দীঘল চুলি।'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['as']['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "language_classification = []\n",
    "\n",
    "instruction = \"निर्देश: दिए गए पाठ की भाषा को निम्नलिखित भाषाओं में से किसी एक के रूप में वर्गीकृत करें: असमिया (as), बांग्ला (bn), गुजराती (gu), हिंदी (hi), कन्नड़ (kn), मलयालम (ml), मराठी (mr), उड़िया (or), पंजाबी (pa), तमिल (ta), या तेलुगू (te)। पाठ: \"\n",
    "\n",
    "for key in ['as', 'bn', 'gu', 'hi', 'kn', 'ml', 'mr', 'or', 'pa', 'ta', 'te']:\n",
    "\n",
    "    for idx, sent in enumerate(data[key]['train']):\n",
    "\n",
    "        if key=='hi' and idx>5000:\n",
    "            break\n",
    "        elif key!='hi' and idx>500:\n",
    "            break\n",
    "\n",
    "        language_classification.append({'id': f'samanantar_{key}',\n",
    "                        'source': instruction + sent['tgt'],\n",
    "                        'target': data[key]['train'][data[key]['train'].num_rows-1-idx]['tgt']})\n",
    "        \n",
    "random.shuffle(language_classification)\n",
    "        \n",
    "with open(f\"Processed_data/samanantar_language_classification.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in language_classification:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Code Mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_csv = pd.read_csv(\"Data/Translation/codemixed_parallel_corpus/English-Hindi code-mixed parallel corpus.csv\")\n",
    "data_csv = data_csv.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 179859, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 309757},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 740551},\n",
       " 'sentiment_review': {'Hindi': 52821, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35130924, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84599189,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in data_csv.itertuples():\n",
    "    hin_r = tokenizer.encode(sample.Sentence)\n",
    "    english = tokenizer.encode(sample.English_Translation)\n",
    "\n",
    "    total_r_english_tokens+= len(hin_r)\n",
    "    total_english_tokens+= len(english)\n",
    "\n",
    "token_per_language['code_mixed'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_mixed = []\n",
    "hindi_instruction = \"Nirdesh: Diye gaye Hindi vaakya se sabse saman romanised hindi vaakya dhunde. Vaakya: \"\n",
    "english_instruction = \"Instruction: Find the most similar hindi sentence to the given romanised hindi sentence. Sentence: \"\n",
    "\n",
    "def remove_username(sentence):\n",
    "\n",
    "    return \" \".join([word for word in sentence.split() if word[0]!='@'])\n",
    "\n",
    "for (idx, sample) in data_csv.iterrows():\n",
    "\n",
    "\n",
    "    if idx%2==0:\n",
    "        data = {'id': f\"code_mixed_{idx}\",\n",
    "                'source': hindi_instruction + remove_username(sample.iloc[0]),\n",
    "                'target': remove_username(sample.iloc[1])}\n",
    "    else:\n",
    "        data = {'id': f\"code_mixed_{idx}\",\n",
    "                'source': english_instruction + remove_username(sample.iloc[1]),\n",
    "                'target': remove_username(sample.iloc[0])}\n",
    "\n",
    "\n",
    "    code_mixed.append(data)\n",
    "\n",
    "with open(\"Processed_data/code_mixed.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for sample in code_mixed:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: HinGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "data_csv = pd.read_csv(\"Data/Translation/HinGE/HinGE.csv\")\n",
    "data_csv = data_csv.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "      <th>Human-generated Hinglish</th>\n",
       "      <th>WAC</th>\n",
       "      <th>WAC rating1</th>\n",
       "      <th>WAC rating2</th>\n",
       "      <th>PAC</th>\n",
       "      <th>PAC rating1</th>\n",
       "      <th>PAC rating2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It was presented to the Legislative Council in...</td>\n",
       "      <td>इसे 1856 में विधायी परिषद के समक्ष प्रस्तुत कि...</td>\n",
       "      <td>['Ise 1856 mein legislative council ke samaksh...</td>\n",
       "      <td>ise 1856 men legislative council ke samaksh pr...</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>ise 1856 men legislative council ke samaksh pr...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the year 1985-86, the erstwhile Ministry of...</td>\n",
       "      <td>वर्ष 1985-86 में पूर्ववर्ती कल्याण मंत्रालय को...</td>\n",
       "      <td>['In the year 1985-86, purvarti kalyan mantral...</td>\n",
       "      <td>year 1985-86 men poorvavarti welfare ministry ...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>year 1985-86 men poorvavarti kalyan mntralay k...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Connecting to the server, please wait...</td>\n",
       "      <td>सर्वर से कनेक्ट कर रहा है, कृपया इंतजार करें...</td>\n",
       "      <td>['Connecting to the server, kripya intezaar ka...</td>\n",
       "      <td>server se kanekt kar raha hai , wait intjar karen</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>server se connecting kar raha hai, kripya wait...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English  \\\n",
       "0  It was presented to the Legislative Council in...   \n",
       "1  In the year 1985-86, the erstwhile Ministry of...   \n",
       "2           Connecting to the server, please wait...   \n",
       "\n",
       "                                               Hindi  \\\n",
       "0  इसे 1856 में विधायी परिषद के समक्ष प्रस्तुत कि...   \n",
       "1  वर्ष 1985-86 में पूर्ववर्ती कल्याण मंत्रालय को...   \n",
       "2   सर्वर से कनेक्ट कर रहा है, कृपया इंतजार करें...    \n",
       "\n",
       "                            Human-generated Hinglish  \\\n",
       "0  ['Ise 1856 mein legislative council ke samaksh...   \n",
       "1  ['In the year 1985-86, purvarti kalyan mantral...   \n",
       "2  ['Connecting to the server, kripya intezaar ka...   \n",
       "\n",
       "                                                 WAC  WAC rating1  \\\n",
       "0  ise 1856 men legislative council ke samaksh pr...            9   \n",
       "1  year 1985-86 men poorvavarti welfare ministry ...           10   \n",
       "2  server se kanekt kar raha hai , wait intjar karen            5   \n",
       "\n",
       "   WAC rating2                                                PAC  \\\n",
       "0            6  ise 1856 men legislative council ke samaksh pr...   \n",
       "1            4  year 1985-86 men poorvavarti kalyan mntralay k...   \n",
       "2            5  server se connecting kar raha hai, kripya wait...   \n",
       "\n",
       "   PAC rating1  PAC rating2  \n",
       "0            9            8  \n",
       "1           10           10  \n",
       "2            9            9  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 179859, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 309757},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 740551},\n",
       " 'sentiment_review': {'Hindi': 52821, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35130924, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84599189,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in data_csv.itertuples():\n",
    "    hindi = tokenizer.encode(sample.Hindi)\n",
    "    english = tokenizer.encode(sample.English)\n",
    "\n",
    "    total_hindi_tokens+= len(hindi)\n",
    "    total_english_tokens+= len(english)\n",
    "\n",
    "token_per_language['hinge'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinge = []\n",
    "englishr_instruction = \"Instruction: From the given English sentence, find the translated romanised Hindi sentence. Sentence: \"\n",
    "hindi_instruction = \"निर्देश: दिए गए हिंदी वाक्य में से अनुवादित रोमनकृत हिंदी वाक्य चुनिए। वाक्य: \"\n",
    "hindir_instruction = \"Nirdesh: Diye gaye romanised hindi vaakya se sabse saman hindi vaakya dhunde. Vaakya: \"\n",
    "hindire_instruction = \"Nirdesh: Diye gaye romanised hindi vaakya se sabse saman english vaakya dhunde. Vaakya: \"\n",
    "\n",
    "\n",
    "for (idx, sample) in data_csv.iterrows():\n",
    "\n",
    "    if len(re.findall(r\"'(.*?)'\", sample.iloc[2]))==0:\n",
    "        continue\n",
    "    if idx%2==0:\n",
    "        data1 = {'id': f\"hinge_{idx}\",\n",
    "                'source': hindi_instruction + sample.iloc[1],\n",
    "                'target': re.findall(r\"'(.*?)'\", sample.iloc[2])[0]}\n",
    "        hinge.append(data1)\n",
    "        data2 = {'id': f\"hinge_{idx}\",\n",
    "                'source': hindir_instruction + re.findall(r\"'(.*?)'\", sample.iloc[2])[0],\n",
    "                'target': sample.iloc[1]}\n",
    "        hinge.append(data2)\n",
    "\n",
    "    else:\n",
    "        data1 = {'id': f\"hinge_{idx}\",\n",
    "                'source': hindire_instruction + re.findall(r\"'(.*?)'\", sample.iloc[2])[0],\n",
    "                'target': sample.iloc[1]}\n",
    "        hinge.append(data1)\n",
    "        data2 = {'id': f\"hinge_{idx}\",\n",
    "                'source': englishr_instruction + sample.iloc[0],\n",
    "                'target': re.findall(r\"'(.*?)'\", sample.iloc[2])[0]}\n",
    "        hinge.append(data2)\n",
    "    \n",
    "\n",
    "\n",
    "    hinge.append(data)\n",
    "\n",
    "with open(\"Processed_data/hinge.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for sample in hinge:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5925"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hinge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: IndicQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Data/Retrieval/IndicQA/indicqa.hi.json\", 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '',\n",
       " 'paragraphs': [{'context': '1 और 2 शताब्दी के दौरान दक्षिणी भारत के चेरस, चोल और पांडिओं के रोमन मिस्र और तमिल राज्यों के बीच विकसित गहन व्यापार संबंध थे। ऊपर इंडोनेशियाई लोगों की तरह, पश्चिमी नाविकों ने समुद्र पार करने के लिए मानसून का इस्तेमाल किया एरिथ्रेअन सागर के पेरिप्लस के अज्ञात लेखक इस मार्ग का वर्णन करता है, साथ ही साथ वस्तुओं के अफ्रीका और भारत लगभग 1 सीई के किनारे पर विभिन्न वाणिज्यिक बंदरगाहों के साथ व्यापार किया गया था। इन व्यापारिक बस्तियों में लाल सागर तट पर मोसीलोन और ओपन थे। प्रशांत महासागर के विपरीत जहां पॉलिनेशिया की सभ्यता दूर-दूर तक द्वीपों और एटोल पर पहुंच गई थी और उनसे आबादी हुई थी, औपनिवेशिक काल तक लगभग सभी द्वीपों, आर्चिपेलॅगो और हिंद महासागर के एंटोल्स निर्जन थे। यद्यपि एशिया के तटीय राज्यों और अफ्रीका के कुछ हिस्सों में कई प्राचीन सभ्यताएं थीं, लेकिन मालदीव केंद्रीय भारतीय महासागर क्षेत्र में एकमात्र द्वीप समूह थे जहां एक प्राचीन सभ्यता विकसित हुई थी। मालदीव के जहाजों ने पास के तटों की यात्रा करने के लिए भारतीय मॉनसून चालू का इस्तेमाल किया। 1405 से 1433 तक एडमिरल झेंग ने हिंद महासागर के माध्यम से कई खजाने यात्राओं पर अंततः अंततः पूर्वी अफ्रीका के तटीय देशों तक पहुंचने वाले मिंग राजवंश के बड़े बेड़े का नेतृत्व किया। 1497 में पुर्तगाली नाविक वास्को द गामा ने केप ऑफ गुड होप को गोल कर दिया और भारत के लिए पाल करने वाले पहले यूरोपीय और बाद में सुदूर पूर्व बन गए। यूरोपीय जहाजों, भारी तोप से सशस्त्र, जल्दी व्यापार पर हावी। पुर्तगाल ने महत्वपूर्ण जलडमरूमध्य और बंदरगाहों पर किलों की स्थापना के द्वारा श्रेष्ठता प्राप्त की। अफ्रीका और एशिया के तट के साथ उनकी आधिकारिकता 17 वीं सदी के मध्य तक चली। बाद में, पुर्तगाली को अन्य यूरोपीय शक्तियों द्वारा चुनौती दी गई थी डच ईस्ट इंडिया कंपनी (1602-1798) ने हिंद महासागर के पार ईस्ट के साथ व्यापार पर नियंत्रण की मांग की। फ्रांस और ब्रिटेन ने क्षेत्र के लिए व्यापारिक कंपनियों की स्थापना की।',\n",
       "   'qas': [{'id': 15,\n",
       "     'category': 'NO',\n",
       "     'question': 'स्पेन ने फिलीपींस और प्रशांत क्षेत्र में मनीला गैलिंस के साथ व्यापारिक अभियान की स्थापना कब की थी ?',\n",
       "     'answers': [{'text': '', 'answer_start': None}]},\n",
       "    {'id': 16,\n",
       "     'category': 'SHORT',\n",
       "     'question': 'पुर्तगाली नाविक वास्को डी गामा ने केप का स्कोर किस वर्ष बनाया था ?',\n",
       "     'answers': [{'text': '1497 ', 'answer_start': 1126}]},\n",
       "    {'id': 17,\n",
       "     'category': 'NO',\n",
       "     'question': 'ब्रिटेन हिंद महासागर में किस वर्ष तक प्रमुख शक्ति बन गया था ?',\n",
       "     'answers': [{'text': '', 'answer_start': None}]},\n",
       "    {'id': 18,\n",
       "     'category': 'SHORT',\n",
       "     'question': 'पश्चिमी नाविकों ने समुद्र पार करने के लिए किसका का इस्तेमाल किया था ?',\n",
       "     'answers': [{'text': 'मानसून ', 'answer_start': 198}]},\n",
       "    {'id': 19,\n",
       "     'category': 'SHORT',\n",
       "     'question': 'मध्य हिंद महासागर क्षेत्र में एकमात्र द्वीप का नाम क्या था ?',\n",
       "     'answers': [{'text': 'मालदीव', 'answer_start': 757}]},\n",
       "    {'id': 20,\n",
       "     'category': 'SHORT',\n",
       "     'question': 'दक्षिणी भारत के चेरों, चोल और पांड्यों के साथ रोमन मिस्र और तमिल साम्राज्यों का व्यापारिक संबंध किस शताब्दी में अत्यधिक था ?',\n",
       "     'answers': [{'text': '1 और 2 शताब्दी', 'answer_start': 0}]},\n",
       "    {'id': 21,\n",
       "     'category': 'SHORT',\n",
       "     'question': 'अफ्रीका और भारत विभिन्न वाणिज्यिक बंदरगाहों के साथ माल का व्यापार किस शताब्दी से किया करते थे ?',\n",
       "     'answers': [{'text': '1 सीई ', 'answer_start': 334}]}]}]}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list = set([sample['paragraphs'][0]['context'] for sample in data['data']])\n",
    "context_dict = {context: idx for idx, context in enumerate(context_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 192,\n",
       "  'category': 'NO',\n",
       "  'question': 'पुराणों के अनुसार नंद वंश को किसके वंश में गिना जाता था?',\n",
       "  'answers': [{'text': '', 'answer_start': None}]},\n",
       " {'id': 193,\n",
       "  'category': 'SHORT',\n",
       "  'question': 'नंदवंश के राजा किस वर्ण से संबंधित थे?',\n",
       "  'answers': [{'text': 'न्यायी क्षत्रिय', 'answer_start': 667}]},\n",
       " {'id': 194,\n",
       "  'category': 'SHORT',\n",
       "  'question': 'नंद सेना में कितने घुड़सवार थे?',\n",
       "  'answers': [{'text': '20 हजार ', 'answer_start': 1175}]},\n",
       " {'id': 195,\n",
       "  'category': 'SHORT',\n",
       "  'question': 'नंद सेना में कितने पैदल सैनिक थे?',\n",
       "  'answers': [{'text': 'दो लाख पैदल', 'answer_start': 1162}]},\n",
       " {'id': 196,\n",
       "  'category': 'SHORT',\n",
       "  'question': 'किन ग्रंथों से पता चलता है कि महापद्मानंद की रानी बहुत सुंदर थी?',\n",
       "  'answers': [{'text': 'जैन और बौद्ध ग्रंथों', 'answer_start': 41}]}]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][34]['paragraphs'][0]['qas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicqa = []\n",
    "\n",
    "instruction = \"निर्देश: दिए गए प्रश्न के आधार पर उपलब्ध विकल्पों में से सबसे प्रासंगिक गद्यांश चुनिए। प्रश्न: \"\n",
    "\n",
    "for sample in data['data']:\n",
    "\n",
    "    \n",
    "    context = sample['paragraphs'][0]['context']\n",
    "\n",
    "    for qas in sample['paragraphs'][0]['qas']:\n",
    "\n",
    "        if qas['category'] == 'No':\n",
    "            continue\n",
    "        indicqa.append({\n",
    "            'id': f\"indicqa_{context_dict[context]}\",\n",
    "            'source': instruction + qas['question'],\n",
    "            'target': context\n",
    "        })\n",
    "\n",
    "random.shuffle(indicqa)\n",
    "\n",
    "with open(f\"Processed_data/indicqa.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in indicqa:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 179859, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 5932809, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 309757},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 740551},\n",
       " 'sentiment_review': {'Hindi': 52821, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35130924, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84599189,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in indicqa:\n",
    "    hin_1 = tokenizer.encode(sample['source'])\n",
    "    hin_2 = tokenizer.encode(sample['target'])\n",
    "\n",
    "    total_hindi_tokens+= len(hin_1)\n",
    "    total_hindi_tokens+= len(hin_2)\n",
    "\n",
    "token_per_language['indicqa'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: MLDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(\"./Data/Retrieval/MLDR/test.jsonl\", \"r\") as f:\n",
    "\n",
    "    for sample in f:\n",
    "        data.append(json.loads(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_passage = []\n",
    "negative_passage = []\n",
    "\n",
    "for sample in data:\n",
    "    for pp in sample['positive_passages']:\n",
    "        positive_passage.append(pp['text'])\n",
    "    for np in sample['negative_passages']:\n",
    "        negative_passage.append(np['text'])\n",
    "\n",
    "positive_passage = set(positive_passage)\n",
    "negative_passage = set(negative_passage)\n",
    "\n",
    "pp_dict = {passage: idx for idx, passage in enumerate(positive_passage)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_id': 'q-hi-1',\n",
       " 'query': 'आप कृपया बताएं, जब आप कहते हैं \"विशुद्ध शस्त्र\", तो आप किस अर्थ में इस्तेमाल कर रहे हैं?',\n",
       " 'positive_passages': [{'docid': 'doc-hi-8',\n",
       "   'text': \"शब्दकोश\\nपुनर्निर्देशित हिन्दू धर्म की शब्दावली \\n\\nशब्दकोश (अन्य वर्तनी: शब्दकोष) एक बडी सूची या ऐसा ग्रन्थ जिसमें शब्दों की वर्तनी, उनकी व्युत्पत्ति, व्याकरणनिर्देश, अर्थ, परिभाषा, प्रयोग और पदार्थ आदि का सन्निवेश हो। शब्दकोश एकभाषीय हो सकते हैं, द्विभाषिक हो सकते हैं या बहुभाषिक हो सकते हैं। अधिकतर शब्दकोशों में शब्दों के उच्चारण के लिये भी व्यवस्था होती है, जैसे - अन्तरराष्ट्रीय ध्वन्यात्मक लिपि में, देवनागरी में या आडियो संचिका के रूप में। कुछ शब्दकोशों में चित्रों का सहारा भी लिया जाता है। अलग-अलग कार्य-क्षेत्रों के लिये अलग-अलग शब्दकोश हो सकते हैं; जैसे - विज्ञान शब्दकोश, चिकित्सा शब्दकोश, विधिक (कानूनी) शब्दकोश, गणित का शब्दकोश आदि।\\n\\nसभ्यता और संस्कृति के उदय से ही मानव जान गया था कि भाव के सही सम्प्रेषण के लिए सही अभिव्यक्ति आवश्यक है। सही अभिव्यक्ति के लिए सही शब्द का चयन आवश्यक है। सही शब्द के चयन के लिए शब्दों के संकलन आवश्यक हैं। शब्दों और भाषा के मानकीकरण की आवश्यकता समझ कर आरम्भिक लिपियों के उदय से बहुत पहले ही आदमी ने शब्दों का लेखाजोखा रखना शुरू कर दिया था। इस के लिए उस ने कोश बनाना शुरू किया। कोश में शब्दों को इकट्ठा किया जाता है।\\n\\nइतिहास \\n\\nसब से पहले शब्द संकलन भारत में बने। भारत की यह शानदार परम्परा वेदों जितनी—कम से कम पाँच हजार वर्ष—पुरानी है। प्रजापति कश्यप का निघण्टु संसार का प्राचीनतम शब्द संकलन है। इस में 18 सौ वैदिक शब्दों को इकट्ठा किया गया है। निघण्टु पर महर्षि यास्क की व्याख्या निरुक्त संसार का पहला शब्दार्थ कोश (डिक्शनरी) एवं विश्वकोश (ऐनसाइक्लोपीडिया) है। इस महान शृंखला की सशक्त कड़ी है छठी या सातवीं सदी में लिखा अमर सिंह कृत नामलिंगानुशासन या त्रिकाण्ड जिसे सारा संसार 'अमरकोश' के नाम से जानता है। अमरकोश को विश्व का सर्वप्रथम समान्तर कोश (थेसेरस) कहा जा सकता है।\\n\\nभारत के बाहर संसार में शब्द संकलन का एक प्राचीन प्रयास अक्कादियाई संस्कृति की शब्द सूची है। यह शायद ईसा पूर्व सातवीं सदी की रचना है। ईसा से तीसरी सदी पहले की चीनी भाषा का कोश है 'ईर्या'।\\n\\nआधुनिक कोशों की नींव डाली इंग्लैंड में 1755 में सैमुएल जानसन ने। उन की डिक्शनरी सैमुएल जॉन्संस डिक्शनरी ऑफ़ इंग्लिश लैंग्वेज ने कोशकारिता को नए आयाम दिए। इस में परिभाषाएँ भी दी गई थीं। असली आधुनिक कोश आया इक्यावन वर्ष बाद 1806 में अमरीका में नोहा वैब्स्टर्स की नोहा वैब्स्टर्स ए कंपैंडियस डिक्शनरी आफ़ इंग्लिश लैंग्वेज प्रकाशित हुई। इस ने जो स्तर स्थापित किया वह पहले कभी नहीं हुआ था। साहित्यिक शब्दावली के साथ साथ कला और विज्ञान क्षेत्रों को स्थान दिया गया था। कोश को सफल होना ही था, हुआ। वैब्स्टर के बाद अंग्रेजी कोशों के संशोधन और नए कोशों के प्रकाशन का व्यवसाय तेजी से बढ़ने लगा।\\n\\nआधुनिक कोश की विधाएँ \\nवर्तमान युग ने कोशविद्या को अत्यन्त व्यापक परिवेश में विकसित किया। सामान्य रूप से उसकी दो मोटी-मोटी विधाएँ कही जा सकती हैं - (1) शब्दकोश और (2) ज्ञानकोश। शब्दकोश के स्वरूप का बहुमुखी प्रवाह निरंतर प्रौढ़ता की ओर बढ़ता लक्षित होता रहा है। आज की कोशविद्या का विकसित स्वरूप भाषा विज्ञान, व्याकरणशास्त्र, साहित्य, अर्थविज्ञान, शब्दप्रयोगीय, ऐतिहासिक विकास, सन्दर्भसापेक्ष अर्थविकास और नाना शास्त्रों तथा विज्ञानों में प्रयुक्त विशिष्ट अर्थों के बौद्धिक और जागरूक शब्दार्थ संकलन का पुंजीकृत परिणाम है।\\n\\nशब्दकोश \\nहमारे परिचित भाषाओं के कोशों में ऑक्सफोर्ड-इंग्लिश-डिक्शनरी के परिशीलन में उपर्युक्त समस्त प्रवृत्तियों का उत्कृष्ट निदर्शन देखा जा सकता है। उसमें शब्दों के सही उच्चारण का संकेत-चिह्नों से विशुद्ध और परिनिष्ठित बोध भी कराया है। योरप के उन्नत और समृद्ध देशों की प्रायः सभी भाषाओं में विकासित स्तर की कोशविद्या के आधार पर उत्कृष्ट, विशाल, प्रमाणिक और सम्पन्न कोशों का निर्माण हो चुका है और उन दोशों में कोशनिर्माण के लिये ऐसे स्थायी संस्थान प्रतिष्ठापित किए जा चुके हैं जिनमें अबाध गति से सर्वदा कार्य चलता रहता है। लब्धप्रतिष्ठा और बडे़-बडे़ विद्वानों का सहयोग तो उन संस्थानों को मिलता ही है, जागरूक जनता भी सहयोग देती है। अंग्रेजी डिक्शनरी तथा अन्य भाषाओं में निर्मित कोशकारों के रचना-विधान-मूलक वैशिष्टयों का अध्ययन करने से अद्यतन कोशों में निम्ननिर्दिष्ट बातों का अनुयोग आवश्यक लगता है—\\n\\n क) उच्चाणमसूचक संकेतचिह्नों के माध्यम से शब्दों के स्वरों व्यंजनों का पूर्णतः शुद्ध और परिनिष्ठित उच्चारण स्वरूप बताना और स्वराघात बलगात का निर्देश करते हुए यतासम्भव उच्चार्य अंश के अक्षरों की बद्धता और अबद्धता का परिचय देना;\\n\\n ख) व्याकरण संबंद्ध उपयोगी और आवश्यक निर्देश देना;\\n\\n ग) शब्दों की इतिहास- संबंद्ध वैज्ञानिक—व्युत्पत्ति प्रदर्शित करना;\\n\\n घ) परिवार—संबंद्ध अथवा परिवारमुक्त निकट या दूर के शब्दों के साथ शब्दरूप और अर्थरूप का तुलनात्मक पक्ष उपस्थित करना;\\n\\n ङ) शब्दों के विभिन्न और पृथक्कृत नाना अर्थों को अधिक—न्यून प्रयोग क्रमानुसार सूचित करना;\\n\\n च) अप्रयुक्त-शब्दो अथवा शब्दप्रयोगों की विलोपसूचना देना;\\n\\n छ) शब्दों के पर्याय बताना; और\\n\\n ज) संगत अर्थों के समर्थनार्थ उदाहरण देना;\\n\\n झ) चित्रों, रेखाचित्रों, मानचित्रों आदि के द्वारा अर्थ को अधिक स्पष्ट करना।\\n\\n'आक्सफोर्ड इंग्लिश डिक्शनरी' का नव्यतम और बृहत्तम संस्करण आधुनिक कोशविद्या की प्रायः सभी विशेषताओं से संपन्न है। नागरीप्रचारिणी सभा के हिंदी शब्दसागर के अतिरिक्त हिन्दी साहित्य सम्मेलन द्वारा प्रकाश्यमान मानक शब्दकोश एक विस्तृत आयास है। हिन्दी कोशकला के लब्धप्रतिष्ठ सम्पादक रामचन्द्र वर्मा के इस प्रशंसनीय कार्य का उपजीव्य भी मुख्यातः शब्दसागर ही है। उसका मूल कलेवर तात्विक रूप में शब्दसागर से ही अधिकांशतः परिकलित है। हिन्दी के अन्य कोशों में भी अधिकांश सामग्री इसी कोश से ली गयी है। थोडे-बहुत मुख्यतः संस्कृत कोशों से और यदा-कदा अन्यत्र से शब्दों और अर्थों को आवश्यक अनावश्यक रूप में ठूँस दिया गया है। ज्ञानमण्डल के बृहद् हिन्दी शब्दकोश में पेटेवाली प्रणाली शुरू की गई है। परन्तु वह पद्धति संस्कृत के कोशों में जिनका निर्माण पश्चिमी विद्वानों के प्रयास से आरम्भ हुआ था, सैकड़ो वर्ष पूर्व से प्रचलित हो गई थी। पर आज भी, नव्य या आधुनिक भारतीय भाषाओं के कोश उस स्तर तक नहीं पहुँच पाए हैं जहाँ तक आक्सफोर्ड इंग्लिश डिक्शनरी अथवा रूसी, अमेरिकन, जर्मन, इताली, फ़्रांसीसी आदि भाषाओं के उत्कृष्ट और अत्यन्त विकसित कोश पहुँच चुके हैं।\\n\\nकोशरचना की ऊपर वर्णित विधा को हम साधारणतः सामान्य भाषा शब्दकोश कह सकते हैं। इस प्रकार शब्दकोश एकभाषी, द्विभाषी, त्रिभाषी और बहुभाषी भी होते हैं। बहुभाषी शब्दकोशों में तुलनात्मक शब्दकोश भी यूरोपीय भाषाओं में ऐतिहासिक और तुलनात्मक भाषाविज्ञान की प्रौढ़ उपलब्धियों से प्रमाणीकृत रूप में निर्मित हो चुके हैं। इनमें मुख्य रूप से भाषावैज्ञानिक अनुशीलन और शोध के परिणामस्वरूप उपलब्ध सामग्री का नियोजन किया गया है। ऐसे तुलनात्मक कोश भी आज बन चुके हैं जिनमें प्राचीन भाषाओं की तुलना मिलती है। ऐसे भी कोश प्रकाशित हैं जिनमें एक से अधिक मुल परिवार की अनेक भाषाओं के शब्दों का तुलनात्मक परिशीलन किया गया है।\\n\\nशब्दकोशों के नाना रूप \\nशब्दकोशों के और भी नाना रूप आज विकसित हो चुके हैं और हो रहे हैं। वैज्ञानिक और शास्त्रीय विषयों के सामूहिक और उस-उस विषय के अनुसार शब्दकोश भी आज सभी समृद्ध भाषाओं में बनते जा रहे हैं। शास्त्रों और विज्ञानशाखाओं के परिभाषिक शब्दकोश भी निर्मित हो चुके हैं और हो रहे हैं। इन शब्दकोशों की रचना एक भाषा में भी होती है और दो या अनेक भाषाओं में भी। कुछ में केवल पर्याय शब्द रहते हैं और कुछ में व्याख्याएँ अथवा परिभाषाएँ भी दी जाती है। विज्ञान और तकनीकी या प्रविधिक विषयों से संबद्ध नाना पारिभाषिक शब्दकोशों में व्याख्यात्मक परिभाषाओं तथा कभी कभी अन्य साधनों की सहायता से भी बिलकुल सही अर्थ का बोध कराया जाता है। दर्शन, भाषाविज्ञान, मनोविज्ञान, समाजविज्ञान और समाजशास्त्र, राजनीतिशास्त्र, अर्थशास्त्र आदि समस्त आधुनिक विद्याओं के कोश विश्व की विविध सम्पन्न भाषाओं में विशेषज्ञों की सहायता से बनाए जा रहे हैं और इस प्रकृति के सैकडों-हजारों कोश भी बन चुके हैं। शब्दार्थकोश सम्बन्धी प्रकृति के अतिरिक्त इनमें ज्ञानकोशात्मक तत्वों की विस्तृत या लघु व्याख्याएँ भी संमिश्रित रहती है। प्राचीन शास्त्रों और दर्शनों आदि के विशिष्ट एवं पारिभाषिक शब्दों के कोश भी बने हैं और बनाए जा रहे हैं। अनके अतिरिक्त एक-एक ग्रन्थ के शब्दार्थ कोश (यथा मानस शब्दावली) और एक-एक लेखक के साहित्य की शब्दावली भी योरप, अमेरिका और भारत आदि में संकलित हो रही है। इनमें उत्तम कोटि के कोशकारों ने ग्रन्थसन्दर्भों के संस्करणात्मक संकेत भी दिए हैं। अकारादि वर्णानुसारी अनुक्रमणिकात्मक उन शब्दसूचियों का—जिनके अर्थ नहीं दिए जाते हैं पर सन्दर्भसंकेत रहता हैं—यहाँ उल्लेख आवश्यक नहीं है। योरप और इंगलैड में ऐसी शब्दसूचियाँ अनेक बनीं। शेक्सपियर द्वारा प्रयुक्त शब्दों की ऐसी अनुक्रमणिका परम प्रसिद्ध है। वैदिक शब्दों की और ऋक्संहिता में प्रयुक्त पदों की ऐसी शब्दसूचियों के अनेक संकलन पहले ही बन चुके हैं। व्याकरण महाभाष्य की भी एक एक ऐसी शब्दानुक्रमणिका प्रकाशित है। परन्तु इनमें अर्थ न होने के कारण यहाँ उनका विवेचन नहीं किया जा रहा है।\\n\\nज्ञानकोश \\nकोश की एक दूसरी विधा ज्ञानकोश भी विकसित हुई है। इसके वृहत्तम और उत्कष्ट रूप को इन्साइक्लोपिडिया कहा गया है। हिन्दी में इसके लिये विश्वकोश शब्द प्रयुक्त और गृहीत हो गया है। यह शब्द बँगाल विश्वकोशकार ने कदाचित् सर्वप्रथम बंगाल के ज्ञानकोश के लिये प्रयुक्त किया। उसका एक हिन्दी संस्करण हिन्दी विश्वकोश के नाम से नए सिरे से प्रकाशित हुआ। हिन्दी में यह शब्द प्रयुक्त होने लगा है। यद्यपि हिन्दी के प्रथम किशोरोपयोगी ज्ञानकोश (अपूर्ण) को श्री श्रीनारायण चतुर्वेदी तथा पं० कृष्ण वल्लभ द्विवेदि द्वारा विश्वभारती अभिधान दिया गया तो भी ज्ञान कोश, ज्ञानदीपिका, विश्वदर्शन, विश्वविद्यालयभण्डार आदि संज्ञाओं का प्रयोग भी ज्ञानकोश के लिये हुआ है। स्वयं सरकार भी बालशिक्षोपयोगी ज्ञानकोशात्मक ग्रन्थ का प्रकाशन 'ज्ञानसरोवर' नाम से कर रही है। परन्तु इन्साइक्लोपीडिया के अनुवाद रूप में विवकोश शब्द ही प्रचलित हो गया। उडीया के एक विश्वकोश का नाम शब्दार्थानुवाद के अनुसार ज्ञान मण्डल रखा भी गया। ऐसा लगता है कि बृहद् परिवेश के व्यापक ज्ञान का परिभाषिक और विशिष्ट शब्दों के माध्यम से ज्ञान देनेवाले ग्रन्थ का इन्साइक्लोपीडिया या विश्वकोश अभिधान निर्धारित हुआ और अपेक्षाकृत लघुतरकोशों को ज्ञानकोश आदि विभिन्न नाम दिए गए। अंग्रेजी आदि भाषाओं में बुक ऑफ़ नालेज, डिक्शनरी आव जनरल नालेज आदि शीर्षकों के अन्तर्गत नाना प्रकार के छोटे बडे विश्वकोश अथवा ज्ञानकोश बने हैं और आज भी निरन्तर प्रकाशित एवं विकसित होते जा रहे हैं। इतना ही नहीं इन्साइक्लोपीडिया ऑफ़ रिलीजन ऐण्ड एथिक्स आदि विषयविशेष से संबंद्ध विश्वकोशों की संख्या भी बहुत ही बडी है। अंग्रेजी भाषा के माध्यम से निर्मित अनेक सामान्य विश्वकोश और विशष विश्वकोश भी आज उपलब्ध हैं।\\n\\nइन्साइक्लोपीडिया ब्रिटानिका, इन्साइक्लोपीडिया अमेरिकाना अंग्रेजी के ऐसे विश्वकोश हैं। अंग्रेजी के सामान्य विश्वकोशों द्वारा इनकी प्रमाणिकता और संमान्यता सर्वस्वीकृत है। निरन्तर इनके संशोधित, संवर्धित तथा परिष्कृत संस्करण निकलते रहते हैं। इन्साइक्लोपीडिया ब्रिटानिका के दो परिशिष्ट ग्रन्थ भी हैं जो प्रकाशित होते रहते हैं और जो नूतन संस्करण की सामग्री के रूप में सातत्य भाव से संकलित होते रहते हैं। इंग्लैंड में इन्साइक्लोपीडिया के पहले से ही ज्ञानकोशात्मक कोशों के नाना रूप बनने लगे थे।\\n\\nज्ञानकोशों के नाना प्रकार \\nज्ञानकोशों के भी इतने अधिक प्रकार और पद्धतियाँ हैं जिनकी चर्चा का यहाँ अवसर नहीं है। चरितकोश, कथाकोश इतिहासकोश, ऐतिहासिक कालकोश, जीवनचरितकोश पुराख्यानकोश, पौराणिक- ख्यातपुरुषकोश आदि आदि प्रकार के विविध नामरूपात्मक ज्ञानकोशों की बहुत सी विधाएँ विकसित और प्रचलित हो चुकी हैं। यहाँ प्रसंगतः ज्ञानकोशों का संकेतात्मक नामनिर्देश मात्र कर दिया जा रहा है। हम इस प्रसंग को यहीं समाप्त करते हैं और शब्दर्थकोश से संबंद्ध प्रकृत विषय की चर्चा पर लौट आते हैं।\\n\\nआधुनिक कोशविद्या : तुलनात्मक दृष्टि \\nभारत में कोशविद्या के आधुनिक स्वरुप का उद्भव और विकास मध्यकालीन हिंदी कोशों की मान्यता और रचनाप्रक्रिया से भिन्न उद्देश्यों को लेकर हुआ। पाश्चात्य कोशों के आदर्श, मान्यताएँ, उद्देश्य, रचनाप्रक्रिया और सीमा के नूतन और परिवर्तित आयामों का प्रवेश भारत की कोश रचनापद्धति में आरंभ हुआ। संस्कृत और इतर भारतीय भाषाओं में पाश्चात्य तथा भारतीय विद्वानों के प्रयास से छोटे-बडे बहुत से कोश निर्मित हुए। इन कोशों का भारत और भारत के बाहर भी निर्माण हुआ। आरंभ में भारतीय भाषाओं के, मुख्यतः संस्कृत के कोश अंग्रेजी, जर्मन, फ्रेंच आदि भाषाओं के माध्यम से बनाए गए। इनमें संस्कृत आदि के शब्द भी रोमन लिपि में रखे गए। शब्दार्थ की व्याख्या और अर्थ आदि के निर्देश कोश की भाषा के अनुसार जर्मन, अंग्रेजी, फारसी, पुर्तगाली आदि भाषाओं में दिए गए। बँगला, तमिल आदि भाषाओं के ऐसे अनके काशों की रचना ईसाई धर्मप्रचारकों द्वारा भारत और आसपास के लघु द्वीपों में हुई। हिंदी के भी ऐसे अनेक कोश बने। सबसे पहला शब्दकोश संभवतः फरग्युमन का 'हिंदुस्तानी अंग्रेजी' (अंग्रेजी हिंदुस्तानी) कोश था जो १७७३ ई० में लंदन में प्रकाशित हुआ। इन आरंभिक कोशों को 'हिंदुस्तानी कोश' कहा गया। ये कोश मुख्यतः हिंदी के ही थे। पाश्चात्य विद्वानों के इन कोशों में हिंदी को हिंदुस्तानी कहने का कदाचित् यह कारण है कि हिंदुस्तान भारत का नाम माना गया और वहाँ की भाषा हिंदुस्तानी कही गई। कोशविद्या के इन पाश्चात्य पंडितों की दृष्टि में हिंदी का ही पर्याय हिंदुस्तानी था और वही सामान्य रूप में हिंदुस्तान की राष्ट्रभाषा थी।\\n\\nआरंभिक क्रम में कोशनिर्माण की प्रेरणात्मक चेतना का बहुत कुछ सामान्य रूप भारत और पश्चिम में मिलता जुलता था। भारत का वैदिक निघंटु विरल और क्लिष्ट शब्दों के अर्थ और पर्यायों का संक्षिप्त संग्रह था। योरप में भी ग्लासेरिया से जिस कोशविद्या का आरंभिक बीजवपन हुआ था, उसके मूल में भई विरल और क्लिष्ट शब्दों का पर्याय द्वारा अर्थबोध कराना ही उद्देश्य था। लातिन की उक्त शब्दार्थसूची से शनैः शनैः पश्चिम की आधुनिक कोशविद्या के वैकासिक सोपान आविर्भूत हुए। भारत और पश्चिम दोनों ही स्थानों में शब्दों के सकलन में वर्गपद्धति का कोई न कोई रूप मिल जाता है। पर आगे चलकर नव्य कोशों का पूर्वोंक्त प्राचीन और मध्यकालीन कोशों से जो सर्वप्रथम और प्रमुखतम भेदक वैशिष्टय प्रकट हुआ वह था - 'वर्णमालाक्रमानुसारी शब्दयोजना' की पद्धति।\\n\\nआधुनिक कोश: सीमा और स्वरूप \\nयोरप में आधुनिक कोशों का जो स्वरूप विकसित हुआ, उसकी रूपरेखा का संकेत ऊपर किया जा चुका है। योरप, एशिया और अफ्रिका के उस तटभाग में जो अरब देशों के प्रभाव में आया था, उक्त पद्धति के अनुकरण पर कोशों का निर्माण होने लगा था। भारत में व्यापक पैमाने पर जिस रूप में कोश निर्मत होते चले, उनकी संक्षिप्त चर्चा की जा चुकी है। इन सबके आधार पर उत्तम कोटि के आधुनिक कोशों की विशिषिटताओं का आकलन करते हुए कहा जा सकता है कि:\\n\\n(क) आधुनिक कोशों में शब्दप्रयोग के ऐतिहाससिक क्रम की सरणि दिखाने के प्रयास को बहुत महत्व दिया गया है। ऐसे कोर्शो को ऐतिहासिक विवरणात्मक कहा जा सकता है। उपलब्ध प्रथम प्रयोग और प्रयोगसंदर्भ का आधार लेकर अर्थ और उनके एकमुखी या बहुमुखी विकास के सप्रमाण उपस्थापन की चेष्टा की जाती है। दूसरे शब्दों में इसे हम शब्दप्रयोग और तद्बोध्यार्थ के रूप की आनुक्रमिक या इतिहासानुसारी विवेचना कह सकते है। इसमें उद्वरणों का उपयोग दोनों ही बातों (शब्दप्रयोग और अर्थविकास) की प्रमाणिकता सिद्ध करते हैं।\\n(ख) आधुनिक कोशकार के द्वार संगृहीत शब्दों और अर्थों के आधार का प्रामाण्य भी अपेक्षित होता है। प्राचीन कोशकार इसके लिये बाध्य नहीं था। वह स्वत: प्रमाण समझा जाता था। पूर्व तंत्रों या ग्रंथों का समाहार करते हुए यदाकदा इतना भी कह देना उसके लिये बहुधा पर्याप्त हो जाता था। पर आधुनिक कोशों में ऐसे शब्दों के संबंध में जिनका साहित्य व्यवहार में प्रयोग नहीं मिलता, यह बताना भी आवश्यक हो जाता है कि अमुक शब्द या अर्थ कोशीय मात्र हैं।\\n(ग) आधुनिक कोशों की एक दुसरी नई धारा ज्ञानकोशात्मक है जिनकी उत्कृष्ट रूप 'विश्वकोश' के नाम से सामने आता है। अन्य रूप पारिभाषिक शब्दकोश, विषयकोश, चरितकोश, ज्ञानकोश, अब्दकोश आदि नाना रूपों में अपने आभोग का विस्तार करते चल रहै हैं।\\n(घ) आधुनिक शब्दकोशों मे अर्थ की स्पष्टता के लिये चित्र, रेखा-चित्र, मानचित्र आदि का उपयोग भी किया जाता है।\\n(ङ) विशुद्ध शस्त्रीय वाङमय (शस्त्र) के प्राचीन स्तर से हटकर आज के कोश वैज्ञानिक अथवा विज्ञानकल्प रचनाप्रक्रिया के स्तर पर पहुँच गए। ये कोश रूपविकास और अर्थविकास की ऐतिहासिक प्रमाणिकता के साथ साथ भाषवैज्ञानिक सिद्धांत की संगति ढूँढने का पूर्ण प्रयत्न करते हैं। आधुनिक भाषाओं के तद्भव, देशी और विदेशी शब्दों के मूल और स्रोत ढ़ूँढने की चेष्टा की जाती है। कभी कभी प्राचीन भाषा या भाषाओ के मूलस्रोतों की गवेषण के व्युत्पत्ति-दर्शन के सदर्भ में महत्वपूर्ण प्रयास होता है। बहुभाषी पर्यायकोशों में एतिहासिक और तुलनात्मक भाषाविज्ञान के सहयोग सहायता द्वारा स्रोतभाषा के कल्पनानिदिप्ट रूप अंगीकृत होते हैं। उदाहरणार्थ प्राचीन भारत योरोपी— आर्यभाषा के बहुभाषी तुलनात्मक कोशों में मूल आर्यभाषा (या आर्यों के 'फादर लैंग्वेज') के कल्पित मृलख्वपो का अनुमान किया जाता है। दूसरे शबदो में इसका तात्पर्य यह है कि आधुनिक उत्कृष्ट कोशों में जहां एक ओर प्राचीन और पूर्ववर्ती वाङ्मय का शब्दप्रयोग के क्रमिक ज्ञान के लिये ऐतिहासिक अध्ययन होता है वहां भाषाविज्ञान के ऐतिहासिक, तुलनात्मक और वर्णनात्मक दुष्टिपक्षों का प्रौढ़ सहयोग और विनियोग अपेक्षित रहता है। कोशविज्ञान की नूतन रचानाप्रक्रिया आज के युग में भाषाविज्ञान के नाना अंगों से बहुत ही प्रभावित हो गई है।\\n\\nकोशारचना को प्रक्रिया और भाषाविज्ञान \\nकोशनिर्माण का शब्दसंकलन सर्वप्रमुख आधार है। परन्तु शब्दों के संग्रह का कार्य अत्यत कठिन है। मुख्य रूप में शब्दों का चयन दो स्त्रोतों से होता है -\\n (१) लिखित साहित्य से और \\n (२) लोकव्यवहार और लोकसाहित्य से।\\n\\nलिखित साहित्य से सग्रह्य शब्दों के लिये हस्तलिखित और मुद्रित ग्रंथो का सहारा लिया जाता है। परंतु इसके अंतर्गत प्राचीन हस्तलेखों और मुद्रित ग्रथो के आधार पर जब शब्दसंकलन होता है तब उभयविध आधारग्रंथों की प्रामाणिकता और पाठशुद्धि आवश्यक होती है। इनके बिमा गृहीत शब्दों का महत्व कम हो जाता है और उनसे भ्रमसृष्टि की संभावना बढ़ती है।\\n\\nविविध प्रकार के शब्दकोश \\n\\nआजकल ऐसे कम्प्यूटर प्रोग्राम उपलब्ध हैं जो शब्दकोश के सारे काम करते हैं। वे कागज पर मुद्रित नहीं हैं बल्कि किसी विशिष्ट फाइल-फॉर्मट में हैं और किसी 'डिक्शनरी सॉफ्टवेयर' के द्वारा प्रयोक्ता को शब्दार्थ ढूढने में मदद करते हैं। इनमें कुछ ऐसी सुविधाएँ भी उपलब्ध हैं जो परम्परागत शब्दकोशों में सम्भव ही नहीं है; जैसे शब्द का उच्चारण ध्वनि के माध्यम से देना आदि।\\n\\nशब्दकोशों के कुछ प्रकार ये हैं-\\n सामान्य शब्दकोश\\n विशिष्ट शब्दकोश - गणित, विज्ञान, विधि, प्रौद्योगिकी, चिकित्सा आदि के शब्दकोश\\n पारिभाषिक शब्दकोश - इनमें किसी क्षेत्र (विषय) के प्रमुख शब्दों के संक्षिप्त और मुख्य अर्थ दिए गए होते हैं।\\n प्राकृतिक भाषा संसाधन के लिए शब्दकोश - ये मानव के बजाय किसी कम्प्यूतर प्रोग्राम द्वारा प्रयोग को ध्यान में रखकर बनाई जातीं हैं।\\n अन्य :\\n द्विभाषी शब्दकोश\\n एलेक्ट्रानिक शब्दकोश\\n ज्ञानकोषीय शब्दकोश (Encyclopedic dictionary)\\n बाल शब्दकोश तथा वृहत् शब्दकोश आदि\\n तुकान्त शब्दकोश (Rhyming dictionary)\\n व्युत्क्रम शन्दकोश (Reverse dictionary)\\n सचित्र शब्दकोश (Visual dictionary)\\n\\nगलत\\n\\nइन्हें भी देंखें \\n कोशकर्म\\n समान्तर कोश\\n अमरकोश\\n शब्दकोशों का इतिहास\\n हिन्दी शब्दसागर\\n पारिभाषिक शब्दावली\\n हिन्दी विकि शब्दकोष - विकिपीडिया के बंधु प्रोजाक्ट में से एक है - विक्शनरी, यानी विकि शब्दकोष। कृपया अंग्रेजी से हिन्दी शब्दों की सूची वहाँ बनायें।\\n\\nबाहरी कड़ियाँ \\n शब्दकोश की आत्मकथा (राजस्थान साहित्य अकादमी)\\n हिन्दी एवं विभिन्न भाषाओं के मध्य शब्दकोष\\n इ-महाशब्दकोश - सी-डैक्, भारत सरकार द्वारा निर्मित\\n Part 1:Dictionary Making in Indian Languages: Survery and Prospects\\n भारतवाणी : भारतीय भाषाओं द्वारा ज्ञान (यहाँ शब्दकोश, भाषाकोश, ज्ञानकोश आदि सब उपलब्ध हैं।)\\n\\nश्रेणी:भाषा\\nश्रेणी:शब्दकोश\"}],\n",
       " 'negative_passages': [{'docid': 'doc-hi-9',\n",
       "   'text': 'कोयला (फ़िल्म)\\nकोयला 1997 में बनी हिन्दी भाषा की एक्शन थ्रिलर फिल्म है। राकेश रोशन द्वारा निर्देशित और निर्मित इस फिल्म में शाहरुख़ ख़ान, माधुरी दीक्षित और अमरीश पुरी प्रमुख भुमिकाओं में हैं। ये साल की 9वीं सबसे ज्यादा कमाई करने वाली फिल्म थी और इसे \"औसत\" दर्जा दिया गया था। इसके गीत भी खासे लोकप्रिय रहे। फिल्म के कुछ सीन अरुणाचल प्रदेश के तवांग में शूट किए गए हैं।\\n\\nसंक्षेप \\nशंकर (शाहरुख खान) एक मूक इंसान है, जिसे राजा (अमरीश पुरी) पालता है। शंकर, राजा का वफादार होता है, पर राजा उसे एक गुलाम से बढ़ कर और कुछ नहीं समझता। शंकर को राजा का छोटा भाई बिना कारण बेदर्दी से मारते रहता है। राजा अपनी खूबसूरत सहायक बिंदिया से ऊब चुका होता है और उसका डॉक्टर उसे किसी छोटी लड़की का सुझाव देता है। एक दिन राजा की नजर गाँव की एक भोली-भाली लड़की, गौरी (माधुरी दीक्षित) पर पड़ती है। वो उसके सपने देखने लगता है और उससे शादी करने की सोचता है। उसके लालची मामा और मामी भी उसकी शादी राजा से कराने को तैयार हो जाते हैं, लेकिन गौरी पहले अपने होने वाले पति की तस्वीर देखना चाहती है। \\n\\nबूढ़े राजा की तस्वीर को देखते साथ ही गौरी शादी से मना कर देगी, ये सोच कर राजा उसे अपनी तस्वीर न भेज कर शंकर की तस्वीर भेज देता है। गौरी को उसी समय उससे प्यार हो जाता है और शादी का कार्यक्रम आगे बढ़ता है। शादी होने से पहले ही गौरी को पता चल जाता है कि उसकी शादी जिससे होने वाली है वो शंकर नहीं है। ये जान कर वो बेहोश हो जाती है, लेकिन राजा पुजारी को शादी रोकने से मना कर देता है। गौरी को जब होश आता है तो उसे पता चलता है कि उसकी शादी हो चुकी है और राजा उसके साथ जबरदस्ती संबंध बनाने की कोशिश में है। गौरी इससे बचने के लिए आत्महत्या करने की कोशिश करती है, पर शंकर और उसका दोस्त आ कर उसे बचा लेते हैं और वो शंकर से पहली बार आमने सामने मिलती है। वो उसे थप्पड़ मारती है और उसकी जिंदगी बर्बाद करने का आरोप भी लगाती है। शंकर का दोस्त उसे बताता है कि इसमें शंकर की कोई गलती नहीं है। हैरान गौरी उससे माफी मांगने की कोशिश करती है, लेकिन तब तक वो चला जा चुका होता है। \\n\\nगौरी का भाई, अशोक (मोहनीश बहल) अपनी बहन को देखने आता है। राजा के दबाव में आ कर वो कह देती है कि वो खुश है, पर शंकर सारी सच्चाई उसके सामने ले आता है। जब उसका भाई अपनी बहन को छुड़ाने आता है तो राजा उसे मार देता है। अपने अंतिम समय पे वो शंकर से वादा लेता है कि वो उसकी बहन की रक्षा करेगा। उसके बाद शंकर और गौरी वहाँ से भाग जाते हैं। राजा गुस्से में गौरी और शंकर को देखते साथ मार डालने को कहता है और सभी उनकी तलाश करने लगते हैं। वे दोनों पहाड़ों और जंगलों में छिपते-छिपाते हैं। जंगल में शंकर को राजा के गुंडों को मारने में बहुत आसानी होती है, पर राजा के गुंडों को बहुत परेशानी होती है, इस कारण वे लोग वहाँ से चले जाते हैं। इसी दौरान गौरी और शंकर एक दूसरे से प्यार करने लगते हैं, लेकिन राजा जब वापस आता है तो वो गौरी और शंकर को झरने के पास देख लेता है और गोली चला देता है। एक गोली गौरी के हाथ में लग जाती है। \\n\\nवे दोनों पकड़े जाते हैं और शंकर को बृजवा और डीआईजी (प्रदीप रावत) मिल कर बुरी तरह मारते हैं और पहाड़ में मरने के लिए छोड़ देते हैं। गौरी को कोठे पर बिंदिया के साथ बेच दिया जाता है। बिंदिया वहाँ से गौरी को भगा देती है, पर बिंदिया को ऐसा करने पर बृजवा मार डालता है। राह चलते एक वैद्य को शंकर मिल जाता है। वो उसे बचा लेता है, पर अभी तक उसे होश नहीं आता है। इसी दौरान उसे पता चलता है कि वो जन्म से गूंगा नहीं है और उसका इलाज किया जा सकता है। शंकर को होश आ जाता है और वो याद करता है कि वो जब एक छोटा बच्चा था, तब उसके पिता हीरा ढूंढने का काम करते थे। उसके माता-पिता की हत्या उसके ही सामने दो अनजान लोगों ने कर दी थी। जब वो ये बात सभी को बताने वाला था तो उसके गले में गरम-गरम कोयला डाल दिया गया था, तब से वो बोल नहीं पाता था। शंकर ठीक हो कर वापस आता है और पहले बृजवा को और फिर अपने माता-पिता को मारने वाले एक व्यक्ति को मार कर गौरी को बचा लेता है। इसी दौरान उसे पता चलता है कि राजा ने ही उसके माता-पिता की पैसों के लिए हत्या की थी। राजा के दो आदमियों और डीआईजी को शंकर मार देता है और अंत में राजा अकेला पड़ जाता है। वो शंकर से अपने सारे गलत कामों के लिए माफी मांगता है, पर राजा उसे माफ नहीं करता और आग में डाल देता है।\\n\\nमुख्य कलाकार \\n शाहरुख़ ख़ान - शंकर\\n माधुरी दीक्षित - गौरी\\n अमरीश पुरी - राजा साब\\n रंजीत - दिलावर \\n सलीम घोष - बृजवा\\n जॉनी लीवर - शंकर का दोस्त  \\n दीपशिखा - बिंदिया \\n अशोक सर्राफ - वैद जी\\n जैक गौड़ - रणबीर \\n सुरेश चटवाल - गौरी के मामा \\n मोहनीश बहल - अशोक \\n शुभा खोटे - गौरी की मामी \\n राम मोहन - बुजुर्ग \\n कुनिका - रसीली \\n हिमानी शिवपुरी - चन्दाबाई \\n विकास आनन्द - हरिया\\n प्रदीप रावत - पुलिस कमिश्नर\\n\\nसंगीत\\n\\nनामांकन और पुरस्कार \\nमनोनीत - फ़िल्मफ़ेयर सर्वश्रेष्ठ खलनायक पुरस्कार - अमरीश पुरी\\n\\nसन्दर्भ\\n\\nबाहरी कड़ियाँ \\n \\n\\nश्रेणी:1997 में बनी हिन्दी फ़िल्म\\nश्रेणी:अरुणाचल प्रदेश में फिल्माई गई फिल्में\\nश्रेणी:राजेश रोशन द्वारा संगीतबद्ध फिल्में'},\n",
       "  {'docid': 'doc-hi-10',\n",
       "   'text': 'ओवरड्राफ्ट\\nthumb|\"मैं आपको चेतावनी देता हूं, साहब ! इस बैंक की असभ्यता सभी सीमाओं से परे है। एक और शब्द और मैं - मैं अपना ओवरड्राफ्ट वापस ले लूंगा!\" (पंच पत्रिका खण्ड 152, जून 27, 1917 से कार्टून)\\n\\nअधिविकर्ष या ओवरड्राफ्ट तब होता है जब बैंक खाते से उपलब्ध शेष राशि से अधिक निकासी हो जाती है। ऐसी स्थिति में उस व्यक्ति को \"ओवरड्रॉन \" (अधिक निकासी किया हुआ) कहा जाता है।\\n\\nयदि खाता प्रदाता से ओवरड्राफ्ट संरक्षण योजना हेतु कोई पूर्व अनुबन्ध है एवं अतिरिक्त आहरित राशि प्राधिकृत ओवरड्राफ्ट सीमा के अंतर्गत है, तब सहमत दर पर ही ब्याज अधिरोपित किया जाता है। यदि यह शेष राशि सहमत शर्तों से अधिक हो जाती है तो शुल्क एवं उच्चतर ब्याज दर अधिरोपित हो सकता है।\\n\\nओवरड्राफ्ट का इतिहास \\nपहला ज्ञात ओवरड्राफ्ट 1728 में प्रदान किया गया था जब व्यापारी विलियम हॉग को £1000 (आज के £65000, अमरीकी $93000) की निकासी जो उनके खाते में उपलब्ध राशि से अधिक की मंजूरी दी गयी थी। यह ओवरड्राफ्ट द रॉयल बैंक ऑफ स्कॉटलैंड के द्वारा प्रदान किया गया था जो पिछले वर्ष एडिनबर्ग में खुला था।\\n\\nओवरड्राफ्ट के कारण \\nओवरड्राफ्ट अनेक प्रकार के कारणों से होते हैं। इन में शामिल हैं:\\n जानबूझकर अल्पकालिक ऋण - खाता धारक स्वयं के पास धन की कमी पाता है और जानबूझकर एक अपर्याप्त-कोष से निकासी करता है। वे संबद्ध शुल्क स्वीकार करते हैं और अपने अगले जमा के साथ ओवरड्राफ्ट को परिपूर्ण करते हैं।\\n एक सही खाता पंजिका के रखरखाव में विफलता - खाता धारक अपने खाते में लेन-देन का सही-सही ध्यान नहीं रखते और लापरवाही से अधिव्यय कर देते हैं।\\n एटीएम (ATM) ओवरड्राफ्ट - बैंक या एटीएम धन की अपर्याप्त उपलब्धता के बावजूद नकद निकासी की अनुमति दे देते हैं। खाता धारक निकासी के समय इस तथ्य से वाकिफ हो भी सकता है और नहीं भी हो सकता है। यदि एटीएम, कार्डधारक के बैंक के साथ संवाद करने में असमर्थ है, तो वह स्वचालित रूप से अधिकृत नेटवर्क द्वारा पूर्व निर्धारित सीमा के अंतर्गत निकासी की अनुमति दे सकता है। \\n जमा पर अस्थाई रोक - खाते में जमा की गई राशि को बैंक रोके रख सकता है। ऐसा विनियमन सीसी (CC) (जो जमा को लंबित रखने संबंधी नीतियों को नियंत्रित करता है) के कारण अथवा बैंक की निजी नीतियों के कारण हो सकता है। धनराशि तत्काल उपलब्ध नहीं हो पाती और परिणामतः ओवरड्राफ्ट शुल्क देना होता है।\\n अप्रत्याशित इलेक्ट्रॉनिक निकासी - खाता धारक ने अतीत में किसी समय व्यापार के द्वारा किसी को इलेक्ट्रॉनिक निकासी के लिए अधिकृत किया हो ऐसा हो सकता है। यदि संदर्भित निकासी अनुबंध की शर्तों के अंतर्गत वैध रूप से हुई हो, जैसे किसी मुफ्त परीक्षण अवधि के पश्चात आवर्ती सेवा के आरंभ होने पर, तो ऐसा दोनों पक्षों के सद्भाव के कारण ही हो सकता है। यह विकलन वेतन से कुर्की का भी परिणाम हो सकता है, किसी करारोपण एजेंसी या क्रेडिट अकाउंट या उसी बैंक में अन्य खाते का समायोजन दावा, या किसी अधिक भुगतान की वसूली हेतु प्रत्यक्ष जमा किया गया चार्जबैक हो सकता है।\\n व्यापारिक त्रुटि - मानवीय भूल के कारण एक व्यापारी किसी ग्राहक के खाते में विकलन (डेबिट) कर सकता है। उदाहरण के लिए, एक ग्राहक $5.00 की खरीद करता है किंतु खाते में भूल से $500.00 की प्रविष्टि हो सकती है। ग्राहक के पास इस राशि को चार्जबैक के माध्यम से व्यापारी से वसूल करने का विकल्प रहता है।\\n व्यापारी को चार्जबैक - एक व्यायापारी को किसी ग्राहक से अनुचित क्रेडिट या डेबिट कार्ड शुल्क वसूल कर लेने पर चार्जबैक प्राप्त हो सकता है या उस व्यापारी से लिए गए किसी माल या सेवा का भुगतान करने के लिए कोई ग्राहक दूसरे के खाते में से डेबिट या क्रेडिट कार्ड के द्वारा अनुचित तरीके से भुगतान कर सकता है। इस चार्जबैक और संबद्ध शुल्क के कारण ओवरड्राफ्ट हो सकता है या तदनंतर की जाने वाली निकासी या व्यापारी को मिले चार्जबैक के कारण व्यापारी के खाते से विकलन (डेबिट) के लिए अपर्याप्त कोष रह सकता है।\\n प्राधिकरण रोक - जब कोइ ग्राहक पिन का उपयोग किए बिना अपने-अपने डेबिट कार्ड से खरीद करता है, तो यह लेनदेन एक उधार लेनदेन माना जाता है। ग्राहक के खाते में उस राशि पर रोक लगा दी जाती है और ग्राहक के उपलब्ध शेष में से वह राशि कम हो जाती है। हालांकि व्यापारी को वह राशि तब तक प्राप्त नहीं होती जब तक जिस अवधि में वह खरीद की गई थी, उस अवधि के लेन-देन बैच को वे संसाधित नहीं कर लेते. बैंक इन राशियों को अनिश्चितकाल तक नहीं रोकते हैं और इसलिए व्यापारी के राशि एकत्र करने से पूर्व ही बैंक इस रोक को हटा लेते हैं, इस प्रकार वह राशि पुनः उपलब्ध हो जाती है। यदि ग्राहक इस निधि को खर्च करता है, तो जब व्यापारी मूल खरीद के लिए राशि एकत्र करेगा उस समय एक अंतरिम जमा को छोड़ कर खाते में से अधि-आहरण होगा.\\n बैंक शुल्क - बैंक खाता धारक से अप्रत्याशित शुल्क वसूल कर लेता है जिससे उस खाते में से होने वाली अगली निकासी के लिए कोष अपर्याप्त रह जाता है।\\n फ्लोट से खिलवाड़ - फ्लोट वह समय है जो एक चेक प्रस्तुत करने और उसके भुगतान करने के बीच लगता है। खाता धारक खाते में अपर्याप्त कोष होते हुए भी यह सोच कर चेक काट देता है कि जब तक इस चेक का भुगतान होगा वह खाते में पर्याप्त राशि जमा करा देगा. जबकि फ्लोट से खिलवाड़ के अनेक मामले नेक इरादे से किए जाते हैं, लेकिन चेक-समाशोधन में लगने वाले समय तथा क्रेडिट और डेबिट के संसाधन में अंतर का लाभ उठा कर कुछ लोग चेक काइटिंग करते हैं। खाते में धनराशि न होते हुए भी चेक जारी करने को चेक काइटिंग कहते हैं। \\n प्रत्यावर्तित चेक जमा - खाता धारक एक चेक या मनीऑर्डर जमा करता है और जमा किया गया चेक, पर्याप्त कोष न होने, खाता बंद होने या यह पता लगने कि चेक जाली, चुराया हुआ, जालयाती से बदलाव किया हुआ या फर्जी है, बैंक द्वारा लौटा दिया जाता है। चेक चार्जबैक और संबद्ध शुल्क के कारण अथवा उस कोष की आशा में अनुवर्ती डेबिट के कारण ओवरड्राफ्ट होता है। ऐसा जमा किए गए चेक के गलत होने की वजह से हो सकता है या ग्राहक गलत चेक का शिकार हुआ हो या यह जाली चेक घोटाला हो. यदि इसके परिणामस्वरूप हुआ ओवरड्राफ्ट बहुत बड़ा है या अल्प समयावधि में उसे कवर नहीं किया जा सकता, तो बैंक मुकदमा कर सकता है या आपराधिक आरोपों पर कार्यवाही के लिए दबाव डाल सकता है।\\n जानबूझकर जालसाज़ी - सक एटीएम में अनुचित ढंग से प्रस्तुत धन जमा किया जाता है, यह जानते होते हुए भी कि चेक या मनी ऑर्डर गलत है, उसे बैंक में जमा किया जाता है और जालसाजी खुलने से पहले बहुत बड़ी राशि डेबिट कर दी जाती है। परिणामस्वरूप एक बार चार्जबैक बनते ही ओवरड्राफ्ट हो जाता है। यह जालसाजी स्वयं के खाते में, दूसरे व्यक्ति के खाते में या पहचान चुराने वाले के द्वारा किसी और के नाम से खोले गए फर्जी खाते में की जा सकती है। \\n बैंक त्रुटि - एक चेक डेबिट मानवीय भूल या कंप्यूटर की गलती से एक अनुचित राशि प्रविष्ट हो सकती है, जिससे चेक काटने वाले की इच्छित राशि से कहीं अधिक राशि खाते से निकल सकती है। ऐसी बैंक-त्रुटियां खाता धारक को नुकसान पहुंचा सकती हैं तो कभी लाभ भी दे सकती हैं। \\n उत्पीड़न - कोई खाता पहचान-चोर का लक्ष्य हो सकता है। यह जालसाजी, डिमांड-ड्राफ्ट, एटीएम (ATM) कार्ड या डेबिट कार्ड जालसाजी, हेराफेरी, चेक-जालसाजी, \"खाता अधिग्रहण\" या फिशिंग के द्वारा हो सकती है। आपराधिक कृत्य के कारण ओवरड्राफ्ट हो सकता है या इसकी वजह से होने वाले अनुवर्ती डेबिट के कारण बाद में भी हो सकता है। एक एटीएम (ATM) से धनराशि या जमा चेक चुराये भी जा सकते हैं या लिफाफा खो गया है या चोरी हो गया है, तो इस मामले में पीड़ित को अक्सर कोई राहत नहीं मिलती.\\n एक दिवसीय ओवरड्राफ्ट - ग्राहक के खाते में एक डेबिट होता है जिसके परिणामस्वरूप ओवरड्राफ्ट होता है जिसे उसी कारोबारी दिन के दौरान ही खाते में क्रेडिट के द्वारा कवर कर दिया जाता है। इसके परिणामस्वरूप वास्तव में ओवरड्राफ्ट शुल्क लगेगा या नहीं यह संबंधित बैंक के जमा-खाता धारक के साथ समझौते पर निर्भर करता है।\\n\\nब्रिटेन\\n\\nब्रिटेन में ओवरड्राफ्ट संरक्षण \\nब्रिटेन में बैंक अक्सर पूर्वयोजित सीमा (अधिकृत ओवरड्राफ्ट सीमा के रूप में ज्ञात) के साथ एक बुनियादी ओवरड्राफ्ट सुविधा प्रदान करते हैं। बहरहाल, प्रदान की गई यह है सुविधा ब्याज मुक्त है या नहीं यह औसत मासिक शेष राशि या बैंक की ओवरड्राफ्ट ऋण दर के अनुसार भिन्न-भिन्न बैंकों में खाता उत्पाद के अनुसार बदलता रहता है। \\n\\nजब ग्राहक अपनी अधिकृत ओवरड्राफ्ट सीमा पार कर लेते हैं, वे प्राधिकरण के बिना अधि-आहरित हो जाते हैं, जिसके परिणामस्वरूप ग्राहक से उस राशि जिसके द्वारा वे अपनी अधिकृत ओवरड्राफ्ट सीमा पार कर चुके हैं पर ऋण की उच्च दर से एक या अधिक शुल्क वसूला जाता है। बैंकों द्वारा लिए जाने वाले शुल्क भिन्न हो सकते हैं। अपर्याप्त कोष के कारण जारीकर्ता बैंक के द्वारा अस्वीकार करने के उपरांत भी ग्राहक द्वारा एक वस्तु प्रस्तुत की जाती है तो उसके कारण भी शुल्क लग सकता है, अर्थात बैंक ग्राहक को अनधिकृत ओवरड्राफ्ट करने की अनुमति न देने का निर्णय करता है। पुनः ऐसे शुल्क का स्तर और प्रकृति भिन्न बैंकों में भिन्न होती है। आमतौर पर, बैंक ग्राहक को पत्र भेज कर सूचित करता है और उस बिंदु के बाद निर्धारित सीमा के अंदर अपने खाते को संचालित करने का अनुरोध करता है। इस प्रक्रिया पर बीबीसी के एक कार्यक्रम व्हिसिलब्लोअर में यह नोट किया गया कि एक बैंक से अनधिकृत ओवरड्राफ्ट की वास्तविक राशि दो पाउंड से भी कम थी।\\n\\nशुल्क की राशि \\nब्रिटेन के किसी बड़े बैंक ने अनधिकृत ओवरड्राफ्ट शुल्क को पूरी तरह से नहीं हटाया है। तथापि, कुछ बैंक एक \\'बफर जोन\\' प्रदान करते हैं, जिसमें यदि ग्राहक एक निश्चित राशि से कम से अपनी सीमा पार करते हैं तो ग्राहकों से शुल्क नहीं लिया जाता. अन्य बैंक ओवरड्राफ्ट के स्तर की मात्रा की परवाह किए बिना ओवरड्राफ्ट शुल्क वसूल करते हैं जिसे कुछ लोग अनुचित मानते हैं। आलोचनाओं के जवाब में लॉयड्स टीएसबी (TSB) ने अपनी शुल्क संरचना बदल दी है, अनधिकृत ओवरड्राफ्ट पर एकल मासिक शुल्क के स्थान पर वे अब प्रतिदिन के हिसाब से शुल्क लेते हैं। वे एक \\'रियायती अवधि\\' भी प्रदान करते हैं जिसमें आप कोई दस्तावेज लौटाए जाने अथवा बैंक शुल्क लगने से पहले अपराह्न 3:30 (सोम-शुक्र) तक धनराशि जमा करा सकते हैं (काम काज के दिन की शुरुआत में डेबिट करने के स्थायी आदेश के अपवाद के साथ). यदि किसी ग्राहक से अनियोजित ओवरड्राफ्ट हो जाता है, उदाहरण के लिए शुक्रवार को, तो लॉयड्स टीएसबी अपने ग्राहकों को सप्ताहांत (शनिवार और रविवार) के लिए दैनिक शुल्क में छूट देते हुए सोमवार को प्रातः 10 बजे से पूर्व धनराशि जमा कराने की अनुमति देते हैं। हालांकि इसके लिए समाशोधित धन की आवश्यकता होती है। एलायंस और लीसेस्टर पूर्व में एक बफर जोन की सुविधा देते थे (\"अंतिम कुछ पाउंड\" सुविधा के नाम से विपणन) लेकिन यह वापस ले ली गई है।\\n\\nसामान्यतः लगाया गया शुल्क ऋण ब्याज की बढ़ी हुई दर के साथ, पच्चीस से तीस पाउंड के बीच होता है। चेक और प्रत्यक्ष डेबिट जो अपर्याप्त कोष के कारण नामंजूर (या \"बाउंस\") हो गए हैं, के शुल्क के रूप में आमतौर पर उतना ही या सामान्य ओवरड्राफ्ट शुल्क से थोड़ा कम और उस से ऊपर शुल्क लगाया जा सकता है। एक स्थिति जिस पर काफी विवाद छिड़ा वह यह है कि चेक/प्रत्यक्ष डेबिट को अस्वीकार करके बैंक शुल्क लगाता है जिससे ग्राहक अधि-आहरित हो जाता है और तब अधि-आहरित हो जाने के लिए शुल्क बगाता है। हालांकि, हैलिफ़ैक्स जैसे कुछ बैंकों में \"शुल्क पर शुल्क नहीं\" की नीति है जिसके अंतर्गत एक खाता यदि पूर्णतः अभुक्त शुल्क के कारण अधि-आहरित हो जाता है तो उससे अतिरिक्त शुल्क नहीं लिया जाता.\\n\\nकानूनी स्थिति और विवाद \\n\\n2006 में फेयर ट्रेडिंग के कार्यालय ने एक बयान जारी किया जिसमें यह निष्कर्ष निकाला गया था कि जब ग्राहक अपनी अधिकतम व्यय सीमा को पार कर गए थे / अपने खाते में विलंब से भुगतान कर रहे थे, तो क्रेडिट  कार्ड जारीकर्ता उनसे विलम्ब से भुगतान हेतु जुर्माना शुल्क उगाह रहे थे। बयान में, ओ एफ टी (OFT) ने सिफारिश की थी कि क्रेडिट कार्ड जारीकर्ता ऐसा अधिकतम शुल्क 12 ब्रिटिश पाउंड निर्धारित करें. \\n\\nओ एफ टी ने अपने बयान में यह अभिमत दिया कि क्रेडिट कार्ड जारीकर्ताओं द्वारा लिया जाने वाला शुल्क बैंकों द्वारा लिये जाने वाले अनधिकृत ओवरड्राफ्ट शुल्क के जैसा ही था। अनधिकृत ओवरड्राफ्ट शुल्क देने वाले अनेक ग्राहकों ने इस बयान का इस्तेमाल शुल्क की राशि वसूली हेतु अपने बैंकों पर मुकदमा करने के लिए एक मंच के रूप में किया है। वर्तमान में ऐसा सोचा जाता है कि इंग्लैंड और वेल्स काउंटी अदालतों में इस प्रकार के दावों की बाढ़ आ गई है। दावेदारों को अक्रसर द कंज्यूमर एक्शन ग्रुप जैसी वेब साइटों से सहायता मिल रही है। आज तक अनेक बैंक अपनी अनधिकृत ओवरड्राफ्ट शुल्क संरचनाओं का औचित्य सिद्ध करने के लिए अदालत में उपस्थित नहीं हुए हैं और कई ग्राहकों ने ऐसे शुल्क पूर्णतः वसूल कर लिए हैं। हालांकि ऐसे मामले भी हैं जिनमें अदालतों ने बैंकों के पक्ष में फैसला सुनाया है और वैकल्पिक रूप से, अपने बैंकों के विरुद्ध पर्याप्त ढंग से मामला प्रस्तुत न कर पाने वाले ग्राहकों के दावों को खारिज कर दिया है।\\n\\nसंयुक्त राज्य अमेरिका\\n\\nअमेरिका में ओवरड्राफ्ट संरक्षण \\nओवरड्राफ्ट संरक्षण बैंकिंग संस्थाओं द्वारा मुख्यतः संयुक्त राज्य अमेरिका में प्रदान की जाने वाली एक वित्तीय परिसेवा है। जब किसी ग्राहक के खाते में निकासी की राशि को कवर करने के लिए पर्याप्त कोष उपलब्ध नहीं होता, तो ओवरड्राफ्ट या कर्टसी पे प्रोग्राम प्रोटेक्शन (सौजन्यतामूलक भुगतान योजना संरक्षण) उस ग्राहक के खाते में प्रस्तुत किए गए मदों का भुगतान करता है। ओवरड्राफ्ट प्रोटेक्शन, एटीएम (ATM) निकासी, डेबिट कार्ड से की गई खरीदारी, इलेक्ट्रॉनिक स्थानान्तरण तथा चेक को कवर कर सकता है। गैर पूर्व-अधिकृत मदों जैसे चेक या एसीएच (ACH) निकासी के मामलों में ओवरड्राफ्ट प्रोटेक्शन उनको बिना भुगतान किये लौटाने या बाउंस करने की अपेक्षा इन मदों के भुगतान की अनुमति देता है हालांकि, एटीएम निकासी और डेबिट कार्ड अथवा चेक कार्ड से की गई खरीद को पूर्व-अधिकृत माना जाता है और जब उसे प्रस्तुत किया जाए तो बैंक को उसका भुगतान करना चाहिए, चाहे यह ओवरड्राफ्ट ही क्यों न हो.\\n\\nओवरड्राफ्ट का तदर्थ कवरेज \\nपरंपरागत रूप से, एक बैंक के प्रबंधक को बैंक की ओवरड्राफ्ट सूची पर हर दिन नजर दौड़ानी होगी. यदि प्रबंधक ने देखा कि एक पसंदीदा ग्राहक ने एक ओवरड्राफ्ट किया है, तो यह उनका विवेक यह कहता है कि वे ग्राहक के पक्ष में ओवरड्राफ्ट का भुगतान कर दें. बैंक परंपरागत रूप से इस तदर्थ कवरेज के लिए शुल्क नहीं लेते थे। चूंकि, यह पूरी तरह से विवेकाधीन था अतः इस पर निर्भर नहीं रहा जा सकता था। बड़े पैमाने पर अंतरराज्यीय शाखा बैंकिंग के आगमन के साथ, पारंपरिक तदर्थ कवरेज व्यावहारिक रूप से गायब हो चुका है।\\n\\nइसका एक अपवाद तथाकथित \"अनिवार्य भुगतान\" सूची है। प्रत्येक कारोबारी दिन की शुरुआत में, शाखा प्रबंधक अक्सर अपनी विशिष्ट शाखा, शहर या राज्य में आयोजित खातों के लिए, अभी भी अस्वीकृति के लिए लंबित मदों की एक कम्प्यूटरीकृत सूची मंगवाते हैं। आम तौर पर, यदि एक ग्राहक नकदी के साथ शाखा में आ जाने में सफल हो जाता है या अस्वीकृति हेतु लंबित मद की राशि को कवर करने के लिए कोई हस्तांतरण करता है, तो मैनेजर (प्रबंधक) उस मद का \"अनिवार्य भुगतान\" कर सकते हैं। इसके अलावा, यदि परिस्थिति कमजोर है या संदर्भित मद एक नियमित ग्राहक द्वारा आयोजित खाते से है, तो प्रबंधक मद का भुगतान करके एक जोखिम ले सकते हैं, लेकिन ऐसा होना बहुत ही असामान्य है। बैंकों का एक कट ऑफ (निर्धारित) समय होता है जिसके अंदर यह कार्रवाई हो जानी चाहिए, उस समय के बाद मद स्वचालित रूप से \"लंबित अस्वीकृति\" से \"अस्वीकृत\" की सूची में चला जाता है और उस पर आगे कोई कार्रवाई नहीं की जा सकती.\\n\\nक्रेडिट की ओवरड्राफ्ट लाइन \\nओवरड्राफ्ट संरक्षण का यह रूप एक संविदात्मक संबंध है जिसमें बैंक ओवरड्राफ्ट एक निश्चित डॉलर सीमा तक ओवरड्राफ्ट का भुगतान करने का वादा करता है। एक उपभोक्ता जो ओवरड्राफ्ट क्रेडिट लाइन चाहता है, उसे एक आवेदन को पूर्ण करके उस पर हस्ताक्षर करना चाहिए. इसके बाद बैंक ग्राहक के क्रेडिट की जांच करता है और आवेदन को मंजूर या नामंजूर कर देता है। ओवरड्राफ्ट क्रेडिट लाइन ऋण हैं और ऋण अधिनियम में सत्य के अनुरूप होने चाहिएं. संबद्ध खातों पर, बैंक आम तौर पर प्रति ओवरड्राफ्ट एक मामूली शुल्क लेते हैं और बकाया राशि पर ब्याज भी वसूलते हैं। कुछ बैंक इस बात का ध्यान रखे बिना कि क्रेडिट लाइन का उपयोग किया जाता है या नहीं, एक छोटा सा मासिक शुल्क लेते हैं। ओवरड्राफ्ट संरक्षण का यह रूप उन उपभोक्ताओं के लिए उपलब्ध है जो बैंकों द्वारा ऐसे खातों के लिए स्थापित ऋणपात्रता के मानदंडों को पूरा करते हैं। एक बार क्रेडिट लाइन स्थापित हो जाती है, तो उपलब्ध क्रेडिट ग्राहक के उपलब्ध शेष रकम के रूप में दिखाई दे सकती है।\\n\\nसंबद्ध खाते \\nयह \"ओवरड्राफ्ट स्थानांतरण संरक्षण\" के रूप में भी संदर्भित है, एक चालू खाता किसी अन्य खाते से जोड़ा जा सकता है, जैसे एक बचत खाते से, क्रेडिट कार्ड से, या क्रेडिट लाइन से. एक बार संबंध स्थापित हो जाने के बाद, जब एक मद चालू खाते में प्रस्तुत किया जाता है और ओवरड्राफ्ट हो जाता है, तो ओवरड्राफ्ट को कवर करने के लिए संबद्ध खाते से कोष चालू खाते में स्थानांतरित हो जाता है। प्रत्येक ओवरड्राफ्ट स्थानांतरण के लिए एक मामूली शुल्क लिया जाता है और यदि संबद्ध खाता एक क्रेडिट कार्ड या क्रेडिट लाइन है तो ग्राहक को उस खाते की शर्तों के अंतर्गत ब्याज चुकाना होता है। \\n\\nसंबद्ध खाते और ओवरड्राफ्ट क्रेडिट लाइन के बीच मुख्य अंतर यह है कि ओवरड्राफ्ट क्रेडिट लाइन आमतौर पर केवल ओवरड्राफ्ट संरक्षण के लिए ही प्रयोग किया जा सकता है। ओवरड्राफ्ट संरक्षण के लिए संबद्ध अलग खाते अपने आप में स्वतंत्र खाते हैं।\\n\\nआनादरण सुरक्षा योजना \\nकुछ बैंकों द्वारा एक और अधिक ताजा उत्पाद की पेशकश की जा रही है जिसे \"अनादरण सुरक्षा\" (नकारे जाने पर सुरक्षा) कहते हैं। \\n\\nछोटे बैंक तृत्तीय पक्ष कंपनियों द्वारा प्रशासित योजनाएं पेश कर रहे हैं जिनसे बैंकों को अतिरिक्त शुल्क आय प्राप्त करने में सहायता मिलेगी. \\nबड़े बैंकों की प्रवृत्ति अनादरण सुरक्षा योजना पेश करने की नहीं है, लेकिन इसके बजाय वे अपने खातों के नियम और शर्तों के अनुसार ओवरड्राफ्ट को संसाधित करते हैं। \\n\\nदोनों में से किसी भी एक मामले में बैंक अपने विवेकानुसार अधि-आहरित मद को कवर करने का निर्णय कर सकते हैं और ओवरड्राफ्ट शुल्क लगा सकते हैं जिसकी राशि को प्रकट (खुलासा) भी किया जा सकता है और नहीं भी. पारंपरिक तदर्थ कवरेज के विपरीत, अधि-आहरित मदों का भुगतान करने या न करने का यह निर्णय स्वचालित है और ग्राहक के औसत शेष, खाते के ओवरड्राफ्ट इतिहास, बैंक में ग्राहक के खातों की संख्या और उन खातों के खुलने से अब तक की अवधि, जैसे विषयनिष्ठ मानदंडों पर आधारित है। हालांकि, स्वचालित मानदंड पूरे होने पर भी, बैंक ओवरड्राफ्ट के भुगतान का वादा नहीं करते हैं।\\n\\nअनादरण सुरक्षा योजना की सतही रूप से ओवरड्राफ्ट क्रेडिट लाइन और ओवरड्राफ्ट की तदर्थ कवरेज के साथ कुछ समानताएं हैं, लेकिन करने के लिए अलग नियमों के तहत काम करती है। एक ओवरड्राफ्ट क्रेडिट लाइन की तरह, अनादरण सुरक्षा योजना की शेष राशि को भी ग्राहक के उपलब्ध शेष के साथ देखा जा सकता है, तब भी बैंक एक अधि-आहरित मद के भुगतान से इंकार करने का अधिकार सुरक्षित रखता है, जो कि परंपरागत तदर्थ कवरेज के समान है। बैंक आमतौर पर प्रत्येक भुक्त ओवरड्राफ्ट के लिए एकमुश्त शुल्क लेते हैं। एक बैंक उस प्रत्येक दिन के लिए जिस दौरान खाते में नकारात्मक शेष रहता है, आवर्ती दैनिक शुल्क भी ले सकता है।\\n\\nआलोचकों का तर्क है कि क्योंकि ग्राहक को धन अग्रिम के रूप में दिया जाता है और उसके पुनर्भुगतान की उम्मीद भी होती है, अतः अनादरण सुरक्षा एक प्रकार का ऋण ही है। क्योंकि बैंक ओवरड्राफ्ट को कवर करने के लिए किसी अनुबंध के तहत बाध्य नहीं हैं, \"अनादरण सुरक्षा\" ट्रुथ इन लेंडिंग एक्ट से विनियमित नहीं होती जिसके अंतर्गत भ्रामक विज्ञपनों पर रोक है तथा ऋण की शर्तों को प्रकट करना आवश्यक है। ऐतिहासिक रूप से, अनादरण सुरक्षा को ग्राहक की अनुमति या जानकारी के बिना उसके खाते में जोड़ा जा सकता है। \\n\\nमई 2005 में, बचत अधिनियम में सत्य के विनियमन डीडी में संशोधन किया गया कि \"अनादरण सुरक्षा\" योजना प्रदान करने वाले बैंकों को अपने ग्राहकों के सामने कुछ निश्चित खुलासे करने होंगे. इन संशोधनों में शामिल हैं, अनादरण सुरक्षा को आरंभ करने वाले लेन-देन का खुलासा करने की आवश्कता, अनादरण सुरक्षा से संबद्ध शुल्क, लगाए गए शुल्कों की संख्या बताने वाला अलग विवरण और भ्रामक विज्ञापनों को रोकने के लिए अनादरण सुरक्षा योजना के विपणन पर प्रतिबंध लगाना. बड़े बैंक, जो अपने नियम एवं शर्तों पर ओवरड्राफ्ट को संसाधित करते हैं, पहले से ही इन खुलासों को कर रहे हैं।\\n\\nउद्योग के आंकड़े \\nअमेरिकी बैंकों द्वारा 2009 में ओवरड्राफ्ट शुल्क से $38.5 बिलियन एकत्र करने का अनुमान है जो 2000 की में लगभग दोगुना है।\\n\\nलेनदेन संसाधन आदेश \\nओवरड्राफ्ट शुल्क संबंधी विवाद का क्षेत्र वह क्रम है जिसमें बैंक एक ग्राहक के लेनदेन खाते में चढ़ाता है। यह विवादास्पद है, क्योंकि सबसे बड़े से सबसे छोटे संसाधन से ग्राहक के खाते में ओवरड्राफ्ट होने की घटनाएं अधिकतम होंगी. यह स्थिति उस समय उत्पन्न होती है जब खाताधारक छोटे-छोटे कई डेबिट बनाता है जिनके लिए खरीद के समय खाते में पर्याप्त कोष उपलब्ध है। बाद में, खाता धारक एक बड़ा डेबिट करता है जो खाते को अधि-आहरित कर देता है (या तो गलती से या जानबूझकर). यदि खाते से भुगतान हेतु सभी मद एक ही दिन प्रस्तुत हों और बैंक सबसे बड़े लेन-देन को पहले संसाधित करता है, तो परिणाम स्वरुप एकाधिक ओवरड्राफ्ट हो सकते हैं। \\n\\nबड़े अमेरिकी बैंकों में \"सबसे बड़ी जांच पहले\" नीति आम है। बैंकों का तर्क है कि ऐसा इसलिए किया जाता है जिस से एक ग्राहक के महत्वपूर्ण लेनदेन (जैसे कि किराया या बंधक चेक या उपयोगिता भुगतान) के अभुक्त लौटाये जाने को रोकने के लिए किया जाता है, बावजूद इसके कि ऐसे कुछ लेनदेन गारंटीशुदा होते हैं। यह सही हो सकता था, यदि बैंक ने कभी वास्तव में किसी कम शुल्क के लिए इन्कार किया होता, बजाय उन्हें जाने देकर जिससे ग्राहक पर एक शुल्क लगे. उपभोक्ताओं ने इस प्रथा को रोकने के लिए मुक़दमा करने का प्रयास किया, उनका तर्क था कि बैंक अधिक ओवरड्राफ्ट शुल्क एकत्र करने के लिए \"सबसे बड़ी जांच पहले\" का प्रयोग करके लेनदेन के क्रम में हेराफेरी करते हैं ताकि कृत्रिम रूप से अधिक ओवरड्राफ्ट उत्पन्न हों. संयुक्त राज्य अमेरिका में अधिकतर बैंक एक संघीय एजेंसी मुद्रा नियंत्रक का कार्यालय से विनियमित होते हैं जिसने इस प्रक्रिया को औपचारिक रूप से मंजूरी दे दी है, हालांकि इस प्रक्रिया को हाल ही में अनेक निजी राजकीय भ्रामक कानूनों के अंतर्गत चुनौती दी गई है। \\n\\nबैंक जमा समझौतों में आम तौर पर यह प्रावधान है कि बैंक अपने विवेक के आधार पर लेन-देन को किसी भी क्रम में समाशोधित कर सकता है।\\n\\nप्रस्तावित विधेयक \\n\\n8 फ़रवरी 2007 को अमेरिकी प्रतिनिधि सभा में पेश एच आर 946 ओवरड्राफ्ट ऋण कार्यक्रम के विनियमन को बढ़ाएगा. प्रस्तावित विधेयक ऋण अधिनियम में सत्य के विनियम जेड में संशोधन करेगा, यह स्पष्ट करने के लिए कि ओवरड्राफ्ट शुल्क कवर किया गया है, ओवरड्राफ्ट ऋण योजना में नामांकन से पूर्व लिखित सहमति की आवश्यकता, कब एक एटीएम निकासी से ओवरड्राफ्ट हो जाएगा इसकी वित्तीय संस्थाओं द्वारा ग्राहक को जानकारी देने की आवश्यकता और वित्तीय संस्थाओं को सिर्फ ओवरड्राफ्ट शुल्क बढ़ने के उद्देश्य से समाशोधन के लिए चेक के क्रमों को बदलने या जमा को देरी से खातों में चढ़ाने से रोकना इस विधेयक का लक्ष्य है। इस विधेयक को अप्रैल 2007 में समिति को भेजा गया था और समिति में ही यह समाप्त हो गया। फरवरी 2009 में, फेडरल रिजर्व ने इस मुद्दे पर सार्वजनिक टिप्पणियां मांगी.\\n\\nइन्हें भी देखें \\n प्राधिकरण रोक\\n बैंक\\n बैंक चार्ज\\n समुदाय निर्माण\\n क्रेडिट\\n करेंट अकाउंट्स\\n\\nसन्दर्भ \\n\\nश्रेणी:बैंकिंग शब्दावली और उपकरण'},\n",
       "  {'docid': 'doc-hi-11',\n",
       "   'text': 'प्रबंधन परामर्श (मैनेजमेंट कंसल्टिंग)\\nप्रबंधन परामर्श प्राथमिक रूप से मौजूदा व्यावसायिक समस्याओं के विश्लेषण के माध्यम से संगठनो को अपने प्रदर्शन को बेहतर बनाने और सुधार के लिए योजनाओं के विकास में मदद करने की प्रथा और उद्योग दोनों को संकेत करता है।\\n\\nसंगठन कई कारणों से प्रबंधन सलाहकारों की सेवाओं को हासिल करते हैं जिसमें बाहरी (और शायद निष्पक्ष) सलाह हासिल करना और सलाहकारों की विशिष्ट विशेषज्ञता का उपयोग करना भी शामिल है।\\n\\nकई संगठनों के साथ सम्बन्ध होने और जोखिम होने की वजह से, परामर्श कंपनियों को कथित तौर पर उद्योग की \"बेहतरीन प्रथाओं\" से सचेत रहना पड़ता है हालांकि एक संगठन से दूसरे संगठन में ऐसी प्रथाओं के स्थानांतरण की योग्यता विचाराधीन परिस्थितियों के आधार पर समस्याग्रस्त हो सकती है.\\n\\nपरामर्श कंपनियां संगठनात्मक परिवर्तन प्रबंधन सहयोग, प्रशिक्षण कौशलों का विकास, प्रौद्योगिकी कार्यान्वयन, रणनीति विकास, या परिचालनात्मक सुधार सेवाएं भी प्रदान कर सकती हैं। प्रबंधन सलाहकार आम तौर पर समस्याओं की पहचान के मार्गदर्शन के लिए और व्यावसायिक कार्यों को अधिक प्रभावी या कुशल तरीके से करने के लिए सिफारिशों के आधार के रूप में काम करने के लिए अपने खुद के, स्वामित्व वाले तरीकों या रूपरेखाओं का इस्तेमाल करते हैं।\\n\\nइतिहास \\nअध्ययन के एक अनोखे क्षेत्र के रूप में प्रबंधन के उदय के साथ प्रबंधन परामर्श का विकास हुआ। सबसे पहली प्रबंधन परामर्श कंपनी का नाम आर्थर डी. लिटिल (Arthur D. Little) था जिसकी स्थापना 1886 में इसी नाम के एमआईटी (MIT) प्रोफ़ेसर ने की थी। हालांकि आर्थर डी. लिटिल बाद में एक महाप्रबंधन परामर्श कंपनी बन गई लेकिन मूल रूप से तकनीकी अनुसन्धान में ही इसकी विशेषता थी। बूज एलन हैमिल्टन (Booz Allen Hamilton) की स्थापना एडविन जी. बूज ने की थी जो कि नॉर्थवेस्टर्न यूनिवर्सिटी के केलॉग स्कूल ऑफ मैनेजमेंट के एक स्नातक थे, उन्होंने इसकी स्थापना 1914 में एक प्रबंधन परामर्श कंपनी के रूप में की थी और यह उद्योग और सरकार दोनों तरह के ग्राहकों को सेवा प्रदान करने वाली पहली कंपनी थी।\\n\\nद्वितीय विश्व युद्ध के बाद, कई नई प्रबंधन परामर्श कंपनियों की स्थापना की गई, जिनमें से बॉस्टन कंसल्टिंग ग्रुप (Boston Consulting Group) सबसे उल्लेखनीय कंपनी थी, जिसकी स्थापना 1963 में की गई थी, जिसने प्रबंधन और रणनीति के अध्ययन में एक कठोर विश्लेषणात्मक दृष्टिकोण प्रदान किया। 1960 और 1970 के दशकों के दौरान बॉस्टन कंसल्टिंग ग्रुप, मैककिंसे (McKinsey), बूज एलन हैमिल्टन और हार्वर्ड बिजनेस स्कूल (Harvard Business School) में किए गए काम से ऐसे संसाधन और दृष्टिकोणों का विकास हुआ जिन्होंने व्यूहात्मक प्रबंधन के नए क्षेत्र को परिभाषित किया और उसके द्वारा स्थापित आधार कर्मों का कई परामर्श कंपनियों ने पालन किया। 1983 में छः प्रोफेसरों द्वारा मॉनिटर ग्रुप (Monitor Group) की स्थापना के साथ उद्योग पर हार्वर्ड बिजनेस स्कूल का प्रभाव बरकरार रहा।\\n\\nयूएसए (USA) में सबसे पहले प्रबंधन परामर्श कंपनी के उदय के कई कारणों में से एक गहरे सांस्कृतिक कारक हैं: इस बात को वहां स्वीकार किया गया (अगर कहा जाय तो यूरोप के विपरीत) कि प्रबंधन और इस तरह के बोर्ड सभी परिस्थितियों में सक्षम या योग्य नहीं हो सकते थे; इसलिए बाहरी योग्यता खरीदने की क्रिया को व्यवसाय सम्बन्धी समस्या के समाधान के एक सामान्य तरीके के रूप में देखा जाता था। इसे प्रबंधन के लिए एक \"अनुबंधीय\" सम्बन्ध के रूप में संदर्भित किया जाता है. इसके विपरीत यूरोप में प्रबंधन को भावनात्मक एवं सांस्कृतिक आयामों के साथ जोड़ा जाता है, जहां प्रबंधक हर समय योग्य होने के लिए बाध्य होता है। इसे \"पैटर फैमिलियास\" पद्धति के रूप में संदर्भित किया जाता है. इसलिए बाहरी सलाह मांगने (और उसका भुगतान करने) को अनुचित माना जाता था. हालांकि कभी-कभी यह तर्क दिया जाता है कि उन दिनों यूएसए में कार्यकारियों के शिक्षा का प्रकार यूरोप की तुलना में अक्सर अलग होता था जहां प्रबंधक अक्सर तकनीकी या अन्य विशेष पृष्ठभूमि के होते थे - जैसे फ़्रांस में तकनीकी ग्रांडेस इकोलेस के स्नातक या जर्मनी में \"डॉक्टर\" (पीएचडी (PhD) के समान) - लेकिन उनकी विशिष्ट प्रबंधन शिक्षा अक्सर सीमित होती थी। हालांकि यह कहना जरूरी है कि अमेरिकी और यूरोपीय व्यवसायों की प्रबंधन संरचनाओं में बहुत ज्यादा अंतर होने की वजह से इसका अंदाज़ा लगाना बहुत मुश्किल है.\\n\\nकेवल द्वितीय विश्व युद्ध के बाद, यूएसए (USA) के नेतृत्व में अंतर्राष्ट्रीय व्यापार के विकास के मद्देनजर, यूरोप में प्रबंधन परामर्श का उद्भव हुआ था। बाज़ार में वर्तमान चलन प्रबंधन परामर्श कंपनियों का एक स्पष्ट विभाजन है।\\n\\nदृष्टिकोण \\nआम तौर पर ऐसा माना जा सकता है कि परामर्श के विभिन्न दृष्टिकोण कहीं न कहीं सातत्य के साथ स्थित है जहां एक तरफ \\'विशेषज्ञ\\' या आदेशात्मक दृष्टिकोण है और दूसरी तरफ सुविधाजनक दृष्टिकोण है। विशेषज्ञ दृष्टिकोण में सलाहकार विशेषज्ञ की भूमिका निभाता है और ग्राहक को विशेषज्ञ सलाह या सहयोग प्रदान करता है और इसकी तुलना में सुविधाजनक दृष्टिकोण के तहत, ग्राहकों से कम इनपुट लिया जाता है और बहुत कम सहयोग प्रदान किया जाता है। सुविधाजनक दृष्टिकोण के साथ, सलाहकार विशिष्ट या तकनीकी विशेषज्ञ ज्ञान पर कम लेकिन परामर्श की प्रक्रिया पर ज्यादा ध्यान देता है। प्रक्रिया पर ध्यान देने की वजह से सुविधाजनक दृष्टिकोण को अक्सर \\'प्रक्रिया परामर्श\\' के रूप में भी संदर्भित किया जाता है जिसके सबसे मशहूर अभ्यासकर्ता के रूप में एडगर स्चीन का नाम लिया जाता है। ऊपर सूचीबद्ध परामर्श कंपनियां इस सातत्य के विशेषज्ञ दृष्टिकोण के काफी करीब है।\\n\\nकई परामर्श कंपनियों को एक मैट्रिक्स संरचना में संगठित किया जाता है, जहां एक \\'अक्ष\\' व्यवसाय के एक कार्य या परामर्श के प्रकार का वर्णन करता है: उदाहरण के लिए, रणनीति, परिचालन, प्रौद्योगिकी, कार्यकारी नेतृत्व, प्रक्रिया सुधार, प्रतिभा प्रबंधन, बिक्री, इत्यादि. दूसरा अक्ष उद्योग केन्द्रित है: उदाहरण के लिए, तेल और गैस, खुदरा, मोटर वाहन. ये सब एक साथ एक मैट्रिक्स का निर्माण करते हैं, जहां मैट्रिक्स में एक या एक से अधिक \"कक्ष (सेल)\" पर सलाहकारों का कब्ज़ा होता है। उदाहरण के लिए, एक सलाहकार खुदरा उद्योग के परिचालन में विशेषज्ञता प्राप्त कर सकता है और एक अन्य सलाहकार डाउनस्ट्रीम तेल और गैस उद्योग में प्रक्रिया सुधार पर ध्यान केंद्रित कर सकता है।\\n\\nविशेषज्ञताएं \\nप्रबंधन परामर्श आम तौर पर व्यवसाय परामर्श सेवाओं के प्रावधान को संदर्भित करता है लेकिन इनमें कई विशेषज्ञताएं होती हैं, जैसे सूचना प्रौद्योगिकी परामर्श, मानव संसाधन परामर्श, आभासी प्रबंधन परामर्श और अन्य परामर्श, जिनमें से कई परामर्श एक साथ दिए जाते हैं और जिनमें से ज्यादातर परामर्श नीचे सूचीबद्ध काफी विविध परामर्श कंपनियों द्वारा प्रदान किए जाते हैं। हालांकि तथाकथित \"बुटीक\" परामर्श कंपनियां छोटे संगठन हैं, जिन्हें एक या ऐसी कुछ विशेषज्ञताओं में विशेषज्ञता प्राप्त है।\\n\\nउद्योग की वर्तमान स्थिति \\nप्रबंधन परामर्श का बहुत तेजी से विकास हुआ है और उद्योग के विकास दर में 1980 और 1990 के दशकों में 20% की वृद्धि हुई है। एक व्यावसायिक सेवा के रूप में परामर्श अत्यधिक चक्रीय और समग्र आर्थिक परिस्थितियों से जुड़ा हुआ है। 2001-2003 की अवधि के दौरान, परामर्श उद्योग में संकुचन हुआ, लेकिन उसके बाद से इसमें धीरे-धीरे उत्तरोत्तर विकास का अनुभव हो रहा है।\\n\\n \\nवर्तमान में, चार मुख्य प्रकार की परामर्श कंपनियां हैं:\\n\\n बड़े और विविध संगठन जो कई तरह की सेवाएं प्रदान करते हैं जिनमें व्यूहात्मक परामर्श प्रथा के अलावा सूचना प्रौद्योगिकी परामर्श भी शामिल है (जैसे एक्सेंचर (Accenture), एबीम कंसल्टिंग (ABeam Consulting), कैपजेमिनी (Capgemini), कॉग्निजैंट (Cognizant), डेलोइट (Deloitte), अर्न्स्ट एण्ड यंग (Ernst & Young), आईबीएम (IBM), केपीएमजी (KPMG), लोजिका (Logica), पीए कंसल्टिंग (PA Consulting), सीएससी (CSC)). कुछ बहुत बड़ी आईटी सेवा प्रदाता कंपनियों ने परामर्श कंपनियों का रूप भी धारण कर लिया है और वे व्यूहात्मक प्रथाएं भी विकसित कर रही हैं (जैसे विप्रो (Wipro), टाटा कंसल्टेंसी सर्विसेज (Tata Consultancy Services), इन्फोसिस (Infosys)) \\n मध्यम आकार की सूचना प्रौद्योगिकी परामर्श कंपनियां, जो कुछ उसी तरह की सेवाओं और प्रौद्योगिकियों के साथ बुटीक शैली को मिश्रित करती हैं जिन्हें बड़े खिलाड़ी अपने ग्राहकों को प्रदान करते हैं।\\n प्रबंधन एवं व्यूहात्मक परामर्श विशेषज्ञ कंपनियां, जो किसी भी उद्योग को प्राथमिक तौर पर व्यूहनीति परामर्श और व्यवसाय ख़ुफ़िया मॉडल (बिज़नेस इन्टैलिजंस मॉडल्स) प्रदान करती हैं (जैसे मैककिंसे एण्ड कंपनी (McKinsey & Company), द बॉस्टन कंसल्टिंग ग्रुप, बेन एण्ड कंपनी (Bain & Company), बूज एण्ड कंपनी, मॉनिटर ग्रुप, ए. टी. कियर्नी (A.T. Kearney), रोलैंड बर्गर स्ट्रेटेजी कंसल्टेंट्स (Roland Berger Strategy Consultants) और आर्थर डी. लिटिल)\\n बुटीक कंपनियां, जिन्होंने विशिष्ट उद्योगों, कार्यात्मक क्षेत्रों या प्रौद्योगिकियों में परामर्श विशेषज्ञता पर अपना ध्यान केंद्रित किया है। उनमें से ज्यादातर बुटीक कंपनियों की स्थापना मशहूर व्यवसाय सिद्धांतकारों ने की थी। ये कंपनियां आम तौर पर छोटे आकार की होती हैं जिनमें 250 से भी कम कर्मचारी काम करते हैं (जैसे केडिस कंसल्टिंग लिमिटेड (Qedis Consulting Ltd), हायरएचेलोन, इंक. (HigherEchelon, Inc.), नॉनप्रोफिट इम्पावरमेंट ग्रुप (Nonprofit Empowerment Group)), जो कम कीमतों पर मदद करती हैं और कभी-कभी बड़ी प्रतिस्पर्धी कंपनियों की तरह नए विचारों की शुरुआत भी करती हैं। अगर उनके पास कोई अनोखी अवधारणा है और वे इसका सफलतापूर्वक विपणन करते हैं, तो वे अक्सर इस भाग से बहुत तेजी से विकास करती हैं या उनके अनुभव में दिलचस्पी रखने वाली बड़ी कंपनियां उन्हें खरीद लेती हैं (जैसे टेक्नोवा इण्डिया प्राइवेट लिमिटेड (Tecnova India Pvt.Ltd.), विस्नोवा (Visnova), सीपीएल बिजनेस कंसल्टेंट्स (CPL Business Consultants)).\\n\\nएक पांचवें प्रकार की उभर रही कंपनी सोर्सिंग सलाहकार कंपनी है, जो इनसोर्सिंग, आउटसोर्सिंग, विक्रेता चयन और अनुबंध बातचीत से संबंधित सोर्सिंग विकल्पों के बारे में खरीदारों को सलाह देती है। शीर्ष 10 सोर्सिंग सलाहकार कंपनियां (ब्लैक बुक ऑफ आउटसोर्सिंग द्वारा दिए गए रैंक के अनुसार) टीपीआई (TPI), गार्टनर (Gartner), हैकेट ग्रुप (Hackett Group), एवरेस्ट ग्रुप (Everest Group), पीडब्ल्यूसी (PwC), अवसंत (Avasant), पीए कंसल्टिंग (PA Consulting) और एक्वा टेरा (EquaTerra) थीं। एक तीव्र विकासशील क्षेत्र होने के बावजूद, सम्पूर्ण रूप से प्रबंधन परामर्श उद्योग पर विचार करने पर इन सबसे बड़ी सोर्सिंग सलाहकार कंपनियों को संभवतः बुटीक कंपनियों के रूप में वर्गीकृत किया जाएगा, जिनमें से एक सबसे बड़ी कंपनी उदाहरण के तौर पर टीपीआई है, जिसकी 2006 की आय, आईएसजी (ISG) द्वारा इसके अधिग्रहण के दौरान, 150 मिलियन अमेरिकी डॉलर से कम थी।\\n\\nपरामर्श कंपनियों में अंतर स्थापित करने का एक और तरीका आय (रेविन्यू) के मॉडल पर आधारित है:\\n\\n1. समय और प्रयास के आधार पर: ज्यादातर कंपनियां समय और प्रयास के आधार पर भुगतान मांगती हैं। वे फीस निर्धारित करने के लिए, विशिष्ट अध्ययनों (केस स्टडीज़) और पिछले रिकॉर्ड का इस्तेमाल करते हैं, जैसे मैककिंसे, बीसीजी (BCG) इत्यादि.\\n\\n2. केवल वितरित परिणामों के आधार पर: बहुत कम और आम तौर पर बुटीक कंपनियां, जिनका सफलता दर काफी अच्छा होता है, इस आधार पर भुगतान मांगती हैं।\\n\\n3. दोनों का संयोजन: कई बड़ी कंपनियां वितरित परिणामों के आधार पर पारिश्रमिक का एक हिस्सा ग्रहण करती हैं। लेकिन आमतौर पर परिवर्तनीय घटक कुल घटकों का केवल 20-30% होता है।\\n\\nचलन \\nप्रबंधन परामर्श गैर-व्यवसाय संबंधित क्षेत्रों में भी अधिक प्रचलित होता जा रहा है। जैसे-जैसे पेशेवर और विशेष सलाह की जरूरत बढ़ती जा रही है वैसे-वैसे सरकारी, अर्ध-सरकारी और लाभरहित एजेंसियां उन्हीं प्रबंधकीय सिद्धांतों की तरफ मुड़ रही हैं जिन्होंने सालों तक निजी क्षेत्र को सहायता दी थी।\\n\\nइक्कीसवीं सदी के प्रारंभिक भाग में आया हुआ एक उद्योग संरचनात्मक चलन, बड़ी विविध पेशेवर सलाहकारी कंपनियों की परामर्श और लेखांकन इकाइयों का उपोत्पाद या अलगाव था, जिनमें एर्न्स्ट एण्ड यंग, पीडब्ल्यूसी और केपीएमजी का नाम सबसे ज्यादा उल्लेखनीय है। लेखांकन और लेखापरीक्षण कंपनियों के रूप में अपने व्यवसाय को शुरू करने वाली इन कंपनियों के लिए प्रबंधन परामर्श उनके व्यवसाय का एक नया विस्तार था। लेकिन लेखांकन प्रथाओं संबंधी कई अतिप्रचारित घोटालों के बाद, जैसे एनरॉन घोटाला, इन कंपनियों ने सख्त नियामक जांच का अधिक आसानी से अनुपालन करने के लिए अपने प्रबंधन परामर्श इकाइयों का अधिकारहरण करना शुरू किया। दुनिया के कुछ भागों में यह चलन अब उल्टा रूप ले रहा है, जहां कंपनियां तेजी से अपने प्रबंधन परामर्श साधनों का फिर से निर्माण कर रही हैं, जैसा कि उनकी कॉर्पोरेट वेबसाइटों में साफ़ दिखाई देता है।\\n\\nआंतरिक कॉर्पोरेट परामर्श समूहों का उदय \\nइन दृष्टिकोणों में निगमों को शामिल किया गया है जो अपने स्वयं के आतंरिक परामर्श समूहों की स्थापना करते हैं, जिसके लिए वे या तो कॉर्पोरेशन अर्थात् निगम से या बाहरी कंपनियों से आतंरिक प्रबंधन सलाहकारों को नियुक्त करते हैं। कई निगमों में 25 से 30 पूर्णकालिक सलाहकारों वाले आतंरिक समूह होते हैं।\\n\\nआतंरिक परामर्श समूहों का निर्माण अक्सर लगभग प्रथा या अभ्यास क्षेत्रों की संख्या के बराबर किया जाता है, जिनमें आम तौर पर निम्न शामिल हैं: संगठनात्मक विकास, प्रक्रिया प्रबंधन, सूचना प्रौद्योगिकी, डिज़ाइन सेवा, प्रशिक्षण और विकास.\\n\\nलाभ \\nआतंरिक सलाहकारों को नियुक्त करने वाली कंपनियों को इन आतंरिक सलाहकारों से कई संभावित लाभ प्राप्त होते हैं:\\n ठीक से प्रबंधित और सशक्तिकरण किए जाने पर आतंरिक परामर्श समूह, निगम के व्यूहात्मक और सामरिक उद्देश्यों की रौशनी में परियोजनाओं की कारगुजारी का मूल्यांकन करते हैं।\\n निगम से परिचित होने की वजह से आतंरिक सलाहकार को परियोजना से वाकिफ होने में अक्सर कम समय लगता है और वह कार्यान्वयन तक परियोजना का मार्गदर्शन करने में सक्षम होते है - यह एक ऐसा चरण है जो बाहरी सलाहकार के इस्तेमाल से अक्सर महंगा साबित हो सकता है।\\n आतंरिक सम्बन्ध कुछ कॉर्पोरेट जानकारी को निजी या गुप्त रखने का अवसर प्रदान करता है।\\n ऐसी सम्भावना है कि आतंरिक सलाहकारों का समय और सामग्री खर्च, समान क्षमता के साथ काम करने वाले बाहरी सलाहकारों की तुलना में काफी कम होता है।\\n संगठन के संभावित वरिष्ठ प्रबंधकों को भर्ती करने और उनका विकास करने के लिए आतंरिक सलाहकार पदों का इस्तेमाल किया जा सकता है।\\n\\nध्यान दें: लागत प्रभावकारिता के मूल्यांकन में, परियोजना के स्तर पर एवं संगठनात्मक स्तर पर, आतंरिक सलाहकार के खर्चों को किस तरह लगाया जाएगा इस बात के प्रति निगमों को जागरूक होना चाहिए और उसके साथ संगत होना चाहिए.\\n\\n आंतरिक सलाहकार अक्सर विशिष्ट रूप से निम्न कार्यों के लिए अनुकूल होते हैं: \\n बाहरी परामर्श परियोजना टीमों का नेतृत्व करने के लिए, या \\n संगठनात्मक प्रबंधन के निर्देश के तहत, बाहरी परामर्श टीमों के साथ \\'अंतःस्थापित\\' संगठनात्मक विषय वस्तु विशेषज्ञों के रूप में काम करने के लिए।\\n\\nआतंरिक सलाहकारों का एक समूह बारीकी से बाहरी परामर्श कंपनियों की निगरानी और उनके साथ काम कर सकता है। यह बेहतर वितरण, गुणवत्ता और समग्र परिचालनीय संबंधों को सुनिश्चित करेगा।\\n\\nपरामर्श सेवाएं प्रदान करने वाली बाहरी कंपनियों में प्राथमिकता के मामले में विरोधाभास रहता है। बाहरी कंपनी की तंदुरुस्ती उनके क्लाइंट (ग्राहक) की तंदुरुस्ती से कुल मिलाकर अधिक महत्वपूर्ण है (हालांकि निश्चित रूप से उनके क्लाइंट की तंदुरुस्ती का उनकी अपनी तंदुरुस्ती पर सीधा असर पड़ सकता है).\\n\\nहानि \\n आंतरिक सलाहकार परामर्श सम्बन्ध में निष्पक्षता नहीं ला सकते हैं, जो कि एक बाहरी कंपनी ला सकती है।\\n आंतरिक सलाहकार अन्य निगमों से बेहतरीन प्रथाओं को भी नहीं ला सकते हैं। इस मुद्दे को कम करने का एक तरीका समूह में अनुभवी व्यक्तियों की नियुक्ति करना और/या आतंरिक सलाहकारों को लगातार विविध प्रशिक्षण प्रदान करना है।\\n जहां परामर्श उद्योग मजबूत है और परामर्श मुआवजा ज्यादा है, वहां उम्मीदवारों की भर्ती करना मुश्किल हो सकता है।\\n आतंरिक परामर्श समूह की लागत और लाभों का सही माप निकालना अक्सर मुश्किल होता है।\\n जब वित्तीय समय खराब होता है तब आर्थिक मूल्य (लागत बनाम लाभ) का प्रभावशाली प्रदर्शन न करने वाले आतंरिक परामर्श समूहों के आकार में संभवतः कटौती करनी पड़ती है या उन्हें फिर से काम सौंपना पड़ता है।\\n\\nसरकारी सलाहकार \\n\\nहाल के दिनों में सरकारी शासन प्रणालियों में प्रबंधन परामर्श का इस्तेमाल काफी बढ़ गया है। बूज एलन हैमिल्टन (अब बूज एण्ड कंपनी से अलग) को खास तौर पर अब एक कंसल्टेंट अर्थात् सलाहकार कंपनी के रूप में अच्छी तरह से जाना जाता है, जो प्राथमिक रूप से अमेरिकी संघीय सरकार की सेवा करती है। डेलोइट कंसल्टिंग एलएलपी (LLP), सरकारी विभागों और एजेंसियों की सबसे ज्यादा मुश्किल समस्याओं के समाधान में, उनकी मदद करने में अपनी उद्योग विशेषता और दशकों के अनुभव का इस्तेमाल करता है।\\nभारत में कृषि वित्त निगम लिमिटेड मुख्य रूप से सरकारी और संबंधित संस्थानों को परामर्श देता है।\\n\\nयूनाइटेड किंगडम \\n\\n1997 से 2006 तक, लेबर (श्रम) सरकारों ने प्रबंधन सलाहकारों के लिए 20 बिलियन पाउंड और आईटी प्रणालियों के लिए कम से कम और 50 बिलियन पाउंड खर्च किया है, जो पिछले रूढ़िवादी (कंज़र्वेटिव) सरकार द्वारा एक साल में खर्च किए गए 500 मिलियन पाउंड से काफी अधिक है। 2003 से 2006 तक सलाहकारों पर किए जाने वाले खर्चों में एक तिहाई वृद्धि हुई है और 2003 से 2004 तक 2.1 बिलियन पाउंड और 2005 से 2006 तक 2.8 बिलियन पाउंड खर्च हुआ है, जिसका मुख्य कारण नैशनल हेल्थ सर्विस द्वारा किए जाने वाले खर्च में वृद्धि है। पिछले तीन सालों में बड़ी परामर्श कंपनियों से परामर्श सेवाओं लिए जाने पर 7.2 बिलियन पाउंड खर्च किया गया है।\\n\\nप्रबंधन परामर्श कंपनियों की रेटिंग \\nवेब सेवा \"vault.com\" हर साल काम करने वाली शीर्ष 50 परामर्श कंपनियों की एक सूची तैयार करती है। रैंकिंग के समय कुछ अन्य विकल्पों के उपरांत कंपनी की सभ्यता, अभ्यास शक्ति, प्रतिष्ठा और मुआवजा (6 प्रतिशत) पर विचार किया जाता है। वर्ष 2011 की शीर्ष 25 कंपनियां इस प्रकार हैं: \\n बेन एण्ड कंपनी (Bain & Company) (8.492) \\n बॉस्टन कंसल्टिंग ग्रुप (The Boston Consulting Group) (8.176) \\n मैककिंसे एण्ड कंपनी (McKinsey & Company) (8.159) \\n एनालिसिस ग्रुप, इंक. (Analysis Group, Inc.) (7.251) \\n द कैम्ब्रिज ग्रुप (The Cambridge Group) (7.178) \\n डेलोइट कंसल्टिंग एलएलपी (Deloitte Consulting LLP) (7.162) \\n ओलिवर वाईमैन (Oliver Wyman) (7.123) \\n एटी कियर्नी (AT Kearney) (7.089) \\n ट्राइएज कंसल्टिंग ग्रुप (Triage Consulting Group) (7.024) \\n सेंसियो कंसल्टिंग ग्रुप (Censeo Consulting Group) (6.903) \\n वेस्ट मोनरो पार्टनर्स (West Monroe Partners) (6.899) \\n कॉर्नरस्टोन रिसर्च (Cornerstone Research) (6.897) \\n प्राइसवाटरहाउसकूपर्स एलएलपी (PricewaterhouseCoopers LLP) (परामर्श प्रथा) (6.890) \\n एल्वरेज़ एण्ड मार्सल (Alvarez & Marsal) (6.844) \\n ट्रिनिटी पार्टनर्स, एलएलसी (Trinity Partners, LLC) (6.840) \\n बूज एण्ड कंपनी (Booz & Company) (6.814) \\n मिलिमैन, इंक. (Milliman, Inc) (6.795) \\n स्ट्रेटेजिक डिसीजंस ग्रुप (Strategic Decisions Group) (6.774) \\n पीआरटीएम (PRTM) (6.769) \\n गैलप कंसल्टिंग (Gallup Consulting) (6.761) \\n डायमंड मैनेजमेंट एण्ड टेक्नोलॉजी कंसल्टेंट्स (Diamond Management & Technology Consultants) (6.753) \\n हेल्थ एडवांसेस, एलएलसी (Health Advances, LLC) (6.729) \\n स्ट्रेटेगोस (Strategos) (6.704) \\n द ब्रेटल ग्रुप (The Brattle Group) (6.696) \\n मॉनिटर ग्रुप (Monitor Group) (6.694)\\n\\nआलोचना \\nलगातार उच्च और बढ़ती आय (रेविन्यू) के बावजूद, प्रबंधन परामर्श कंपनी को लगातार क्लाइंट एवं प्रबंधन विद्वानो से आलोचना मिलती रहती हैं।\\n\\n\"प्रचलित या लोकप्रिय शब्दों (buzzwords) के अत्यधिक इस्तेमाल और प्रबंधन सनकों का प्रचार एवं उन पर निर्भरता और क्लाइंट जिन्हें निष्पादित कर सके एसी योजनाओं को विकसित करने में विफलता की वजह से प्रबंधन सलाहकारों की अक्सर आलोचना की जाती है।\" प्रबंधन परामर्श के बारे में कई महत्वपूर्ण किताबों में यह तर्क दिया गया है कि वास्तव में प्रस्तावित परिवर्तन का निर्माण करने के लिए प्रबंधन परामर्शकारी सलाह और व्यवसाय कार्यकारियों की क्षमता के बीच के बेमेल के परिणामस्वरूप मौजूदा व्यवसायों में काफी नुकसान होता है। क्रिस आर्गिरिस की किताब \"फ्लॉड एडवाइस एण्ड द मैनेजमेंट ट्रैप\" के अनुसार क्रिस आर्गिरिस का विश्वास है कि आजकाल दी जाने वाली सलाहों में से ज्यादातर सलाहों में असली योग्यता का काफी अंश होता है। हालांकि, नज़दीकी अवलोकन से पता चलता है कि आजकल दी जाने वाली ज्यादातर सलाहों में अंतराल और विसंगतियां होती हैं, जो भविष्य में सकारात्मक परिणामों को रोक सकती हैं।\\n\\nबहुत ज्यादा फीस के बावजूद, अप्रतिष्ठित परमार्श कंपनियों पर अक्सर खाली वादे करने का आरोप लगाया जाता है। उन पर अक्सर \"स्पष्टवादी\" न होने और उनकी सलाह जिस आधार पर कही जानी चाहिए उस अनुभव का अभाव होने का आरोप लगाया जाता है। ये सलाहकार बहुत कम नवाचार लाते है और उसकी बजाय साधारण और \"पूर्वपैकेज्ड\" व्यूहनीतियां और योजनाएं प्रदान करते हैं, जो क्लाइंट के विशेष उपयोग की दृष्टि से अप्रासंगिक होते हैं। वे क्लाइंटों के सामने, उनसे पहले अपनी कंपनी के हितों को रखकर, अपनी जिम्मेदारियों को प्राथमिकता देने में विफल हो सकते हैं।\\n\\nएक और चिंता का विषय परामर्श कंपनियों द्वारा परिणामों की स्थिरता पर दिया जाने वाला वादा है। क्लाइंट और परामर्श कंपनियों के बीच के कामकाज के अंत में, अक्सर इस बात की उम्मीद रहती है कि सलाहकार अपने प्रयास टिकाउ है एसा सुनिश्चित करने के लिए कुछ समयावधि तक परियोजना के परिणामों का लेखा परीक्षण करेंगे। हालांकि कुछ परामर्श कंपनियों द्वारा धारणीयता (sustainability) को बढ़ावा दिए जाने के बावजूद, परियोजना के बंद होने के बाद क्लाइंट और परामर्श कंपनियों के बीच सम्बन्ध विच्छेद की वजह से, इसे लागू करना मुश्किल होता है।\\n\\nअतिरिक्त आलोचनाओं में शामिल हैं: लागत में कटौती करने के अभियान में व्यवसाय (कर्मचारियों को काम से निकालकर) का अलगाव, केवल विश्लेषण रिपोर्ट प्रदान करना, जूनियर सलाहकार सीनियर सलाहकारों की दर से भुगतान मांगते हैं, \"कस्टम कार्य\" के रूप में कई क्लाइंटों को एक ही तरह के रिपोर्टों को फिर से बेचना, नवाचार का अभाव, उन दिनों के लिए ओवरबिलिंग करना जब काम नहीं किया गया है, गुणवत्ता के मूल्य पर गति, अनुत्तरदायी बड़ी कंपनियां और (छोटे) क्लाइंट पर ध्यान देने का अभाव, अनुबंधों में परिणामों विषयक स्पष्टता का अभाव और गोपनीयता.\\n\\nपेशेवर/व्यावसायिक योग्यता \\n\\nऐसी कई योग्यताएं हैं जिसके दम पर कोई एक प्रबंधन सलाहकार बन सकता है; उनमें शामिल हैं:\\n\\n अंतरराष्ट्रीय स्तर पर मान्यता प्राप्त सर्टिफाइड मैनेजमेंट कंसल्टेंट (सीएमसी (CMC)) पेशेवर पदनाम\\n एकाउंटेंसी योग्यताएं: एएएफएम (AAFM) से चार्टर्ड मैनेजमेंट एकाउन्टेंट (सीआईएमए (CIMA)), चार्टर्ड सर्टिफाइड एकाउन्टेंट (एसीसीए (ACCA)), चार्टर्ड एकाउन्टेंट (सीए (CA)), सर्टिफाइड पब्लिक एकाउन्टेंट (सीपीए (CPA)), सर्टिफाइड प्रैक्टिसिंग एकाउन्टेंट (सीपीए (CPA)), सर्टिफाइड मैनेजमेंट एकाउन्टेंट (सीएमए (CMA)), चार्टर्ड कोस्ट एकाउन्टेंट (सीसीए (CCA))\\n इंजीनियरिंग योग्यताएं: चार्टर्ड इंजीनियर (सी. इंग्लैंड - यूके) प्रोफेशनल इंजीनियर (पीई / पी. इंग्लैंड - संयुक्त राज्य अमेरिका और कनाडा), इंजीनियर डिप्लोमा ग्रांडे इकोले (फ्रांस)\\n बीमांकिक योग्यताएं: कैजुएल्टी एक्चुअरियल सोसाइटी (एफसीएएस (FCAS))- अमेरिका, सोसाइटी ऑफ एक्चुअरिज़ (एफएसए (FSA)) - अमेरिका, इंस्टिट्यूट ऑफ एक्चुअरिज़ (एफआईए (FIA)) - ब्रिटेन, फैकल्टी ऑफ एक्चुअरिज़ (एफएफए (FFA)) - स्कॉटलैंड\\n वित्त योग्यताएं: चार्टर्ड फाइनेंशियल एनालिस्ट (सीएफए (CFA)), सर्टिफाइड ट्रेज़री प्रोफेशनल (सीटीपी (CTP))\\n परामर्श योग्यताएं: व्यवसाय परामर्श में मास्टर ऑफ साइंस (एमएससी (MSc)), फर्टवैंगेन यूनिवर्सिटी ऑफ एप्लाइड साइंसेस, जर्मनी / मास्टर ऑफ बिजनेस एडमिनिस्ट्रेशन इन इंटरनैशनल बिजनेस कंसल्टिंग (एमबीए (MBA)) होचशल ओफेनबर्ग युनिवारिसिती ऑफ एप्लाइड साइंसेस, जर्मनी\\n बिजनेस एडमिनिस्ट्रेशन योग्यताएं: मास्टर ऑफ साइंस इन मैनेजमेंट - यूरोप - (एमएससी इन मैनेजमेंट), मास्टर इन मैनेजमेंट एट ग्रांडे इकोले - फ़्रांस, मास्टर ऑफ बिजनेस एडमिनिस्ट्रेशन (एमबीए) - यूएसए कनाडा डॉक्टर ऑफ मैनेजमेंट (पीएचडी), डॉक्टर ऑफ बिजनेस एडमिनिस्ट्रेशन - यूएसए/कनाडा - (डीबीए (DBA)) \\n पब्लिक एडमिनिस्ट्रेशन योग्यताएं: मास्टर ऑफ पब्लिक एडमिनिस्ट्रेशन (एमपीए (MPA)) - यूएसए/कनाडा/यूरोप, डॉक्टर ऑफ पब्लिक एडमिनिस्ट्रेशन\\n प्रोजेक्ट मैनेजमेंट योग्यताएं: विश्व स्तर पर मान्यता प्राप्त प्रोजेक्ट मैनेजमेंट प्रोफेशनल (पीएमपी (PMP)), मास्टर ऑफ प्रोजेक्ट मैनेजमेंट (एमपीएम (MPM)) - यूएसए/कनाडा/यूरोप\\n उन्नत पेशेवर उपाधियां जैसे पीएचडी या मास्टर्स डिग्री इन इंजीनियरिंग एण्ड साइंस, एमडी, जेडी इत्यादि को विशिष्ट रूप से मैककिंसे, बेन एण्ड कंपनी, आर्थर डी. लिटिल और बॉस्टन कंसल्टिंग ग्रुप जैसी कंपनियों द्वारा मांगी जाती है। ये उपाधियां (डिग्रियों) प्रबंधन परामर्श, अंतर्राष्ट्रीय प्रबंधन, या अन्य प्रासंगिक फोकस में भी हो सकती है।\\n अकाडेमिशर अंटरनेहमेंसबेरेटर (Akademischer Unternehmensberater) (एकाडेमिक मैनेजमेंट कंसल्टेंट) - ऑस्ट्रिया - इन्साइट - इंस्टिट्यूट फॉर मैनेजमेंट कंसल्टेंट्स एण्ड इन्फोर्मेशन टेक्नोलॉजी एक्सपर्ट्स, वियना\\n विपणन योग्यताएं: चार्टर्ड पोस्टग्रेजुएट डिप्लोमा इन मार्केटिंग, जिसके फलस्वरूप द चार्टर्ड इंस्टिट्यूट ऑफ मार्केटिंग (सीआईएम (CIM)) से चार्टर्ड मार्केटर का दर्जा मिल सकता है\\n परामर्श योग्यताएं: मल्टीडाइमेन्शनल ह्यूमन फैक्टर मैनेजमेंट कंसल्टिंग (एमडीएचएफएम (MDHFM) मल्टीडाइमेन्शनल ह्यूमन फैक्टर मैनेजमेंट स्कूल जर्मनी बाई लुईस डैनियल मालडोनैडो फोंकेन-\\n\\nइन्हें भी देखें\\n\\nकंपनियों की सूची \\n प्रबंधन परामर्श कंपनियों की सूची\\n :Category:Management consulting firms\\n\\nपरामर्श के कार्यक्षेत्र \\n व्यूहात्मक प्रबंधन\\n परिचालन प्रबंधन\\n औद्योगिक इंजीनियरिंग\\n\\nसंबंधित संस्कृति \\n मामला साक्षात्कार\\n अभिप्रेरक प्रवचन\\n व्यवसाय प्रशिक्षण\\n प्रबंधन सनक\\n व्यवसाय दर्शन और लोकप्रिय प्रबंधन सिद्धांत उप प्रणाली संगठन और सम्पूर्ण प्रबंधन संस्कृति पर प्रभाव\\n\\nसंस्थान \\n इंस्टिट्यूट ऑफ बिजनेस कंसल्टिंग यूके (UK)\\n मैनेजमेंट कंसल्टेंसीज एसोसिएशन यूके (UK)\\n इंस्टिट्यूट ऑफ मैनेजमेंट कंसल्टेंट्स यूएसए (USA)\\n फिलिप्स ग्रेजुएट इंस्टिट्यूट\\n सीएमसी-कनाडा\\n इंटरनैशनल काउंसिल ऑफ मैनेजमेंट कंसल्टिंग इंस्टिट्यूट्स\\n\\nसन्दर्भ\\n\\nबाहरी कड़ियाँ\\n एसोसिएशन ऑफ मैनेजमेंट कंसल्टिंग फर्म्स (एएमसीएफ (AMCF))\\n मैनेजमेंट कंसल्टेंसीज एसोसिएशन\\n अमेरिका में प्रबंधन परामर्श कंपनियों की सूची\\n\\nअतिरिक्त पठन \\n\\n \"व्हाट क्लाइंट्स डोंट टेल मैनेजमेंट कंसल्टेंट्स इन कंसल्टिंग: व्हाट कंसल्टेंट्स शुड डू, व्हाट क्लाइंट्स शुड नो\", वाई क्वान लू द्वारा, ऑथर्स ऑनलाइन (Authors OnLine), 2008, ISBN 0-7552-0438-7 \\n \"टूल्स फॉर प्रोजेक्ट मैनेजमेंट, वर्कशॉप्स एण्ड कंसल्टिंग\", निकोलाई एंडलर्स द्वारा, (2008) पब्लिसिस पब्लिशिंग एर्लैंगेन (Publicis Publishing Erlangen), ISBN 978-3-89578-302-9\\n क्रिटिकल कंसल्टिंग: न्यू पर्सपेक्टिव्स ऑन द मैनेजमेंट एडवाइस इंडस्ट्री, संस्करण, टिमोथी क्लार्क और रोबिन फिन्चम द्वारा, ब्लैकवेल पब्लिशर्स (Blackwell Publishers), 2001, ISBN 0-631-21820-3\\n मैनेजमेंट कंसल्टेंसी - बाउंडरीज एण्ड नॉलेज इन एक्शन, एंड्रियू स्टर्डी, करेन हैंडली, टिमोथी क्लार्क और रोबिन फिन्चम द्वारा, ऑक्सफोर्ड यूनिवर्सिटी प्रेस (Oxford University Press), 2009, ISBN 978-0-19-921264-4.\\n\\nश्रेणी:प्रबंधन\\nश्रेणी:परामर्श\\nश्रेणी:व्यूहात्मक प्रबंधन'},\n",
       "  {'docid': 'doc-hi-12',\n",
       "   'text': 'अन-नस्र\\nसूरा अन-नस्र (इंग्लिश: An-Nasr) इस्लाम के पवित्र ग्रन्थ कुरआन का 110 वां सूरा (अध्याय) है। इसमें 5 आयतें हैं।\\n\\nनाम\\nइस सूरा के अरबी भाषा के नाम को क़ुरआन के प्रमुख हिंदी अनुवाद में सूरा अन्-नस्र और प्रसिद्ध किंग फ़हद प्रेस के अनुवाद में भी सूरा अन्-नस्र \\nनाम दिया गया है।\\n\\nनाम पहली ही आयत “जब अल्लाह की मदद (नस्र) आ जाए\" के शब्द \\'नस्र\\' को इस सूरा का नाम दिया गया है।\\n\\nअवतरणकाल\\n\\nमदनी सूरा अर्थात पैग़म्बर मुहम्मद के मदीना के निवास के समय हिजरत के पश्चात अवतरित हुई।\\n\\nविद्वान मौलाना सैयद अबुल आला मौदूदी लिखते हैं कि\\nहज़रत अब्दुल्लाह बिन अब्बास (रजि.) का बयान है कि यह कुरआन मजीद की अन्तिम सूरा है अर्थात् सिके पश्चात कुछ आयतें तो अवतरित हुई, किन्तु कोई पूर्ण सूरा नबी (सल्ल.) पर अवतरित नहीं हुई। (हदीस : मुस्लिम , नसी, तबरानी, इब्ने अबी शैबा, इब्ने मरदूयह) हज़रत अब्दुल्लाह बिन उमर से उल्लिखित है कि यह सूरा हिज्जतुल-विदाअ (नबी सल्ल. का अन्तिम हज) के अवसर पर अय्यामे- तशरीक़ (क़ुरबानी के तीन दिन) के मध्य में मिना के स्थान पर अवतरित हुई और इसके पश्चात् नबी (सल्ल.) ने अपनी ऊँटनी पर सवार होकर अपना प्रसिद्ध अभिभाषण दिया, (हदीस : तिरमिज़ी , बज़्जार , बैहक़ी)। (इस अभिभाषण में लोगों को यह याद दिलाने के बाद कि) “ यह अय्यामे तशरीक़ के मध्य का दिन है और यह \\' मशअरे हराम \\'(स्थान विशेष) है। नबी (सल्ल.) ने कहा कि मैं नहीं जानता, शायद इसके बाद में तुमसे न मिल सकूँ। सावधान रहो, तुम्हारे खून, तुम्हारी इज़्ज़तें एक दूसरे पर उसी तरह हराम हैं जिस तरह यह दिन और यह स्थान हराम है। यहाँ तक कि तुम अपने प्रभु के सामने उपस्थित हो और वह तुमसे तुम्हारे कर्मों के बारे में पूछगछ करे। सुनो, यह बात तुममें से निकटवाला दूरवाले तक पहुँचा दे; सुनो क्या मैंने तुम्हें पहुंचा दिया? \"इसके बाद जब हम लोग मदीना लौटे तो कुछ अधिक दिन नहीं बीते थे कि नबी (सल्ल.) का देहान्त हो गया।इन दोनों रिवायतों (उल्लेखों) को मिलाकर देखा जाए तो मालूम होता है कि सूरा ‘नस्र\\' के अवतरण और अल्लाह के रसूल (सल्ल.) के दुनिया से प्रस्थान करने के मध्य तीन महीने कुछ दिन का अन्तराल था, क्योंकि इतिहास की दृष्टि से हिज्जतुल विदाअ और हुजूर (सल्ल.) के देहावसान के मध्य इतना ही समय गुज़रा था। इब्ने अब्बास (रजि.) का बयान है कि जब यह सूरा अवतरित हुई तो नबी (सल्ल.) ने फ़रमाया कि मुझे मेरी मृत्यु की ख़बर दे दी गई है और मेरा समय पुरा हुआ (मुस्नद अहमद, इब्ने ज़रीर, इब्ने मुज़िर, इब्ने मरदूयह)। दूसरे उल्लेखों, जो हज़रत अब्दुल्लाह बिन अब्बास (रजि.) से उद्धृत हुए हैं, में बयान किया गया है कि इस सूरा के अवतरण से नबी (सल्ल.) ने यह समक्ष लिया था कि आपको संसार से विदा होने की सूचना दे दी गई है (हदीस : मुस्लिम, मुस्नद अहमद, इब्ने जरीर , तबरानी , नसई)।\\n\\nविषय और वार्ता \\nइस्लाम के विद्वान मौलाना सैयद अबुल आला मौदूदी लिखते हैं कि\\nजैसा कि उपर्युक्त उल्लेख से मालूम होता है , इसि सूरा में अल्लाह ने अपने रसूल (सल्ल.) को यह बताया था कि जब अरब में इस्लाम की विजय पूर्ण हो जाए और अल्लाह के दीन (धर्म) में लोग दल -के- दल प्रवेश करने लगे, तो इसका अर्थ यह है कि यह काम पूरा हो गया जिसके लिए आप संसार में भेजे गए थे। तदन्तर आपको आदेश दिया गया कि आप अल्लाह की स्तुति और उसकी महानता का वर्णन करने में लग जाएँ कि उसकी उदार कृपा से आप इतना बड़ा काम सम्प्न करने में सफल हुए और उससे प्रार्थना करें कि इस सेवा के करने में जो भूल-चूक या कोताही भी आपसे हुई हो, उसे वह क्षमा कर दे। हज़रत आइशा (रजि.) कहती है कि अल्लाह के रसूल (सल्ल.) अपने देहान्त से पहले “सुब्हा न - कल्लाहुम - म व बिहमदि - क , अस्तग़फ़िरु - क व अतूबु इलैक\" (तेरी स्तुति हो ऐ अल्लाह , मैं तुझसे क्षमा - याचना करता हूँ और तेरी ही ओर लौटता हूँ।) (कुछ उल्लेखों में ये शब्द आए हैं , “ सुब्हानल्लाहि व बिहमदिही अस्तग़फ़िरुल्लाहि व अतूबु इलैह\") बहुत अधिक पढ़ा करते थे । मैंने कहा , “ऐ अल्लाह के रसूल! ये कैसे शब्द है जो आपने अब पढ़ने आरम्भ कर दिए हैं? \\' \\'तो कहा कि मेरे लिए एक लक्षण निश्चित कर दिया गया है। जब मैं उसे देखू तो ये शब्द कहा करूं और वे हैं, \"जब अल्लाह की सहायता आ जाए और विजय प्राप्त हो जाए” (हदीस: मुस्नद अहमद , मुस्लिम , इब्ने जरीर)। (इसके अतिरिक्त कुछ और ईश- स्मरण के शब्द भी हदीसों में उल्लिखित हैं जो आप (सल्ल.) अपने जीवन के अन्तिम दिनों में अधिकतर उच्चारित किया करते थे।) इब्ने अब्बास (रजि.) का बयान है कि इस सूरा के अवतरित होने के बाद अल्लाह के रसूल (सल्ल.) परलोक के लिए परिश्रम और तपस्या करने में इतनी कड़ाई के साथ व्यस्त हो गए जितने इनसे पहले कभी न हुए थे। (हदीस: नसई, तबरानी, इब्ने अबी हातिम , इब्ने मरदूयह)\\n\\nसुरह\\xa0\"अन-नस्र\\'\\' का अनुवाद\\nबिस्मिल्लाह हिर्रह्मा निर्रहीम \\nअल्लाह के नाम से जो दयालु और कृपाशील है।\\n\\nइस सूरा का प्रमुख अनुवाद:\\n\\nक़ुरआन की मूल भाषा अरबी से उर्दू अनुवाद\\xa0\"मौलाना मुहम्मद फ़ारूक़ खान\", उर्दू से हिंदी \"मुहम्मद अहमद\" ने किया:\\n\\nبسم الله الرحمن الرحيم\\n\\n\\u06dd जब अल्लाह की सहायता आ जाए और विजय प्राप्त हो,\\xa0(110:1)\\n\\n\\u06dd और तुम लोगों को देखो कि वे अल्लाह के दीन (धर्म) में गिरोह के गिरोह प्रवेश कर रहे है,\\xa0(110:2)\\xa0\\n\\n\\u06dd तो अपने रब की प्रशंसा करो और उससे क्षमा चाहो। निस्संदेह वह बड़ा तौबा क़बूल करने वाला है\\xa0(110:3)\\n\\nबाहरी कडियाँ\\nइस सूरह का प्रसिद्ध अनुवादकों द्वारा किया अनुवाद क़ुरआन प्रोजेक्ट पर देखें\\nAn-Nasr 110:1\\n\\n क़ुरआन के अनुवाद 92 भाषाओं में\\n\\nसन्दर्भ\\n\\nइन्हें भी देखें\\nक़ुरआन\\nमुहम्मद\\nवही\\nआयत (क़ुरआन)\\nसूरा\\nक़ुरआन का हिन्दी अनुवाद\\nइस्लामी शब्दावली\\n\\nश्रेणी:सूरा'},\n",
       "  {'docid': 'doc-hi-13',\n",
       "   'text': 'मलिक अंबर\\nमलिक अंबर का जन्म संभवत: 1549 में एक हब्शी परिवार में हुआ। बाल्यकाल में ही उसे दास बनाकर बगदाद के बाजार में ले जाकर ख्वाजा पीर बगदाद के हाथों बेचा गया। ख्वाज़ा मलिक अंबर के साथ दक्षिण भारत गया जहाँ उसे निजामशाह प्रथम के मंत्री चंगे़ज खाँ ने खरीद लिया। मलिक अंबर की बुद्धि कुशाग्र, प्रकृति प्रतिभायुक्त और उदार थी, अत: उसे अन्य गुलामों की अपेक्षा ख्याति पाने में देर न लगी। चंगेज खाँ के संरक्षण में रहकर निज़ामशाही  राजनीति तथा सैनिक प्रबंध को समझने का उसको अवसर प्राप्त हुआ। चंगेज खाँ की आकस्मिक मृत्यु होने के कारण वह कुछ समय तक इधर-उधर निजामशाही राज्य में ठोकरें खाता रहा। निजामशाही राज्य पर काले बादलों को आच्छादित होते देखकर तथा दलबंदी के संताप और मुगलों के निरंतर आक्रमणों से भयभीत होकर ख्याति पाने की आशा से वह बीजापुर और गोलकुंडा गया परंतु जब इन राज्यों में भी यथेष्ट सुअवसर प्राप्त न हुआ तक वह अन्य हब्शियों के साथ फिर अहमदनगर लौट आया। वह सेना में भरती हुआ और पूनः सकी शादी हुई एक दहुना नाम की औरत से फिर अमँग खाँ ने 150 अश्वारोहियों का सरदार नियुक्त किया। वह अपने आश्रयदाता के साथ चुनार पहुँचा और उसने मुगल आक्रमणकारियों को परेशान करना प्रारंभ किया। शत्रु के शिविरों पर छापा मारकर वह रसद लूट लेता था और उसके प्रदेश में घुस पड़ता था। इस प्रकार धीरे-धीरे उसकी ख्याति बढ़ने लगी। \\n\\nपरंतु जब अहमदनगर पर मुगलों का अधिकार हो गया और निजामशाही राज्य अपनी अंतिम साँसें ले रहा था तब मलिक अंबर को अपने अदम्य साहस, शक्ति एवं गुणों का परिचय देने का अवसर मिला। मराठों की सहायता से उसने एक सेना का निर्माण करके निजामशाही परिवार के अली नाम के व्यक्ति को गद्दी पर बिठाकर परेंदा में नवीन राजधानी स्थापित की। ह्रासग्रस्त राज्य का पुन: संगठन करके और सुख शांति के वातावरण का प्रतिपादन करके उसने एक नवीन जाग्रति पैदा कर दी। निजामशाही राज्य पुन: प्रभुता तथा ऐश्वर्य की ओर उन्मुख हो गया। परिस्थिति उसके अनुकूल थी। राजकुमार सलीम के अकस्मात् विद्रोह के कारण मुगल सेना का दक्षिण से हटना अनिवार्य हो गया था। फलत: मलिक अंबर ने मुगलों द्वारा विजय किए हुए प्रदेशों पर अपना अधिकार करना प्रारंभ कर दिया और अहमदनगर, प्राय: समस्त दक्षिण भाग, हस्तगत कर लिया। परंतु शीघ्र ही उसको एक अन्य कठिनाई का सामना करना पड़ा। सआदत खाँ ने, जो निजामशाही सरदार था, मुगलों की अधीनता स्वीकार कर ली। यह देखकर उसके एक अनुधर राजू ने उसके अधिकृत प्रदेश पर अपना अधिकार जमा लिया और उसने मुगलों से टक्कर लेना प्रारंभ कर दिया। वह भी परेंदा आया पर अन्य निज़ामशाही सेवकों में सम्मिलित हो गया। परंतु आशाजनक पद न पाने के कारण क्रुद्ध होकर वह अपने प्रदेश को वापस चला गया और वहाँ से निजामशाह को अंबर के विरुद्ध भड़काना प्रारंभ किया। फलस्वरूप, अंबर और राजू दोनों एक दूसरे के शत्रु हो गए। लेकिन अपने क्षेत्रों में दोनों मुगलों का मुकाबला करते रहे। इसके बावजूद 1605 तक मलिक अंबर की परिस्थिति दृढ़ ही होती गई।\\n\\nमुगलों की संपूर्ण अहमदनगर राज्य से निकालकर उसने परेंदा को छोड़ दिया और जुन्नार में नई राजधानी बनाई। राजू को परास्त कर उसने बंदी बना लिया और फिर मौत के घाट उतार दिया, तथा उसकी जागीर पर भी अधिकार कर लिया। मुगलों से टक्कर लेते लेते उसने खानेखाना को लोहे के चने चबवा दिए। अपने सेनाध्यक्ष खानेखाना की असफलता पर जहाँगीर को क्रोध आया और इसका कारण जानने के हेतु खानेखाना को दरबार में बुलाया गया। आगरा पहुँचकर खानेखाना ने विषम परिस्थिति का ब्योरा दिया, अतएव मलिक अंबर की बढ़ती हुई सत्ता का दमन करने के अभिप्राय से वह पुन: दक्षिण भेजा गया।\\n\\nअब मलिक अंबर ने बीजापुर और गोलकुंडा से सहायता ली और मुगलों पर टूट पड़ा। उसने खानेखाना की योजना को असफल कर दिया। विवश होकर सम्राट् ने राजकुमार और आसफ खाँ को एक बड़ी सेना के साथ दक्षिण भेजा पर उसे भी कोई सफलता न मिली। मलिक अंबर की शक्ति दिन-प्रति-दिन बढ़ती गई और 1610 में समस्या इतनी गंभीर हो गई कि आसफ खाँ ने सम्राट् से अनुरोध किया कि वह स्वयं ही पधारें। जहाँगीर ने इस सुझाव पर विचार किया और दक्षिण प्रस्थान करने की बात सोची परंतु अन्य अमीरों ने इसका समर्थन न किया। अब दक्षिण की समस्या के हल का उत्तरदायित्व खानेजहाँ को सौंपा गया। परंतु इसके पूर्व कि वह वहाँ पहुँचे खानेखाना ने, अपने बेटों की मदद से वर्षा ऋतु में मलिक अंबर पर अचानक हमले की योजना बनाकर उसपर हमला कर दिया। मलिक अंबर तो तैयार ही बैठा था। उसने मुगलों के छक्के छुड़ा दिए और खानेखाना को बुरहानपुर लौटने पर बाध्य कर दिया। उसको एक संधि पर हस्ताक्षर भी करने पड़े। तत्पश्चात् मलिक अंबर ने अहमदनगर के निकटवर्ती प्रदेशों पर अधिकार करके उसके किले पर घेरा ढाला और उसको भी छीन लिया। बरार और वालाकाट के कुछ भागों को छोड़कर लगभग संपूर्ण निजामशाही राज्य, जिसपर मुगलों ने 1600-1601 में अपना अधिकार जमा लिया था, अब मलिक अंबर ने उनके हाथों से छीन लिया और निजामशाही वंश के राज्य को पुनर्जीवन प्रदान किया।\\n\\nखानजहाँ लोदी ने प्रदेश में पहुँचकर वहाँ के वातावरण से परिचित होने का प्रयास किया। उसने सम्राट् को यह सुझाव दिया कि खानेखाना को हटाकर सेनापति पद का भार उसको ही सौंपा जाए। उसने वचन दिया कि यदि उसका प्रस्ताव स्वीकार कर लिया गया तो वह अहमदनगर तथा बीजापुर के राज्यों पर मुगल सत्ता दो वर्षों के भीतर ही स्थापित कर देगा। जहाँगीर ने उसकी बातें मान लीं और उसे प्रचुर धन और सेना दी। फिर भी जब वह मलिक अंबर के विरुद्ध मैदान में उतरा, तब उसे यह प्रतीत हुआ कि यद्यपि शत्रु की तलवार उसकी तलवार से भारी नहीं, तथापि उसके लड़ने का ढंग अवश्य ही निराला है। कहने का तात्पर्य यह कि उसे भी मलिक अंबर के सामने झुकना पड़ा और उसका गर्व चूर चूर हो गया। मलिक अंबर को परास्त करने के अभिप्राय से सम्राट् ने एक विशाल योजना बनाई जिसका यह उद्देश्य था कि अहमदनगर पर तीन दिशाओं से एक साथ सैनिक अभियान करके मलिक अंबर को घेरकर उसकी सत्ता को नष्ट भ्रष्ट कर दिया जाए। परंतु यह योजना भी असफल सिद्ध हुई और शाही सेना अस्तव्यस्त होकर भाग खड़ी हुई। खोई प्रतिष्ठा को पुन: प्राप्त करने के उद्देश्य से खानेखाना को फिर दक्षिण क्षेत्र में भेजा गया। वह वहाँ 1612 ई में पहुँचा। उसका यह सौभाग्य था कि इस समय निजामशाह के दरबार में आंतरिक फूट फैली थी। इस परिस्थिति से लाभान्वित होकर उसने अनेक दक्षिणी सरदारों को घूस देकर अपने पक्ष में कर लिया। यद्यपि मलिक अंबर को बीजापुर और गोलकुंडा का सहयोग प्राप्त था, तिसपर भी कूटनीति और सबल सेना के सामने उसकी कुछ न चली। 1616 ई के युद्ध में उसे हार खानी पड़ी। विजेताओं ने किर्की को नष्ट-भ्रष्ट कर डाला। यद्यपि खानेखाना ने मुगल प्रतिष्ठा को एक सीमा तक फिर से स्थापित कर दिया था, परंतु उसपर घूसखोरी के आरोप लगते ही रहे। इसीलिए सम्राट् ने राजकुमार खुर्रम को एक विशाल सेना के साथ दक्षिण क्षेत्र में भेजा। राजकुमार के आगमन से दक्षिणी राज्यों में खलबली मच गई। शीघ्र ही बीजापुर तथा गोलकुंडा के नरेशों ने मुगलों से संधि कर ली। ऐसी दशा में जबकि मलिक अंबर मित्रहीन हो गया, उसके समक्ष सर झुकाने के अतिरिक्त कोई अन्य उपाय नहीं रह गया। अतएव विवश होकर उसने बालाघाट का क्षेत्र और अहमदनगर के दुर्ग की कुंजी मुगलों को सौंप दी और इस प्रकार निजामशाही राज्य को लोप होने से बचा लिया।\\n\\nअगले दो वर्षों तक वह चुपचाप अपने साधनों को जुटाने में लगा रहा। इधर मुगल सेना में विद्वेष की प्रचंड अग्नि प्रवाहित हो गई। अत: मलिक अंबर ने पुन: गोलकुंडा और बीजापुर को मिलाकर मुगल विरोधी संघ स्थापित कर लिया। दो वर्ष पूर्व हुई संधि की धाराओं का उल्लंघन कर वह मुगल अधिकृत क्षेत्रों पर टूट पड़ा और तीन मास की लघु अवधि में ही उसने मुगलाई अहमदनगर के अधिकांश भाग और बरार को हस्तगत कर लिया। उसने न केवल बालापुर को लूटा ही बल्कि उसपर घेरा भी डाला। बुरहानपुर की दिशा में पीछे हटती हुई मुगल सेनाओं पर निरंतर वार करता हुआ वह बुरहानपुर तक बढ़ गया। नगर के बाहर घेरा डाला और निकटवर्ती प्रदेश को खूब लूटा। इतना ही नहीं, उसने मालवा में प्रवेश करके मांडू पर भी छापा मारा। इससे नर्मदा के उत्तर और दक्षिण क्षेत्रों में मुगलों की ख्याति को बहुत धक्का लगा।\\n\\nपरिस्थिति को निरंतर गंभीर होते हुए देखकर खानेखाना ने सैनिक सहायता की बार बार याचना की। सम्राट् ने राजकुमार शाहजहाँ को यह आदेश दिया वह सेना सहित दक्षिण को प्रस्थान करे। उसके वहाँ पहुँचते ही वातावरण शीघ्रता से बदलने लगा। उसकी सेना आँधी के समान शत्रु के देश पर आच्छादित हो गई। मराठे मांडू से भाग खड़े हुए और शत्रु को बुरहानपुर को दुर्ग भी खाली करना पड़ा। मुगलों ने अब किर्की पर धावा बोल दिया। संभवत: निज़ामशाह अपने परिवार सहित आक्रमणकारियों के हाथ पड़ जाता परंतु मलिक अंबर ने उन लोगों को दौलताबाद भेज दिया था। किर्की से चलकर मुगल सेना अहमदनगर पहुँची और उसको घेरे से मुक्त किया। मलिक अंबर दौलताबाद के दुर्ग से अपने दुर्भाग्य की गतिविधि को देख रहा था।\\n\\nकुछ विपरीत परिस्थितियों के कारण शाहजहाँ इस युद्ध को आगे बढ़ाना नहीं चाहता था। इसलिए उसने संधि करना ही उचित समझा। मलिक अंबर ने उस समस्त क्षेत्र को वापस कर दिया जो उसने गत दो वर्षों में मुगलों से छीन लिया था। इसके अतिरिक्त 14 कोस निकटवर्ती भूमि भी दी। तीनों दक्षिणी रियासतों ने 50 लाख रुपया कर के रूप में देने का वचन दिया 20 लाख गोलकुंडा ने और शेष 12 लाख अहमदनगर ने। इस प्रकार बड़े चातुर्य से मलिक अंबर ने निजामशाही राज्य को काल के मुँह से पुन: निकाल लिया। परंतु उसकी विपत्तियों का अंत न हुआ। फिर भी उसके साहस में कमी न आई।\\n\\nशाहजहाँ ने अपने पिता के प्रति विद्रोह करके मुगल साम्राज्य में राजनीतिक भूकंप पैदा कर दिया। अतएव जब उत्तर में परास्त होकर वह दक्षिण प्रदेश में पहुँचा और उसने मलिक अंबर से सहायता की याचना की, तब सम्राट् की शत्रुता मोल लेने के भय से मलिक अंबर ने इनकार कर दिया। परंतु इसके पीछे नीति भी थी। शोलापुर को लेकर निजामशाह और आदिलशाह में झगड़ा चल रहा था। उसमें उसको मुगलों की सहानुभूति प्राप्त करने की आशा थी। अतएव जब महावत खाँ शाहजहाँ का पीछा करते हुए दक्षिण प्रदेश में पहुँचा, तब आदिलशाह और मलिक अंबर दोनों ने ही मुगलाई सहायता के लिए याचना की। कुछ समय तक तो महावत खाँ ने दोनों को द्विविधा में रखा, परंतु तब शाहजहाँ बंगाल की ओर भाग गया तब मुगल सेनापति ने आदिलशाह को सहायता देने का वचन दिया। परंतु शीघ्र ही उसे बंगाल की ओर जाना पड़ा।\\n\\nइस सुअवसर से मलिक अंबर ने पूरा लाभ उठाया। सुरक्षा हेतु निजामशाह को तो उसने सपरिवार दौलताबाद भेज दिया और स्वयं सेना लेकर गोलकुंडा की सीमा की ओर बढ़ा। कुतुबशाह से धन लेकर संधि करके वह आदिलशाही प्रदेश पर टूट पड़ा। वांछित स्थानों पर अधिकार करके वह बीजापुर की ओर लूटता हुआ अग्रसर होने लगा। आदिलशाह ने मुगलों से सहायता माँगी। भाटवाड़ी की लड़ाई में मुगल आदिलशाही सेना ने मलिक अंबर का डटकर सामना किया। परंतु 15 जून 1625 को मलिक अंबर ने उन्हें बुरी तरह हराया। इस सफलता ने उसके यश और कीर्ति में वृद्धि की। अब वह कुशल सेनापति, राजनीतिज्ञ और प्रबंधकर्ता समझा जाने लगा। उसके साहस और साधनों में भी उन्नति हुई। फलस्वरूप अहमदनगर व शोलापुर पर उसने फिर से अपना आधिपत्य जमा लिया और उसके सेनापति, याकूत खान ने बुरहानपुर के किले पर घेरा डाल दिया। इसी समय महावत खाँ, शाहजहाँ का पीछा करते करते पुन: दक्षिण आ पहुँचा। याकूत खाँ ने बुरहानपुर से अपनी सेना हटा ली। मलिक अंबर इस बार शाहजहाँ को सरंक्षण देने में बिल्कुल न हिचकिचाया। दोनों संयुक्त सेनाओं ने बुरहानपुर पर घेरा डाला, परंतु कोई सफलता प्राप्त न हुई। थोड़े समय बाद शाहजहाँ ने हथियार डाल दिए और अपने को समर्पित कर दिया। ऐसी परिस्थिति में मलिक अंबर के लिए मुगलों का सामना करना कठिन था। अतएव उसने बुरहानपुर के दुर्ग से सेना हटा ली। अगले वर्ष उसे मुगलों से टक्कर लेने का अवसर प्राप्त हुआ। इस समय जहाँगीर रोगग्रस्त था। नूरजहाँ की गुटबंदी ने महावत खाँ को विद्रोह करने पर विवश कर दिया था, तथा संपूर्ण शाही सेनाएँ महावत खाँ का विद्रोह दमन करने में लगी हुई थीं। दक्षिण में कोई भी कुशल सेनापति न रह गया था। इससे पहले कि वह अपनी सेनाओं की गतिविधि मुगलों के विरुद्ध या आदिलशाह के विरुद्ध संचालित करे, मृत्यु ने उसकी आँखें मई 14, 1615 को अस्सी वर्ष की आयु में बंद कर दीं।\\nright|thumb|300px|मलिक अम्बर का मकबरा (१८६० में)\\n1601 से 1626 तक, मलिक अंबर ने अपनी प्रतिभा, अदम्य साहस, कार्यकुशलता और सैन्य चातुर्य का परिचय दिया। भारतीय इतिहास में ऐसा बिरला ही उदाहरण मिलेगा जब किसी उजड़े हुए राज्य को एक साधारण श्रेणी के व्यक्ति ने नवजीवन प्रदान किया हो। मलिक अंबर की प्रतिभा बहुमुखी थी। वह सुयोग्य सेनापति तो था ही, इसके साथ साथ कुशल नीतिज्ञ और चतुर शासक भी था। उसने मराठों की सैनिक मनोवृत्ति का ठीक मूल्यांकन करके एक नवीन सैनिक प्रणाली का आविष्कार किया। टोडरमल की भूमिकर व्यवस्था को अपने राज्य में प्रचलन करके उसने न केवल रिक्त कोष को ही समृद्धिशाली बनाया बल्कि जनता को भी सुख प्रदान किया। किर्की में उसने अपनी राजधानी बसाई और यहाँ उसने अनेक मस्जिदों, महलों का निर्माण कराया तथा उद्यान लगवाए। सिंचाई के लिए नहरें भी खुदवाईं। महवल दर्रा, दरवाजा नाखुदा महल, काला चबुतरा दीवान-ए-आम और दीवान-ए-खास, जो आज खंडहरों के रूप में दिखाई देते हैं उसकी भावनाओं को प्रमाणित करते हैं। उसने ज्ञान तथा विद्वानों दोनों को सरंक्षण प्रदान किया। अरब से बहुत विद्वान् आए और उसने उन्हें प्रोत्साहन दिया। उनमें से एक अली हैदर था, जिसने 11वीं शताब्दी हिजरी के प्रसिद्ध संतों की जीवनियों पर \"इक्व अल जवहार\" ग्रंथ की रचना की। फारस से आए हुए विद्वानों को भी उसने आश्रय दिया। उसने किर्की में चितखाना की स्थापना की जहाँ बहुत से हिंदू और मुसलमान विद्वान् ज्ञान की विभिन्न शाखाओं का गंभीर अध्ययन करते थे।\\n\\nइन्हें भी देखें\\n चाँद बीबी\\n\\nसन्दर्भ\\n\\nबाहरी कड़ियाँ \\n मलिक अम्बर: गुलाम से शासक बनकर मराठों की मदद से मुगलों को चटाई धूल!\\n Mentioned on page 9\\n Malik Ambar: A remarkable life B.N. Goswamy\\n The Tribune, Chandigarh,13 अगस्त 2006, India Online edition]\\n\\nश्रेणी:भारत का इतिहास'},\n",
       "  {'docid': 'doc-hi-14',\n",
       "   'text': 'फलों की जेली\\n[[चित्र:Strawberry jam on a dish.JPG|अंगूठाकार|स्ट्राबेरी का जैम]]\\n[[File:Ribotroshhashana.jpg|thumb|Five varieties of fruit preserves (clockwise from top): apple, quince, plum, squash, orange (in the center)]]\\nफलों की जेली या मुरब्बा,  फलों, सब्जियों और चीनी को मिश्रित करके बनाई गैइ खाद्य वस्तु है जिसे प्रायः काँच के बर्तनों में रखा जाता है। s.\\n\\nफलों को टिकाऊ बनाये अथवा अधिक दिनों तक रखने में काफी अडचनें आतीं हैं। इसके अलावा सभी फल सभी जगह और सभी समय उपलब्ध नहीं होते। इसलिए उपलब्ध फलों से जैली तैयार कर अधिक दिनों तक उपयोग में लाया जा सकता है।१|\\n\\nजैली बनाने की विधि\\n\\nफलों का चुनाव\\nजैली बनाने के लिए ऐसे फल लेने चाहिए जो पकने की अवस्था में हो | यदि किसी कम पेक्टिन वाले फल से जैली बनानी हो तो उसके साथ कुछ मात्रा में अधिक पेक्टिन वाला फल भी मिला देना चाहिए या व्यवसायिक पेक्टिन चूर्ण मिलाकर जैली बनाई जा सकती है | जैली बनाने के लिए ताजे फलों का प्रयोग करना चाहिए | फलों को तोड़कर लम्बे समय पर के लिए रख दिया जाय तो इसमें पेक्टिन का ह्रास होने लगता है | ऐसे फल जिनमें पेक्टिन पर्याप्त मात्रा में पाया जाता है वे हैं – अमरुद, सेब, करौंदा, आम, पटुवा, कैथा, खट्टे प्लम, खट्टे अंगूर, निम्बू, संतरा, गलगल, आदि |\\n\\nपेक्टिन अर्क तैयार करना\\nफलों को धोना : फल के ऊपर धूल ,मिट्टी,जंतुनाशक निकालने के लिए फलों को अच्छी तरह धोना चाहिए।\\n\\nजन्तुरहित करना : सामाग्रीयोन के उपकरणों का उपयोग करके उबाले हुये पानी में जंतुरहित करना चाहिए।\\n\\nफलों से पेक्टिन निकालना\\nफल से पेक्टिन प्राप्त करने, अधिकतम रस प्राप्त करने और फल में खुशबु पैदा करने वाले पदार्थों की उपलब्धि के लिए, इन्हें उबला या पकाया जाता है I पेक्टिन प्राप्त करने के लिए फलों में पानी भी मिलाया जाता है I पानी की मात्रा फल के रसीलेपन पर निर्भर करती है I फलों को काटकर माध्यम आकार के एक जैसे टुकड़े करों | इन टुकडों को उतना पानी डालकर गरम करो जीतने पानी मे आसानी से वे डूब जाएँ | अधिक रसदार फलों में पानी मिलाने की जरुरत नहीं होती है I केवल उन्हें कुचल करके और 5 – 10 मिनट तक उबालकर रस निचोड़ लिया जाता है I कड़े फल जैसे – सेव, अमरुद, कटहल, नारंगी इत्यादि में पानी मिलाने की जरुरत होती है I सेव में आधे से पूरे फल के वजह के बराबर पानी, अमरुद, नारंगी व निम्बू में फल के वजह का डेढ़ से 2 गुना पानी मिलाया जाता है अमरुद तथा सेव में सामान्यतः प्रति किलो फल में एक से सवा किलो तक पानी मिलाकर 30 – 40 मिनट तक धीमी आँच पर पकाना चाहिए I पकाने का कार्य घरेलू स्तर पर धुंआ रहित भट्टी या स्टोव में अल्युमिनियम के भगोने में करना चाहिए I पानी मिलाने से पहले ही इन्हें बिना छिले ही छोटे – छोटे टुकड़ों में करना चाहिए I पानी मिलाने से पहले ही इन्हें बिना छिले ही छोटे – छोटे टुकड़ों में काट लेना चाहिए I निम्बू वर्गीय का बाहरी पिला भाग चाकू से छील देना चाहिए I तत्पश्चात फलों के छोटे – छोटे टुकड़ों में काटकर व दो गुना पानी मिलाकर 40 – 50 मिनट तक पकाना चाहिए पकाने से फल में उपस्थित पेक्टिन घुलकर पानी में आ जाती है I इसे बारीक मलमल के कपड़े में छान लेना चाहिए ताकि रस स्वयं ही टपककर निकल जाय I पेक्टिन निचोड़ में गुदा नहीं आनी चाहिए I\\n\\nउबालने का समय फल की किस्म और गठक पर निर्भर करता है I फल को इतना उबालना चाहिए कि वह नम होकर, पेक्टिनयुक्त रस का पूर्ण निष्कर्षण होने दें I सामान्यतः सेब को 20 से 30 मिनट, अमरुद को 30 से 40 मिनट मिनट, नारंगी को 30 से 60 मिनट, सरस फलों को 5 से 10 मिनट तक उबाला जाता है I अधिक उबालने से रस धुंधला हो जाता है I\\n\\nद्रव्य दूधिया हो जाने पर उसे कपड़े से छान लेना चाहिए |कपड़े में फलों के टुकड़े रह जाएंगे और बर्तन मे पेक्टिन अर्क रहेगा |फलों के इन टुकड़ों में फिर से पानी डालकर उबालों |द्रव्य दूधिया हो जाने पर फिर उसे छानो और पेक्टिन अर्क अलग करों | इस अर्क को कुछ घंटे तक इसी तरह रखिए |उपर्युक्त पानी को निकालें इस पानी से पेक्टिन की मात्रा निश्चित करकेनिम्नलिखित जांच करो |\\n\\nशक्कर डालकर पकाना\\nउत्तम श्रेणी की पेक्टिन हो तो तीन चौथाई शक्कर डालनी चाहिए |मध्यम श्रेणी के पेक्टिन हो तो अर्क से कम मात्रा मे शक्कर डालनी चाहिए | अम्ल डालकर धीमे आंच पर पकाना चाहिए।\\n\\nरस में पेक्टिन की जाँच करना\\nरस मे पेक्टिन का जांच क्र्ना : कटोरी मे 1 टी स्पून पेक्टिन अर्क लेकर उसमें 2 टी स्पून स्पिरिट मिलाओं |इस मिश्रण को हिलाओं और कुछ मिनट तक रखो |जब एक ठोस गोली बन जाए तो समझ लों की उत्तम श्रेणी का पेक्टिन है |यदि नर्म गोली तैयार हो तो समझ लो की यह मध्ययम श्रेणी का पेक्टिन है |गाढ़ा द्रव्य तैयार हो तो समझ लो की पेक्टिन की मात्रा बिलकुल कम है।\\n\\nरस में कितनी पेक्टिन है, इसकी जाँच करना अत्यंत आवश्यक है क्योंकि पेक्टिन की मात्रा के अनुसार ही इसमें चीनी मिलाई जाती है I रस में पेक्टिन की जाँच करने की दो विधियाँ हैं –\\n\\n अल्कोहल या स्प्रिट द्वारा\\n जैली मीटर द्वारा\\n स्प्रिट द्वारा\\n\\nएक काँच के गिलास में ठण्डा किया हुआ एक चम्मच रस डालिए I इसमें दो चम्मच स्प्रिट डालने से रस में उपस्थित पेक्टिन जम जाएगी I लगभग एक मिनट बाद उसे सावधानी से एक प्लेट में गिरना चाहिए I यदि यह एक ठोस थक्के के रूप में गिरे तो समझना चाहिए कि इसमें पेक्टिन ठीक मात्रा में है I यानि रस में उतम श्रेणी का पेक्टिन हैं I यदि गिरते समय थक्के के रूप में गिरकर दो – तीन टुकड़ों में हो जाय तो रस में मध्यम श्रेणी की पेक्टिन समझानी चाहिए I यदि इसमें कई छोटे –छोटे टुकड़े बन जाय तो यह निम्न श्रेणी के पेक्टिन की सूचक है।\\n\\nचीनी मिलाना व पकाना\\nरस में चीनी पेक्टिन की जाँच के अनुसार मिलाई जाती है I उतम श्रेणी की पेक्टिन के लिए प्रति लीटर रस में एक किलो ग्राम चीनी मिलाई जाती है I मध्यम श्रेणी वाले रस में प्रति लीटर 750 ग्राम चीनी मिलाई जाती है I चीनी मिलाने के बाद रस को पकाने रख देना चाहिए I पकाना एक महत्वपूर्ण कदम है I इससे शर्करा घुल जाती है तथा शर्करा, पेक्टिन और अम्ल अच्छी तरह मिल जाते हैं, जिससे जैली जम जाती है I इसका मुख्य कारण शर्करा सांद्रण को इतना बढ़ाना है कि जैली जम जाय I जैली पकाने का कार्य कम से कम समय में पूरा होना चाहिए I अधिक पकाने से सुगंध की कमी, बदरंग और पेक्टिन का जल – अपघटन हो जाता है, जिससे जेली जम नहीं पाती है I जब चीनी घुल जाय तो उसे मलमल के कपड़े से छान लेना चाहिए ताकि चीनी की गंदगी दूर हो जाय I अब इसे तेज आग पर पकाना चाहिए ताकि लगभग 30 मिनट में जैली पककर तैयार हो जाय I प्रायः समापन बिन्दु पर पहुँचने से पहले जेली में अम्ल मिलाया जाता है, पाहिले नहीं I इससे उत्पाद का रंग हल्का रहता है तथा पेक्टिन का जलापघटन भी कम हो जाता है I पकाते समय उफान को रोकने के लिए थोड़ा सा खाने लायक परन्तु गंधरहित तेल इस्तेमाल किया जा सकता है I\\n\\nअम्ल/खट्टास मिलाना – खट्टास की एक निश्चित मात्रा से ही जैली जमती है I कुछ फलों में यह पर्याप्त मात्रा में बिधमान रहती है लेकिन कुछ में इसकी मात्रा कम रहती है I इसलिए जिन फलों में खट्टास कम होती है उनमें प्रति किलो ग्राम चीनी में 5 – 7 ग्राम खट्टास मिलानी चाहिए ताकि जैली तैयार हो जाने पर उसमें खट्टास की मात्रा 75 प्रतिशत बनी रहे I खट्टास अम्ल के रूप में मिलाई जाती है I खट्टास जैली तैयार होने के लगभग 5 – 6 मिनट पहले मिलानी चाहिए I\\n\\nबोतलों में भरना – जब जैली तैयार हो जाय तो भगोने की आग से उतारकर मैल की परत हटा देनी चाहिए I मैल की परत हटाने के लिए छेद वाली कलछी का प्रयोग करना चाहिए I जैली को गरम – गरम ही स्टरलाइज किया हुए चौड़े मुँह की बोतल में ऊपर तक भर दीजिए I ठण्डा होने पर जैली दही जैसी जम जाएगी तथा सिकुड़कर लगभग 1 सेंटीमीटर स्थान खली रह जाएगा I अब मोम पिघलाकर बोतल में डाल दीजिए I ऐसा करने से यह बोतल सील बन्द हो जाएगी I उसमे नमी नहीं प्रवेश कर पाएगी I\\n\\nसन्दर्भ\\n\\nhttps://www.pakwangali.in/sweet-recipes/watermelon-jelly-tarbuj-pakwangali-recipe-hindi/article/925008.html\\n\\nश्रेणी:फल संरक्षण'},\n",
       "  {'docid': 'doc-hi-15',\n",
       "   'text': 'ट्यूडर राजघराना\\nट्यूडर राजवंश (Tudor dynasty) ने 1485 से 1603 ई0 तक इंग्लैंड में शासन किया। उसे हम इंग्लैंड के इतिहास के मध्य और आधुनिक युग की कड़ी मान सकते हैं। मध्यकालीन दुर्व्यवस्थाओं एवं अशांत स्थितियों को दूर करने, इंग्लैंड के आधुनिक राजनीतिक युग के प्रवर्तन और राष्ट्र की महत्ता के दिनों प्रारंभ करने का श्रेय उसे प्राप्त है।\\n\\nहेनरी सप्तम \\n\\nट्यूडर वंश का प्रथम शासक हेनरी सप्तम (1485-1509) ई0 था। वह विख्यात वेल्स सरदार सर एविन ट्यूडर का पौत्र और रिशामांड का अर्ल था। उसने वासवर्थ की लड़ाई में रिचर्ड तृतीय को हराकर सिंहासन पर अधिकार कर लिया और यार्क राजकुमारी एलिजाबेथ से विवाह कर \\'गुलाबों के युद्ध\\' का अंत कर दिया।\\n\\nहेनरी सप्तम के सम्मुख अपने राज्याधिकार को दृढ़ करने की समस्या थी, इसके हेतु जहाँ एक ओर तो उसने लैंबर्ट सिमनेल और पार्किन वारवेक जैसे राज्य के नकली दावेदारों क नाश किया, वहीं सामंतों की उपद्रवकारी शक्ति के विध्वंस के लिये वद विधान तथा भृत्य विधान बनाए। \\'स्टार चेंबर\\' (नक्षत्रभवन) के न्यायालय की स्थापना और प्रिवी कौंसिल के शासन द्वारा उसने अपनी शक्तिवृद्धि की। पार्लिमेंट से उसने अच्छा संबंध बनाए रखा और यथाशक्ति उसकी कम से कम बैठकें बुलाईं। राजकीय व्यय चलाने के लिए पार्लियामेंट द्वारा स्वीकृत धन कें अतिरिक्त धनी और व्यापारी वर्गों से कर्ज, दान तथा अर्थदंड जैसे उपायों के साथ ही मितव्ययता का सहारा लिया। देश के आंतरिक प्रशासन में सशक्त राजतंत्र की उसने स्थापना की। उसके समय में कृषि और व्यापार की उन्नति तथा गरीबों एवं बेकारों के भरणपोषण की व्यवस्था की गई थी। वैदेशिक मामलों में तटस्थता और समकालीन राजपरिवारों से वैवाहिक संबंध की नीति का अबलंबन कर उसने राष्ट्रीय हित के संवर्धन के साथ ही परिवारिक प्रतिष्ठा में भी वृद्वि की।\\n\\nहेनरी अष्टम \\n\\nहेनरी अष्टम (1509-1547 ई0) अपने पिता की मृत्यु के बाद राजा बना। वह अपने वंश का संभवत: सर्वाधिक महत्वाकांक्षी शासक था। विरासत में प्राप्त सुदृढ़ राजकीय शक्ति और संचित धनराशि का उपयोग कर उसने केवल दरबार की शानशौकत ही नहीं बढ़ाई, अपितु अंतरराष्ट्रीय राजनीति में भी पूर्ण भाग लिया। उसके समकालीन प्रत्येक राजा की यह महत्वाकांक्षा थी कि वह रोम का पवित्र सम्राट बने। हेनरी भी इस दौड में पीछे न था, किंतु 1519 में उस पद के लिए होनेवाले चुनाव में स्पेन के चार्ल्स पंचम ने उसे पिछाड़ दिया। इसके पूर्व हेनरी ने स्पेन और फ्रांस के राजाओं का बारी बारी से पक्ष लेकर उन्हें एक दूसरे के विरुद्ध भिड़ाए रखने की नीति प्रारंभ कर दी थी। उसका मंत्री वुल्जे उस नीति के प्रयोग में दक्ष था और उसी से अंतर्राष्ट्रीय राजनीति में शक्तिसंतुलन के सिद्धांत का प्रारंभ माना जाता है।\\n\\n1527 ई. में हेनरी अष्टम के शासन का द्वितीय चरण प्रारंभ हुआ। उसकी रानी कैथरीन के कोई पुत्र संतान न थी। हेनरी उसे तलाक देना चाहता था। उसके लिये पोप की अनुज्ञा लेना आवश्यक था। किंतु पोप कैथरीन के भतीजे तथा रोमन सम्राट् चार्ल्स के भय से वैसी स्वीकृति देने में देरी करने लगा। हेनरी प्रतीक्षा करने के लिये तैयार न था। उसने अपने असफल मंत्री बुल्जे को पदच्युत कर दिया और पोप का इंग्लैंड पर धार्मिक प्रभुत्व मिटाने के लिये पार्लिमेंट बुलाई। क्रमश: उसने \\'प्रथम फल\\' (Annates) का विधान, अपील का विधान, संप्रभुता का विधान और उत्तराधिकार का विधान जैसे अनेक विधानों को पारित किया। वस्तुत: हेनरी पोप को डराना मात्र चाहता था लेकिन पारिणाम अत्यंत दूरगामी सिद्ध हुआ। यद्धपि उसने देश के धार्मिक विश्वासों में विशेष परिवर्तन नहीं किए, तथापि धर्मसुधार की लहर एक बार चल चुकने के बाद लौटनेवाली न थी। 1529 से 1536 ई0 तक जो धर्मसुधार पार्लिमेंट उसने बुलाई उसके द्वारा पारित विधानों के फलस्वरूप इंग्लैंड की राजशक्ति पोप के अनेक नियंत्रणों से ही नहीं मुक्त हुई, उसके चर्च का रोम से विलगाव हो गया और अप्रत्यक्ष रूप से पार्लिमेंट की शक्ति भी मान्य हो गई।\\n\\nएडवर्ड षष्ठम \\n\\nएडवर्ड षष्ठम (1547-1553 ई.) पिता हेनरी के तृतीय उत्तराधिकार के विधेयक (1544 ई.) के अनुसार 9 वर्ष की अवस्था में राज्यासीन हुआ। शासन प्राय: एक संरक्षक समिति के द्वारा चलता रहा, जिसक नेता सोमरसेट और नॉर्थबरलैंड के अर्ल थे। उसके समय की मुख्य विशेषता थी इंग्लैंड में प्युरिटन धर्म की स्थापना और धर्मसुधार की प्रगति। 1549 ई0 और 1552 ई0 में प्रार्थना संबंधी नए विधान पारित हुए और धार्मिक समानता लाने का प्रयत्न किया गया।\\n\\nमेरी \\n\\nमेरी (1553-1558 ई.) एडवर्ड षष्ठ की 1553 ई. में मृत्यु के बाद इंग्लैंड की राजगद्दी की उत्तराधिकारणी बनी। वह कैथरीन से उत्पन्न हेनरी अष्टम की पुत्री थी। उसकी माँ के तलाक के प्रश्न को लेकर इंग्लैंउ मे धर्मसुधार प्रारंभ हुआ था जिससे मेरी के मन में प्रतिक्रिया की भावना थी। प्रोटेस्टेंट धर्म को समाप्त कर इंग्लैंड में पुन: कैथलिक धर्म और पोप का प्रभुत्व स्थापित करना उसका उद्देश्य हो गया। उस हेतु उसने एडवर्ड षष्ठ के समय के सभी धर्मसुधार विधानों का ही अंत नहीं किया, अपितु अपने पिता के अनेक तटस्थ और राजहितकारी सुधारों को भी वापस ले लिया। उससे भी आगे बढ़ उसने रोम से पुन: संबंध स्थापित कर पोप के प्रतिनिधि का इंग्लैंड में स्वागत किया ओर स्पेन के कैथलिक शासक फिलिप द्वितीय से विवाह किया। उसने प्राटेस्टेंटों को कठोर दंड दिया। लगभग 300 धर्मसुधारक भिक्षु जीवित जला दिए गए जिनमें मुख्य थे लैटिमर, रिडले और कैनमर। इसी कारण बाद में वह \\'खूनी मेरी\\' कहलाई। पार्लियामेंट मेरी के इन कार्यों से प्रसन्न न थी। इसी बीच 1558 ई0 में फ्रांस के तट पर स्थित कैले का बंदरगाह भी उसके हाथों से निकल गया। विरोध की भावनाएँ उठ ही रही थीं कि नि:संतान मेरी की 1558 ई. में मृत्यु हो गई और इंग्लैंड गृहयुद्ध की एक भीषण अग्नि से बच गया।\\n\\nएलिजाबेथ \\n\\n1558 ई. में सिंहासनारूढ़ हुई। उसने देश की धार्मिक समस्या के सुलझाने और अंग्रेजों की नवयुगीन महत्वाकांक्षाओं की पूर्ति के उपाय ढूँढ निकाले। उसने धार्मिक क्षेत्र में मध्यम मार्ग का अवलंबन किया और अपने पिता के समय की धार्मिक व्यवस्था को पुन:प्रचलित किया। रोम से संबंध विच्छिन्न कर संप्रभुता का विधान एडवर्ड षष्ठ के 42 धाराओंवाले विधान की तीन कटर्\\u200c सुधारवादी धाराओं को निकालकर 39 धराओं विधान और एकरूपता का विधान आदि उसकी धर्मव्यवस्था के मुख्य अंग थे, जिनसे इंग्लैंड में राष्ट्रीय आंग्लिकन चर्च की स्थापना हुई। इसके विरोधियों को, चाहे वे कैथलिक अथवा नान कॉनफार्स्मिट हों, 20 शिलिंग प्रति मास के अर्थदंड मात्र से मुक्ति मिल सकती थी। उस युग के लिये यह धार्मिक उदारता विशेष बात थी।\\n\\nराजनीतिक क्षेत्र में एलिजावेथ न अपने पूर्वजों की तरह सशक्त राजतंत्र, कौंसिल द्वारा शासन और स्वतंत्र वैदेशिक नीति के सिद्धांतों का अनुसरण किया। इसीलिये उसने पार्लिमेंट की बैठकें कम बुलाईं। फ्रांस और स्पेन के राजाओं को विवाह का लालच देते हुए उसने उनको हमेशा धोखे में रखा। फ्रांस और स्काटलैंड मिलकर इंग्लैंड पर कोई आक्रमण न कर दें, इसकी भी वह चिंता करती थी। स्काटलैंड की रूपवती रानी मेरी के विरुद्ध होनेवाली षड्यंत्रों में भी उसका हाथ होने का संदेह किया जाता है। जब बेचारी मेरी स्काटलैंड से भाग कर इंग्लैंड आई तो उसे दो वर्षों तक कारागार में रहना पड़ा और अंत में उसे प्राणदंड दिया गया।\\n\\nएलिजाबेथ की नीति और स्वतंत्र निर्णयों से पार्लियामेंट प्रसन्न नहीं रहती थी। उसने उसके विवाह के संबंध में कई प्रस्ताव किए जिन्हें वह ठुकराती रही। किंतु भाषण स्वातंत्रय और आर्थिक एकाधिकारों के लाइसेंसों की स्वीकृति के प्रश्न पर पार्लियामेंट के सम्मुख सम्राज्ञी को झुकना पड़ा। सौभाग्य से विदेशी भय के कारण जनसाधारण सर्वदा उसके अनुकूल रहा। 1588 ई. में जब स्पेन के कैथलिक राजा फिलिप द्वितीय ने इंग्लैंड पर आक्रमण करने के लिए अपना विकराल आर्मेडा भेजा तो सारा देश रानी के साथ हो गया। अंग्रेज नाविकों और प्रकृति ने मिलकर आर्मेडा को तितर-बितर कर दिया जिससे इंग्लैंड की सामरिक शक्ति की प्रतिष्ठा बढ़ी।\\n\\nएलिजाबेथ का समय इंग्लैंड के इतिहास का स्वर्णयुग कहा जाता है। साहित्यगगन के देदीप्यमान सितारे शेक्सपियर, बेकन, मार्लो आदि ने महान्\\u200c अंग्रेजी साहित्य को जन्म दिया, रैले, हार्किस और ड्रैक जैसे नाविकों ने समुद्री जहाजों में बैठकर दुनिया की परिक्रमा की, जहाजी लूट से राजकोष भरा गया, उपनिवेश स्थापित हुए और व्यापार के लिए नई कंपनियाँ खोली गईं। देश की धनधान्य से पूर्णता, राजदरबार की शानशौकत में वृद्धि, विदेशों में प्रतिष्ठा, अन्य देशों के मुकाबले अपेक्षाकृत धार्मिक शांति और आधुनिक युग की अनेक गौरवमय उपलब्धियों से युक्त ट्यूडर शासन का अंत, एलिजाबेथ की मृत्यु के साथ, सन्\\u200c 1603 ई. में हो गया।\\ncenter|thumb|700px|ट्यूडर राजवंश के शासक\\n\\nसन्दर्भ ग्रंथ \\n1. त्रिपाठी रा. प्र. : इंग्लैंड का इतिहास (सं. 1999), \\n\\n2. ट्रेवेलियन : हिसट्री ऑव इंग्लैंड, (1952 ई0); \\n\\n3. फिशर, एच. एफ. एल. : पोलिटिकल हिस्ट्री ऑव इंग्लैंड (1952 ई.);\\n\\n4. पोलॉर्ड, एफ. : पोलिटिकल हिस्ट्री ऑफ इंग्लैंड, (1547-1603 ई.); \\n\\n5. पालार्ड, एफ. : हेनरी अष्टम, क्रैंनमर, वुल्जे; 6. आइंस्टाइन : ट्यूडर आइडियल्स्\\u200c; \\n\\n7. विलियमसन जे. ए. : दि एज ऑव ड्रेक (1938 ई.); \\n\\n8. कीर, डी. एल : दि कांस्टिट्यूशनल हिस्ट्री ऑव मार्डन ब्रिटेन (1953 ई.); \\n\\n9. ऐडम्स्\\u200c. जी. बी. : कांस्टिट्यूशनल हिस्ट्री ऑव इंग्लैंड।\\n\\nबाहरी कड़ियाँ \\n Tudor Dynasty World History Database\\n History lectures, essays and lectures by John Guy\\n Tudor treasures from The National Archives\\n Tudor Place\\n Tudor History\\n The Tudors on the official website of the British monarchy\\n  on the official website of the British monarchy\\n Tudor History\\n \"The Tudor delusion\": an article in The Times Literary Supplement by Clifford S. L. Davies, arguing that we are wrong even to talk about \"the Tudors\", 11 जून 2008.\\n The Family Tree of the Tudors and the Stuarts in Pictures\\n\\nश्रेणी:ब्रिटेन का इतिहास\\nश्रेणी:विकिपरियोजना ब्रिटिश राजशाही\\nश्रेणी:ट्यूडर राजघराना'}]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "mldr = []\n",
    "\n",
    "instruction = \"निर्देश: दिए गए प्रश्न के आधार पर उपलब्ध विकल्पों में से सबसे प्रासंगिक अनुच्छेद को चुनें। प्रश्न: \"\n",
    "\n",
    "for sample in data:\n",
    "\n",
    "    passage = sample['positive_passages'][0]['text']\n",
    "    query = sample['query']\n",
    "\n",
    "    mldr.append({\n",
    "        'id': f\"mldir_{pp_dict[passage]}\",\n",
    "        'source': instruction + query,\n",
    "        'target': passage\n",
    "    })\n",
    "\n",
    "random.shuffle(mldr)\n",
    "\n",
    "with open(f\"Processed_data/mldr_test.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in mldr:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 179859, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 1175819, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 309757},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 740551},\n",
       " 'sentiment_review': {'Hindi': 52821, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35130924, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84599189,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in mldr:\n",
    "    hin_1 = tokenizer.encode(sample['source'])\n",
    "    hin_2 = tokenizer.encode(sample['target'])\n",
    "\n",
    "    total_hindi_tokens+= len(hin_1)\n",
    "    total_hindi_tokens+= len(hin_2)\n",
    "\n",
    "token_per_language['mldr'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: MLQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Data/Retrieval/MLQA_V1/test/test-context-en-question-hi.json\", \"r\") as f:\n",
    "    hin_eng_data = json.load(f)\n",
    "with open(\"./Data/Retrieval/MLQA_V1/test/test-context-hi-question-en.json\", \"r\") as f:\n",
    "    eng_hin_data = json.load(f)\n",
    "with open(\"./Data/Retrieval/MLQA_V1/test/test-context-hi-question-hi.json\", \"r\") as f:\n",
    "    hin_hin_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_context = []\n",
    "english_context = []\n",
    "\n",
    "for topic in hin_hin_data['data']:\n",
    "    \n",
    "    for sample in topic['paragraphs']:\n",
    "        hindi_context.append(sample['context'])\n",
    "\n",
    "hindi_context = set(hindi_context)\n",
    "\n",
    "hindi_context_dict = {passage: idx for idx, passage in enumerate(hindi_context)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlqa = []\n",
    "\n",
    "instruction = \"निर्देश: प्रश्न के आधार पर उपलब्ध विकल्पों में से सबसे प्रासंगिक संदर्भ प्राप्त करें। प्रश्न:\"\n",
    "\n",
    "for topic in hin_hin_data['data']:\n",
    "\n",
    "    for sample in topic['paragraphs']:\n",
    "\n",
    "        context = sample['context']\n",
    "\n",
    "        for qas in sample['qas']:\n",
    "            mlqa.append({\n",
    "                'id': f\"mlqa_{hindi_context_dict[context]}\",\n",
    "                'source': instruction + qas['question'],\n",
    "                'target': context               \n",
    "            })\n",
    "\n",
    "random.shuffle(mlqa)\n",
    "with open(\"./Processed_data/mlqa_test.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in mlqa:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 179859, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 1175819, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 309757},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 740551},\n",
       " 'sentiment_review': {'Hindi': 52821, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35130924, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84599189,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in mlqa:\n",
    "    hin_1 = tokenizer.encode(sample['source'])\n",
    "    hin_2 = tokenizer.encode(sample['target'])\n",
    "\n",
    "    total_hindi_tokens+= len(hin_1)\n",
    "    total_hindi_tokens+= len(hin_2)\n",
    "\n",
    "token_per_language['mlqa'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: ABP news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"Data/Retrieval/ABP_news/ABP_new_query_doc.json\", \"r\") as f:\n",
    "    query_doc = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "abp = []\n",
    "\n",
    "instruction = \"निर्देश: प्रश्न के आधार पर उपलब्ध विकल्पों में से सबसे प्रासंगिक समाचार लेख ढूंढें। प्रश्न:\"\n",
    "count = 0\n",
    "\n",
    "for field in query_doc.keys():\n",
    "\n",
    "    for idx, sample in enumerate(query_doc[field]):\n",
    "\n",
    "        context = sample[0]\n",
    "        question = sample[1]\n",
    "\n",
    "        if question is None:\n",
    "            count+=1\n",
    "            continue\n",
    "\n",
    "        abp.append({\n",
    "            'id': f\"abp_{field}_{idx}\",\n",
    "            'source': instruction + question,\n",
    "            'target': context          \n",
    "        })\n",
    "\n",
    "random.shuffle(abp)\n",
    "with open(\"./Processed_data/abp_news.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in abp:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'abp_lifestyle_342',\n",
       " 'source': 'निर्देश: प्रश्न के आधार पर उपलब्ध विकल्पों में से सबसे प्रासंगिक समाचार लेख ढूंढें। प्रश्न:मोक्षदा एकादशी 2024 में किस तिथि और दिन को मनाई जाएगी??',\n",
       " 'target': 'Mokshada Ekadashi 2024:\\xa0पंचाग (Panchang) के अनुसार मार्गशीर्ष महीने के शुक्ल पक्ष में पड़ने वाली एकादशी तिथि को मोक्षदा एकादशी के नाम से जाना जाता है. इस दिन भगवान श्रीहरि (Vishnu ji) की पूजा और व्रत करने वाले जातकों से भगवान प्रसन्न होते हैं और व्यक्ति को पापों व कष्टों से मुक्ति मिलती है. मोक्षदा एकादशी पर श्रीहरि के चतुर्भुज स्वरूप की पूजा का महत्व है.\\nइस वर्ष 2024 में मोक्षदा एकादशी का व्रत बुधवार 11 दिसंबर को रखा जाएगा. वहीं अगले दिन 12 दिसंबर को व्रत का पारण किया जाएगा. शास्त्रों में मोक्षदा एकादशी व्रत के पूजा और महत्व के बारे में बताया गया है. विशेष रूप से इस एकादशी को मोक्ष प्राप्ति के लिए श्रेष्ठ माना जाता है.\\nमोक्षदा एकादशी व्रत का महत्व (Mokshada Ekadashi Significance)\\nमोक्षदा एकादशी पर भगवान विष्णु (Lord Vishnu) के साथ ही भगवान श्रीकृष्ण (Lord Krishna) की अराधना भी की जाती है. ज्योतिषाचार्य अनीष व्यास बताते हैं कि धार्मिक मान्यता के अनुसार इस व्रत को करने से पूर्वजों की आत्मा को मोक्ष प्राप्ति होती है. इसका कारण यह है कि जिस दिन मोक्षदा एकादशी होती है उसी दिन भगवान श्रीकृष्ण ने श्रीमद्भगवद्गीता का उपदेश दिया था. इसलिए मोक्षदा एकादशी के दिन गीता जंयती (Gita Jayanti) पर्व भी मनाया जाता है.\\nयह भी मान्यता है कि इस दिन व्रत रखने वाले जातकों के पाप कर्म नष्ट हो जाते हैं उसे जीवन में अपार सफलता मिलती है और मरणोपरांत व्यक्ति को स्वर्ग की प्राप्ति होती है.\\nमोक्षदा एकादशी पूजा विधि (Mokshada Ekadashi Puja Vidhi)\\nमोक्षदा एकादशी के दिन सुबह जल्दी उठकर स्नान करें और फिर साफ-सुथरे कपड़े पहन लें पूजाघर में दीप जलाकर व्रत का संकल्प लें. एक चौकी पर भगवान विष्णु की प्रतिमा या तस्वीर को स्थापित कर भगवान का जलाभिषेक करें और फिर पीले वस्त्र अर्पित करें. भगवान को रोली, अक्षत, फूल, तुलसी दल, धूप, दीप और नैवेद्य अर्पित कर मंत्र जाप के साथ पूजा करें. पूजा के बाद व्रत कथा का पाठ जरूर करें और अंत में आरती करें.\\nये भी पढ़ें: Shukra Gochar 2024: शनि की राशि मकर में दैत्यों के गुरु का गोचर इन राशियों का खोल देगा भाग्य\\nDisclaimer: यहां मुहैया सूचना सिर्फ मान्यताओं और जानकारियों पर आधारित है. यहां यह बताना जरूरी है कि\\xa0ABPLive.com किसी भी तरह की मान्यता, जानकारी की पुष्टि नहीं करता है. किसी भी जानकारी या मान्यता को अमल में लाने से पहले संबंधित विशेषज्ञ से सलाह लें.\\xa0'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abp[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 179859, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 1175819, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 309757},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 740551},\n",
       " 'sentiment_review': {'Hindi': 52821, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35130924, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84599189,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in abp:\n",
    "    hin_1 = tokenizer.encode(sample['source'])\n",
    "    hin_2 = tokenizer.encode(sample['target'])\n",
    "\n",
    "    total_hindi_tokens+= len(hin_1)\n",
    "    total_hindi_tokens+= len(hin_2)\n",
    "\n",
    "token_per_language['abp'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"rajpurkar/squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661180',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'The Basilica of the Sacred heart at Notre Dame is beside to which structure?',\n",
       " 'answers': {'text': ['the Main Building'], 'answer_start': [279]}}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 179859, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 1175819, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 309757},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 740551},\n",
       " 'sentiment_review': {'Hindi': 52821, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35130924, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84599189,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for idx in range(len(ds['train'])):\n",
    "    context = tokenizer.encode(ds['train'][idx]['context'])\n",
    "    qs = tokenizer.encode(ds['train'][idx]['question'])\n",
    "\n",
    "    total_english_tokens+= len(context)\n",
    "    total_english_tokens+= len(qs)\n",
    "\n",
    "token_per_language['squad'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = []\n",
    "\n",
    "instruction = \"Instruction: Given a question, retrieve the most relevant passage. Question: \"\n",
    "count = 0\n",
    "\n",
    "for idx in range(len(ds['train'])):\n",
    "\n",
    "    context = ds['train'][idx]['context']\n",
    "    question = ds['train'][idx]['question']\n",
    "\n",
    "    squad.append({\n",
    "        'id': f\"squad_{idx}\",\n",
    "        'source': instruction + question,\n",
    "        'target': context          \n",
    "    })\n",
    "\n",
    "random.shuffle(squad)\n",
    "with open(\"./Processed_data/squad.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in squad:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = []\n",
    "\n",
    "instruction = \"Instruction: Given a question, retrieve the most relevant passage. Question: \"\n",
    "count = 0\n",
    "\n",
    "for idx in range(len(ds['validation'])):\n",
    "\n",
    "    context = ds['validation'][idx]['context']\n",
    "    question = ds['validation'][idx]['question']\n",
    "\n",
    "    squad.append({\n",
    "        'id': f\"squad_{idx}\",\n",
    "        'source': instruction + question,\n",
    "        'target': context          \n",
    "    })\n",
    "\n",
    "random.shuffle(squad)\n",
    "with open(\"./Processed_data/squad_test.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in squad:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: ELI5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"sentence-transformers/eli5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Why has the Mars Rover Opportunity's Lithium Ion Battery Lasted 11+ Years and the one in My Cell Phone/Laptop/Tablet Dies in Less Than 2?\",\n",
       " 'answer': 'NASA requirements lean toward the \\'overengineered\\' side (for good reason - if something goes wrong you can\\'t replace it). The battery in your phone is more from the \"make it cheaper, they can always buy another battery\" school of engineering. (Just to clarify, I am not being cynical about phone/laptop batteries. Most people - me included - would rather not pay something like 100 times as much for a battery that is able to withstand operating on Mars and lasts several times longer.)'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_hindi_crosssum': {'Hindi': 15632,\n",
       "  'English': 418483,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_english_crosssum': {'Hindi': 283593,\n",
       "  'English': 16649,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'hindi_hindi_crosssum': {'Hindi': 5423345,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'english_english_crosssum': {'Hindi': 0,\n",
       "  'English': 24667255,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'flores': {'Hindi': 32818, 'English': 34399, 'Romanised_Hindi': 0},\n",
       " 'laser': {'Hindi': 8965, 'English': 9642, 'Romanised_Hindi': 0},\n",
       " 'Mintaka': {'Hindi': 0, 'English': 289459, 'Romanised_Hindi': 383435},\n",
       " 'discourse': {'Hindi': 877773, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'massive': {'Hindi': 1865198, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment': {'Hindi': 179859, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'indicqa': {'Hindi': 1068905, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mldr': {'Hindi': 1175819, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'mlqa': {'Hindi': 1240305, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'sentiment_joshi': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 309757},\n",
       " 'sentiment_shete': {'Hindi': 0, 'English': 0, 'Romanised_Hindi': 740551},\n",
       " 'sentiment_review': {'Hindi': 52821, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'code_mixed': {'Hindi': 0, 'English': 343825, 'Romanised_Hindi': 457636},\n",
       " 'hinge': {'Hindi': 49195, 'English': 51579, 'Romanised_Hindi': 0},\n",
       " 'abp': {'Hindi': 12083574, 'English': 0, 'Romanised_Hindi': 0},\n",
       " 'squad': {'Hindi': 0, 'English': 20283952, 'Romanised_Hindi': 0},\n",
       " 'eli5': {'Hindi': 0, 'English': 44545346, 'Romanised_Hindi': 0},\n",
       " 'amazon_review': {'Hindi': 0, 'English': 35130924, 'Romanised_Hindi': 0},\n",
       " 'stackoverflow': {'Hindi': 0, 'English': 676294, 'Romanised_Hindi': 0},\n",
       " 'abp_news_classification': {'Hindi': 84599189,\n",
       "  'English': 0,\n",
       "  'Romanised_Hindi': 0},\n",
       " 'intent': {'Hindi': 245250, 'English': 0, 'Romanised_Hindi': 0}}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for idx in range(len(ds['train'])):\n",
    "    answer = tokenizer.encode(ds['train'][idx]['answer'])\n",
    "    qs = tokenizer.encode(ds['train'][idx]['question'])\n",
    "\n",
    "    total_english_tokens+= len(answer)\n",
    "    total_english_tokens+= len(qs)\n",
    "\n",
    "token_per_language['eli5'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}\n",
    "token_per_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5 = []\n",
    "\n",
    "instruction = \"Instruction: Given a question, retrieve the most relevant answer. Question: \"\n",
    "count = 0\n",
    "\n",
    "for idx in range(len(ds['train'])):\n",
    "\n",
    "    answer = ds['train'][idx]['answer']\n",
    "    question = ds['train'][idx]['question']\n",
    "\n",
    "    eli5.append({\n",
    "        'id': f\"eli5_{idx}\",\n",
    "        'source': instruction + question,\n",
    "        'target': answer          \n",
    "    })\n",
    "\n",
    "random.shuffle(eli5)\n",
    "with open(\"./Processed_data/eli5.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in eli5:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Stackover flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"mteb/stackoverflowdupquestions-reranking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_english_tokens = 0\n",
    "total_r_english_tokens = 0\n",
    "total_hindi_tokens = 0\n",
    "for sample in ds['train']:\n",
    "    query = tokenizer.encode(sample['query'])\n",
    "    positive = tokenizer.encode(sample['positive'][0])\n",
    "\n",
    "    total_english_tokens+= len(query)\n",
    "    total_english_tokens+= len(positive)\n",
    "\n",
    "token_per_language['stackoverflow'] = {'Hindi': total_hindi_tokens,\n",
    "                                'English': total_english_tokens,\n",
    "                                'Romanised_Hindi': total_r_english_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['query', 'positive', 'negative'],\n",
       "    num_rows: 19847\n",
       "})"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackoverflow = []\n",
    "\n",
    "instruction = \"Instruction: Given a query, retrieve the most similar sentence. Query: \"\n",
    "count = 0\n",
    "\n",
    "for idx in range(len(ds['train'])):\n",
    "\n",
    "    answer = ds['train'][idx]['positive'][0]\n",
    "    question = ds['train'][idx]['query']\n",
    "\n",
    "    stackoverflow.append({\n",
    "        'id': f\"stackoverflow_{idx}\",\n",
    "        'source': instruction + question,\n",
    "        'target': answer          \n",
    "    })\n",
    "\n",
    "random.shuffle(stackoverflow)\n",
    "with open(\"./Processed_data/stackoverflow.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in stackoverflow:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackoverflow_test = []\n",
    "\n",
    "instruction = \"Instruction: Given a query, retrieve the most similar sentence. Query: \"\n",
    "count = 0\n",
    "\n",
    "for idx in range(len(ds['train'])):\n",
    "\n",
    "    answer = ds['train'][idx]['positive'][0]\n",
    "    question = ds['train'][idx]['query']\n",
    "\n",
    "    stackoverflow_test.append({\n",
    "        'id': f\"stackoverflow_test_{idx}\",\n",
    "        'source': instruction + question,\n",
    "        'target': answer          \n",
    "    })\n",
    "\n",
    "random.shuffle(stackoverflow_test)\n",
    "with open(\"./Processed_data/stackoverflow_test.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in stackoverflow_test:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"token_per_language.json\", 'w') as f:\n",
    "    json.dump(token_per_language, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MTEB datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: XNLI New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/toxicity/miniconda3/envs/AI/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"mteb/xnli\", \"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'खैर यह बहुत रोचक हो गया है',\n",
       " 'hypothesis': 'यह बहुत ही दिलचस ् प है .',\n",
       " 'label': 0,\n",
       " 'lang': 'hi'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "xnli_new = []\n",
    "\n",
    "instruction = \"Instruction: Given a query, retrieve the most similar sentence. Query: \"\n",
    "count = 0\n",
    "\n",
    "for idx, sample in enumerate(ds['train']):\n",
    "\n",
    "    if sample['label'] != 0:\n",
    "        continue\n",
    "\n",
    "    answer = sample['premise']\n",
    "    question = sample['hypothesis']\n",
    "\n",
    "    xnli_new.append({\n",
    "        'id': f\"xnli_new_{idx}\",\n",
    "        'source': instruction + question,\n",
    "        'target': answer          \n",
    "    })\n",
    "\n",
    "random.shuffle(xnli_new)\n",
    "with open(\"./Processed_data/xnli_new.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in xnli_new:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Belebele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split: 100%|██████████| 900/900 [00:00<00:00, 117308.60 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds_dev = load_dataset(\"facebook/belebele\", \"hin_Deva\")\n",
    "ds_latin = load_dataset(\"facebook/belebele\", \"hin_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'link': 'https://en.wikibooks.org/wiki/Blended_Learning_in_K-12/Synchronous_and_asynchronous_communication_methods',\n",
       " 'question_number': 1,\n",
       " 'flores_passage': 'Atulyakalik sanchaar pratibimb aur dusron ki pratikriya ke liye samay ko badhaava deta hai. Yah students ko apni gati se kam karne aur prashikshan sambandhi jaankari ki gati ko niyantrit karne ki anumati deta hai. Iske alawa, samay ki pabandi kam hai aur apni pasand ke anusaar kam karne ke ghanton mein badlav kiya jaa sakta hai. (Bremer, 1998) Internet aur world wide web ke upyog se shiksharthiyon ko har waqt jaankari praapt karne ki suvidha milti hai. Chhaatr din mein kabhi bhi shikshak ko sawal bhej sakte hain aur agli baar aamne-saamne hone waali meeting hone tak intazaar karne ke bajaay kabhi bhi apne sawal ka turant jawab pa sakte hain.',\n",
       " 'question': 'Inme se kaun sa chhaatron ke liye atulyakaalik sanchaar ka laabh nhi hai? ',\n",
       " 'mc_answer1': 'Ek sansaadhan ke roop mein internet ka upayog',\n",
       " 'mc_answer2': 'Kisi bhi samay shikshakon se milne ki suvidha',\n",
       " 'mc_answer3': 'Apne hisab se kaam krne ki suvidha',\n",
       " 'mc_answer4': 'Bhagam-bhaag se bachaav',\n",
       " 'correct_answer_num': '2',\n",
       " 'dialect': 'hin_Latn',\n",
       " 'ds': datetime.datetime(2023, 7, 21, 0, 0)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_latin['test'][23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "belebele = []\n",
    "\n",
    "eng_instruction = \"Instruction: Given a query, retrieve the most similar passage. Query: \"\n",
    "hindi_instruction = \"निर्देश: एक प्रश्न दिया गया है, सबसे समान अनुच्छेद को पुनः प्राप्त करें। प्रश्न: \"\n",
    "count = 0\n",
    "\n",
    "for idx, sample in enumerate(ds_latin['test']):\n",
    "\n",
    "    passage = sample['flores_passage']\n",
    "    question = sample['question']\n",
    "\n",
    "    belebele.append({\n",
    "        'id': f\"belebele_{idx}\",\n",
    "        'source': eng_instruction + question,\n",
    "        'target': passage          \n",
    "    })\n",
    "\n",
    "max_idx = idx\n",
    "\n",
    "for idx, sample in enumerate(ds_dev['test']):\n",
    "\n",
    "    passage = sample['flores_passage']\n",
    "    question = sample['question']\n",
    "\n",
    "    belebele.append({\n",
    "        'id': f\"belebele_{max_idx + idx+1}\",\n",
    "        'source': hindi_instruction + question,\n",
    "        'target': passage          \n",
    "    })\n",
    "\n",
    "random.shuffle(belebele)\n",
    "with open(\"./Processed_data/belebele.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in belebele:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: IN22-Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['kan_Knda', 'brx_Deva', 'hin_Deva', 'urd_Arab', 'tam_Taml', 'mni_Mtei', 'tel_Telu', 'ory_Orya', 'eng_Latn', 'kas_Arab', 'pan_Guru', 'snd_Deva', 'asm_Beng', 'gom_Deva', 'npi_Deva', 'mal_Mlym', 'doi_Deva', 'sat_Olck', 'mai_Deva', 'ben_Beng', 'san_Deva', 'mar_Deva', 'guj_Gujr'],\n",
       "        num_rows: 1503\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mteb.tasks import IN22ConvBitextMining\n",
    "\n",
    "task = IN22ConvBitextMining()\n",
    "task.load_data()\n",
    "task.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"ai4bharat/IN22-Conv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "convbtm = []\n",
    "\n",
    "hindi_instruction = \"निर्देश: दिए गए पाठ का सबसे समान अनुवाद खोजें। पाठ: \"\n",
    "\n",
    "for idx, sample in enumerate(ds['test']):\n",
    "\n",
    "    for taregt_lang in ['asm_Beng', 'ben_Beng', 'brx_Deva', 'doi_Deva', 'eng_Latn', 'gom_Deva', 'guj_Gujr', 'kan_Knda', 'kas_Arab', 'mai_Deva', 'mal_Mlym', 'mar_Deva', 'mni_Mtei', 'npi_Deva', 'ory_Orya', 'pan_Guru', 'san_Deva', 'sat_Olck', 'snd_Deva', 'tam_Taml', 'tel_Telu', 'urd_Arab']:\n",
    "\n",
    "        text = sample['hin_Deva']\n",
    "        target = sample[taregt_lang]\n",
    "\n",
    "        convbtm.append({\n",
    "            'id': f\"convbtm_{idx}\",\n",
    "            'source': hindi_instruction + text,\n",
    "            'target': target          \n",
    "        })\n",
    "\n",
    "random.shuffle(convbtm)\n",
    "with open(\"./Processed_data/convbtm.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in convbtm:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: LinceMTBitextMining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 8059/8059 [00:00<00:00, 1405250.52 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"mteb/LinceMTBitextMining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Have you seen this movie?',\n",
       " 'sentence2': 'Kya tumne yeh movie dekhi hai?'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "lince = []\n",
    "\n",
    "instruction = \"Instruction: Find the most similar romanised Hindi sentence of the give english sentence. Sentence: \"\n",
    "\n",
    "for idx, sample in enumerate(ds['test']):\n",
    "\n",
    "\n",
    "    sent1 = sample['hin_Deva']\n",
    "    sent2 = sample[taregt_lang]\n",
    "\n",
    "    lince.append({\n",
    "        'id': f\"lince_{idx}\",\n",
    "        'source': instruction + sent1,\n",
    "        'target': sent2          \n",
    "    })\n",
    "\n",
    "random.shuffle(lince)\n",
    "with open(\"./Processed_data/lince.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in lince:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: WikiReranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"ellamind/wikipedia-2023-11-reranking-multilingual\", \"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'डी.ए.पी. और जिंक सल्फेट को मिलाने पर क्या होता है?',\n",
       " 'positive': ['डी.ए.पी. के घोल में जिंक सल्फेट के घोल को मिलाने पर थक्केदार घना अवक्षेप बन जाता है। मैग्नीशियम सल्फेट के साथ ऐसा नहीं होता।'],\n",
       " 'negative': ['उर्वरक, पौधों के लिये आवश्यक तत्वों की तत्काल पूर्ति के साधन हैं लेकिन इनके प्रयोग के कुछ दुष्परिणाम भी हैं। ये लंबे समय तक मिट्टी में बने नहीं रहते हैं। सिंचाई के बाद जल के साथ ये रसायन जमीन के नीचे भौम जलस्तर तक पहुँचकर उसे दूषित करते हैं। मिट्टी में उपस्थित जीवाणुओं और सुक्ष्मजीवों के लिए भी ये घातक साबित होते हैं। भारत में रासायनिक खाद का सर्वाधिक प्रयोग पंजाब में होता है। वर्तमान समय में वहाँ पानी का जलस्तर एवं मृदा की पोषकता में भारी कमी देखी गई है। इसके साथ ही मृदा तथा उपज में हानीकारक रसायनों की मात्रा में बहुत वृद्दी पाई गई है। इसलिए उर्वरक के विकल्प के रूप में जैविक खाद का प्रयोग तेजी से लोकप्रीय हो रहा है।',\n",
       "  'डी.ए.पी. के कुछ दानों को लेकर तम्बाकू की तरह उसमें चूना मिलाकर मलने पर तीक्ष्ण गन्ध निकलती है, जिसे सूंघना असह्य हो जाता है।',\n",
       "  'यह सख्त दानेदार, भूरा काला बादामी रंगों से युक्त तथा नाखूनों से आसानी से न टूटने वाला उर्वरक है। यह चूर्ण के रूप में भी उपलब्ध होता है। इस दानेदार उर्वरक की मिलावट बहुधा डी.ए.पी. व एन.पी.के. मिक्चर उर्वरकों के साथ की जाने की सम्भावना बनी रहती है।',\n",
       "  'जिंक सल्फेट में मैंग्नीशिम सल्फेट प्रमुख मिलावटी रसायन है। भौतिक रूप से समानता के कारण नकली असली की पहचान कठिन होती है।',\n",
       "  'जिंक सल्फेट के घोल में पतला कास्टिक का घोल मिलाने पर सफेद, मटमैला मांड़ जैसा अवक्षेप बनता है, जिसमें गाढ़ा कास्टिक का घोल मिलाने पर अवक्षेप पूर्णतया घुल जाता है। यदि जिंक सल्फेट की जगह पर मैंग्नीशिम सल्फेट है तो अवक्षेप नहीं घुलेगा।',\n",
       "  '(१) तौलिए या थाला में डालना : तौलिए में छोटे पौधों में आधा व बड़े पौधों में एक फुट की तने से दूरी रखते हुए खादें डाल दी जाती है। खादें पौधों की टहनियों के फैलाव के नीचे बिखेर कर डालने के बाद मिट्टी में मिला दी जातीहै। मिट्टी में खादें मिलाना अति आवश्यक होता है। जब बहुत ज्यादा नमी हो या बहुत ज्यादा सूखा पड़ रहा हो तो खादें न डालें।',\n",
       "  '(२) पट्टी में खाद डालना : टहनियों के फैलाव के बाहरी घेरे में 20-25 सेंटीमीटर पट्टी में खादें डाल दी जाती है और ऊपर से ढक दिया जाता है। ऐसे विधि वहीं प्रयोग में लाई जाती है जहां ज्यादा बरसात होती है।',\n",
       "  '(३) छिड़काव विधि : पत्तों के ऊपर छिड़काव किया जाता है। ज्यादात्तर यूरियाखाद को पानी में घोल कर उसे छिड़काव द्वारा पत्तों पर डाला जाता है। 1 किलो यूरिया को ५० लीटर पानी में घोलकर छिडकाव करें पानी कम होने पर पत्तियों के झुलसने की संभावना रहती है']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test'][23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "wikireranking = []\n",
    "\n",
    "hindi_instruction = \"निर्देश: दिए गए प्रश्न के लिए सबसे अधिक समानता रखने वाले दस्तावेज़ को पहचानें और पुनः प्राप्त करें। प्रश्न:\"\n",
    "\n",
    "for idx, sample in enumerate(ds['test']):\n",
    "\n",
    "    query = sample['query']\n",
    "    positive = sample['positive'][0]\n",
    "\n",
    "    wikireranking.append({\n",
    "        'id': f\"wikireranking_{idx}\",\n",
    "        'source': hindi_instruction + query,\n",
    "        'target': positive          \n",
    "    })\n",
    "\n",
    "random.shuffle(wikireranking)\n",
    "with open(\"./Processed_data/wikireranking.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in wikireranking:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: IndicCrosslingualSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 656/656 [00:00<00:00, 29377.77 examples/s]\n",
      "Stringifying the column: 100%|██████████| 656/656 [00:00<00:00, 244748.57 examples/s]\n",
      "Casting to class labels: 100%|██████████| 656/656 [00:00<00:00, 287599.40 examples/s]\n",
      "Map: 100%|██████████| 957/957 [00:00<00:00, 34464.26 examples/s]\n",
      "Stringifying the column: 100%|██████████| 957/957 [00:00<00:00, 436393.66 examples/s]\n",
      "Casting to class labels: 100%|██████████| 957/957 [00:00<00:00, 400194.31 examples/s]\n",
      "Map: 100%|██████████| 780/780 [00:00<00:00, 34356.43 examples/s]\n",
      "Stringifying the column: 100%|██████████| 780/780 [00:00<00:00, 376387.15 examples/s]\n",
      "Casting to class labels: 100%|██████████| 780/780 [00:00<00:00, 347779.01 examples/s]\n",
      "Map: 100%|██████████| 1268/1268 [00:00<00:00, 35120.33 examples/s]\n",
      "Stringifying the column: 100%|██████████| 1268/1268 [00:00<00:00, 463031.30 examples/s]\n",
      "Casting to class labels: 100%|██████████| 1268/1268 [00:00<00:00, 420059.83 examples/s]\n",
      "Map: 100%|██████████| 953/953 [00:00<00:00, 32205.39 examples/s]\n",
      "Stringifying the column: 100%|██████████| 953/953 [00:00<00:00, 444871.64 examples/s]\n",
      "Casting to class labels: 100%|██████████| 953/953 [00:00<00:00, 327449.14 examples/s]\n",
      "Map: 100%|██████████| 947/947 [00:00<00:00, 34652.78 examples/s]\n",
      "Stringifying the column: 100%|██████████| 947/947 [00:00<00:00, 442464.73 examples/s]\n",
      "Casting to class labels: 100%|██████████| 947/947 [00:00<00:00, 392645.90 examples/s]\n",
      "Map: 100%|██████████| 779/779 [00:00<00:00, 3584.93 examples/s]\n",
      "Stringifying the column: 100%|██████████| 779/779 [00:00<00:00, 352352.29 examples/s]\n",
      "Casting to class labels: 100%|██████████| 779/779 [00:00<00:00, 326246.91 examples/s]\n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 32436.04 examples/s]\n",
      "Stringifying the column: 100%|██████████| 500/500 [00:00<00:00, 248625.01 examples/s]\n",
      "Casting to class labels: 100%|██████████| 500/500 [00:00<00:00, 240031.13 examples/s]\n",
      "Map: 100%|██████████| 688/688 [00:00<00:00, 29464.37 examples/s]\n",
      "Stringifying the column: 100%|██████████| 688/688 [00:00<00:00, 339013.29 examples/s]\n",
      "Casting to class labels: 100%|██████████| 688/688 [00:00<00:00, 323506.86 examples/s]\n",
      "Map: 100%|██████████| 1044/1044 [00:00<00:00, 34295.26 examples/s]\n",
      "Stringifying the column: 100%|██████████| 1044/1044 [00:00<00:00, 407904.37 examples/s]\n",
      "Casting to class labels: 100%|██████████| 1044/1044 [00:00<00:00, 370148.21 examples/s]\n",
      "Map: 100%|██████████| 948/948 [00:00<00:00, 34240.10 examples/s]\n",
      "Stringifying the column: 100%|██████████| 948/948 [00:00<00:00, 442981.30 examples/s]\n",
      "Casting to class labels: 100%|██████████| 948/948 [00:00<00:00, 394229.64 examples/s]\n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 32642.02 examples/s]\n",
      "Stringifying the column: 100%|██████████| 500/500 [00:00<00:00, 251789.17 examples/s]\n",
      "Casting to class labels: 100%|██████████| 500/500 [00:00<00:00, 252304.14 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'en-ta': DatasetDict({\n",
       "     test: Dataset({\n",
       "         features: ['lang_code', 'source', 'sentence1', 'sentence2', 'score', 'label'],\n",
       "         num_rows: 256\n",
       "     })\n",
       " }),\n",
       " 'en-kn': DatasetDict({\n",
       "     test: Dataset({\n",
       "         features: ['lang_code', 'source', 'sentence1', 'sentence2', 'score', 'label'],\n",
       "         num_rows: 256\n",
       "     })\n",
       " }),\n",
       " 'en-pa': DatasetDict({\n",
       "     test: Dataset({\n",
       "         features: ['lang_code', 'source', 'sentence1', 'sentence2', 'score', 'label'],\n",
       "         num_rows: 256\n",
       "     })\n",
       " }),\n",
       " 'en-or': DatasetDict({\n",
       "     test: Dataset({\n",
       "         features: ['lang_code', 'source', 'sentence1', 'sentence2', 'score', 'label'],\n",
       "         num_rows: 256\n",
       "     })\n",
       " }),\n",
       " 'en-as': DatasetDict({\n",
       "     test: Dataset({\n",
       "         features: ['lang_code', 'source', 'sentence1', 'sentence2', 'score', 'label'],\n",
       "         num_rows: 256\n",
       "     })\n",
       " }),\n",
       " 'en-te': DatasetDict({\n",
       "     test: Dataset({\n",
       "         features: ['lang_code', 'source', 'sentence1', 'sentence2', 'score', 'label'],\n",
       "         num_rows: 256\n",
       "     })\n",
       " }),\n",
       " 'en-gu': DatasetDict({\n",
       "     test: Dataset({\n",
       "         features: ['lang_code', 'source', 'sentence1', 'sentence2', 'score', 'label'],\n",
       "         num_rows: 256\n",
       "     })\n",
       " }),\n",
       " 'en-ur': DatasetDict({\n",
       "     test: Dataset({\n",
       "         features: ['lang_code', 'source', 'sentence1', 'sentence2', 'score', 'label'],\n",
       "         num_rows: 256\n",
       "     })\n",
       " }),\n",
       " 'en-hi': DatasetDict({\n",
       "     test: Dataset({\n",
       "         features: ['lang_code', 'source', 'sentence1', 'sentence2', 'score', 'label'],\n",
       "         num_rows: 256\n",
       "     })\n",
       " }),\n",
       " 'en-ml': DatasetDict({\n",
       "     test: Dataset({\n",
       "         features: ['lang_code', 'source', 'sentence1', 'sentence2', 'score', 'label'],\n",
       "         num_rows: 256\n",
       "     })\n",
       " }),\n",
       " 'en-bn': DatasetDict({\n",
       "     test: Dataset({\n",
       "         features: ['lang_code', 'source', 'sentence1', 'sentence2', 'score', 'label'],\n",
       "         num_rows: 256\n",
       "     })\n",
       " }),\n",
       " 'en-mr': DatasetDict({\n",
       "     test: Dataset({\n",
       "         features: ['lang_code', 'source', 'sentence1', 'sentence2', 'score', 'label'],\n",
       "         num_rows: 256\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mteb.tasks import IndicCrosslingualSTS\n",
    "\n",
    "task = IndicCrosslingualSTS()\n",
    "task.load_data()\n",
    "task.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens per languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158845879\n",
      "306227746\n",
      "2399439\n"
     ]
    }
   ],
   "source": [
    "Hindi = 0\n",
    "English = 0\n",
    "Romanised_Hindi = 0\n",
    "\n",
    "for key in token_per_language.keys():\n",
    "\n",
    "    Hindi+=token_per_language[key]['Hindi']\n",
    "    English+=token_per_language[key]['English']\n",
    "    Romanised_Hindi+=token_per_language[key]['Romanised_Hindi']\n",
    "\n",
    "print(Hindi)\n",
    "print(English)\n",
    "print(Romanised_Hindi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Length Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "files = glob.glob(\"./Processed_data/*\")\n",
    "\n",
    "data = []\n",
    "token_len = []\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "\n",
    "        for sample in f:\n",
    "            sample = json.loads(sample)\n",
    "            data.append(sample)\n",
    "\n",
    "            source_tok = len(tokenizer(sample['source']).input_ids)\n",
    "            target_tok = len(tokenizer(sample['target']).input_ids)\n",
    "\n",
    "            token_len.append(source_tok)\n",
    "            token_len.append(target_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "token_len = np.array(token_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(66759)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_len.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(188.22772704193713)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_len.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(64.0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(token_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_len = sorted(token_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(token_len, bins=50, color='blue', alpha=0.7, edgecolor='black')\n",
    "plt.xlabel(\"Token Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Token Length Distribution\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import glob, json, os\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "files = glob.glob(\"./Processed_data/*\")\n",
    "\n",
    "def get_jsonl(file):\n",
    "    data = []\n",
    "    with open(file, 'r') as f:\n",
    "        for sample in f:\n",
    "            data.append(json.loads(sample))\n",
    "    return data\n",
    "\n",
    "def save_jsonl(data, path):\n",
    "    with open(path, 'w') as f:\n",
    "        for sample in data:\n",
    "            json.dump(sample, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    if \"_test\" in file:\n",
    "        continue\n",
    "\n",
    "    if file not in [\"./Processed_data/crosssum_english_hindi.jsonl\", \"./Processed_data/crosssum_hindi_english.jsonl\",\n",
    "                    \"./Processed_data/crosssum_hindi_hindi.jsonl\", \"./Processed_data/crosssum_english_english.jsonl\",\n",
    "                    \"./Processed_data/flores.jsonl\", \"./Processed_data/mintaka.jsonl\",\n",
    "                    \"./Processed_data/mldr.jsonl\", \"./Processed_data/mlqa.jsonl\",\n",
    "                    \"./Processed_data/amazon_review.jsonl\", \"./Processed_data/squad.jsonl\",\n",
    "                    \"./Processed_data/stackoverflow.jsonl\"]:\n",
    "        \n",
    "        data = get_jsonl(file)\n",
    "        random.shuffle(data)\n",
    "        train, val = train_test_split(data, test_size=0.2)\n",
    "\n",
    "        path = f\"./training_data/{file.split('/')[-1].split('.')[0]}/\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        save_jsonl(train, f\"{path}train.jsonl\")\n",
    "        save_jsonl(val, f\"{path}val.jsonl\")\n",
    "    else:\n",
    "        data = get_jsonl(file)\n",
    "        path = f\"./training_data/{file.split('/')[-1].split('.')[0]}/\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        save_jsonl(data, f\"{path}train.jsonl\")\n",
    "\n",
    "        test_path = f\".{file.split('.')[1]}_test.{file.split('.')[2]}\"\n",
    "        data = get_jsonl(test_path)\n",
    "        save_jsonl(data, f\"{path}val.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./training_data/mldr/train.jsonl\n",
      "./training_data/amazon_review/train.jsonl\n",
      "./training_data/indicqa/train.jsonl\n",
      "./training_data/sentiment_joshi/train.jsonl\n",
      "./training_data/eli5/train.jsonl\n",
      "./training_data/wikireranking/train.jsonl\n",
      "./training_data/convbtm/train.jsonl\n",
      "./training_data/laser/train.jsonl\n",
      "./training_data/mlqa/train.jsonl\n",
      "./training_data/sentiment_shete/train.jsonl\n",
      "./training_data/hinge/train.jsonl\n",
      "./training_data/code_mixed/train.jsonl\n",
      "./training_data/crosssum_english_english/train.jsonl\n",
      "./training_data/massive/train.jsonl\n",
      "./training_data/abp_news_classification/train.jsonl\n",
      "./training_data/xnli_new/train.jsonl\n",
      "./training_data/lince/train.jsonl\n",
      "./training_data/squad/train.jsonl\n",
      "./training_data/sentiment/train.jsonl\n",
      "./training_data/mtop_intent/train.jsonl\n",
      "./training_data/phinc/train.jsonl\n",
      "./training_data/stackoverflow/train.jsonl\n",
      "./training_data/crosssum_hindi_hindi/train.jsonl\n",
      "./training_data/sentiment_review/train.jsonl\n",
      "./training_data/discourse/train.jsonl\n",
      "./training_data/flores/train.jsonl\n",
      "./training_data/crosssum_english_hindi/train.jsonl\n",
      "./training_data/crosssum_hindi_english/train.jsonl\n",
      "./training_data/belebele/train.jsonl\n",
      "./training_data/mintaka/train.jsonl\n",
      "./training_data/abp_news/train.jsonl\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "train_files = glob.glob(\"./training_data/*/train.jsonl\", recursive=True)\n",
    "val_files = glob.glob(\"./training_data/*/val.jsonl\", recursive=True)\n",
    "\n",
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "exclude_files = ['sentiment_shete', 'sentiment_joshi', 'hinge', 'code_mixed', 'sentiment_review', 'abp_news', 'crosssum_english_english']\n",
    "exclude_files = ['xnli', 'Wikireranking', 'samanantar_language_classification']\n",
    "#exclude_files = ['samanantar_language_classification']\n",
    "\n",
    "english_data_files = ['amazon_review', 'crosssum_english_english', 'eli5', 'squad']\n",
    "#english_data_files = []\n",
    "\n",
    "def save_jsonl(data, path):\n",
    "\n",
    "    with open(path, 'w') as f:\n",
    "        for sample in data:\n",
    "            json.dump(sample, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "for file in train_files:\n",
    "\n",
    "    if file.split('/')[2] in exclude_files:\n",
    "        #print(file)\n",
    "        continue\n",
    "    print(file)\n",
    "\n",
    "    if file.split('/')[2] in english_data_files:\n",
    "        data = []\n",
    "        with open(file, 'r') as f:\n",
    "            for sample in f:\n",
    "                data.append(json.loads(sample))\n",
    "        length_of_data = len(data)\n",
    "        train_data = train_data + data[:length_of_data//2]\n",
    "\n",
    "    else:\n",
    "\n",
    "        with open(file, 'r') as f:\n",
    "            for sample in f:\n",
    "                train_data.append(json.loads(sample))\n",
    "\n",
    "for file in val_files:\n",
    "\n",
    "    if file.split('/')[2] in exclude_files:\n",
    "        continue\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        for sample in f:\n",
    "            val_data.append(json.loads(sample))\n",
    "\n",
    "\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(val_data)\n",
    "\n",
    "save_jsonl(train_data, \"./new_training_data/train_data.jsonl\")\n",
    "save_jsonl(val_data, \"./new_training_data/val_data.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "658097"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "659297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "807411"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "815419"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Hard Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m     data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[0;32m---> 43\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[1;32m     47\u001b[0m     data[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhard_negative\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m generate_query_for_article(sample)\n",
      "File \u001b[0;32m~/miniconda3/envs/AI/lib/python3.10/json/__init__.py:299\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(fp\u001b[38;5;241m.\u001b[39mread(),\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m--> 299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mloads\u001b[39m(s, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    300\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``s`` (a ``str``, ``bytes`` or ``bytearray`` instance\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03m    containing a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "\n",
    "def generate_query_for_article(sample):\n",
    "\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "        api_key=\"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\"\n",
    "    )\n",
    "    \n",
    "    system_message = \"\"\"\n",
    "        You are an AI assistant designed to generate challenging hard negative examples in the same language as the output. Your task is to produce exactly one concise and well-formed hard negative response that seems similar to the correct Output text, but is actually irrelevant for the given Input text. The hard negative should be misleading in a subtle way — close in topic or style, but not a valid answer. Make sure the grammar and vocabulary are correct. Wrap the hard negative inside ## markers like this: ## hard negative text ##*.**\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"nvidia/llama-3.3-nemotron-super-49b-v1\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": f\"Input Text: {sample['source']} \\nOutput Text: {sample['target']} \\nGenerate Hard Negative example: \"}\n",
    "            ],\n",
    "            temperature=0.6,\n",
    "            top_p=0.95,\n",
    "            max_tokens=100,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stream=False\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        time.sleep(5)\n",
    "        return generate_query_for_article(sample)\n",
    "    \n",
    "    return completion.choices[0].message.content.split(\"##\")[1]\n",
    "\n",
    "with open(\"./new_training_data/train_data.jsonl\", \"r\") as f:\n",
    "    data = []\n",
    "    for sample in f:\n",
    "        data.append(json.loads(sample))\n",
    "\n",
    "for idx, sample in enumerate(data):\n",
    "    \n",
    "    data[idx]['hard_negative'] = generate_query_for_article(sample)\n",
    "    data[idx]['hard_negative_flag'] = 1\n",
    "\n",
    "    if idx%5000==0:\n",
    "        print(f\"Processed {idx} samples\")\n",
    "        with open(\"./new_training_data/train_data_with_hard_negative.jsonl\", \"w\") as f:\n",
    "            for sample in data:\n",
    "                json.dump(sample, f, ensure_ascii=False)\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LingoIITGN/Ganga-2-1B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bitext_Mining = ['./training_data/crosssum_english_english/train.jsonl',\n",
    "                 './training_data/crosssum_hindi_hindi/train.jsonl',\n",
    "                 './training_data/crosssum_english_hindi/train.jsonl',\n",
    "                 './training_data/crosssum_hindi_english/train.jsonl',\n",
    "                 './training_data/flores/train.jsonl',\n",
    "                 './training_data/laser/train.jsonl',\n",
    "                 './training_data/mintaka/train.jsonl',\n",
    "                 './training_data/phinc/train.jsonl']\n",
    "\n",
    "Classification = ['./training_data/discourse/train.jsonl',\n",
    "                  './training_data/massive/train.jsonl',\n",
    "                  './training_data/sentiment_joshi/train.jsonl',\n",
    "                  './training_data/sentiment_shete/train.jsonl',\n",
    "                  './training_data/sentiment_review/train.jsonl',\n",
    "                  './training_data/sentiment/train.jsonl',\n",
    "                 './training_data/abp_news_classification/train.jsonl',\n",
    "                 './training_data/amazon_review/train.jsonl'\n",
    "                  ]\n",
    "\n",
    "Retrieval = ['./training_data/abp_news/train.jsonl',\n",
    "             './training_data/indicqa/train.jsonl',\n",
    "             './training_data/mldr/train.jsonl',\n",
    "             './training_data/mlqa/train.jsonl',\n",
    "             './training_data/squad/train.jsonl',\n",
    "             './training_data/stackoverflow/train.jsonl',\n",
    "             './training_data/eli5/train.jsonl'\n",
    "            ]\n",
    "\n",
    "Translation = ['./training_data/code_mixed/train.jsonl',\n",
    "               './training_data/hinge/train.jsonl',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_dict = {}\n",
    "\n",
    "for task in Bitext_Mining:\n",
    "    task_dict[task] = \"Bitext_Mining\"\n",
    "\n",
    "for task in Classification:\n",
    "    task_dict[task] = \"Classification\"\n",
    "\n",
    "for task in Retrieval:\n",
    "    task_dict[task] = \"Retrieval\"\n",
    "\n",
    "for task in Translation:\n",
    "    task_dict[task] = \"Translation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_task = {}\n",
    "for task_type, files in task_dict.items():\n",
    "    for fname in files:\n",
    "        file_to_task[fname] = task_type\n",
    "\n",
    "# Collect all .jsonl files\n",
    "files = glob.glob(\"./training_data/*/train.jsonl\", recursive=True)\n",
    "\n",
    "summary = {\n",
    "    \"overall_total_tokens\": 0,\n",
    "    \"overall_samples\": 0,\n",
    "    \"task_type_summary\": defaultdict(lambda: {\n",
    "        \"total_tokens\": 0,\n",
    "        \"total_samples\": 0,\n",
    "        \"max_token_length\": 0,\n",
    "        \"min_token_length\": float(\"inf\")\n",
    "    }),\n",
    "    \"file_summary\": {}\n",
    "}\n",
    "\n",
    "for file in files:\n",
    "    num_tokens = 0\n",
    "    num_sample = 0\n",
    "    max_length = 0\n",
    "    min_length = float(\"inf\")\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            sample = json.loads(line)\n",
    "            source = sample['source']\n",
    "            target = sample['target']\n",
    "            token_len = len(tokenizer.encode(source)) + len(tokenizer.encode(target))\n",
    "            \n",
    "            num_tokens += token_len\n",
    "            num_sample += 1\n",
    "            max_length = max(max_length, token_len)\n",
    "            min_length = min(min_length, token_len)\n",
    "        \n",
    "    #filename = os.path.basename(file)\n",
    "    task_type = task_dict.get(file, \"unknown\")\n",
    "\n",
    "    # Update task type summary\n",
    "    task_data = summary[\"task_type_summary\"][task_type]\n",
    "    task_data[\"total_tokens\"] += num_tokens\n",
    "    task_data[\"total_samples\"] += num_sample\n",
    "    task_data[\"max_token_length\"] = max(task_data[\"max_token_length\"], max_length)\n",
    "    task_data[\"min_token_length\"] = min(task_data[\"min_token_length\"], min_length)\n",
    "\n",
    "    summary['file_summary'][file] = {\n",
    "                        \"task_type\": task_type,\n",
    "                        \"total_samples\": num_sample,\n",
    "                        \"total_tokens\": num_tokens,\n",
    "                        \"max_token_length\": max_length,\n",
    "                        \"min_token_length\": min_length,\n",
    "    }\n",
    "\n",
    "    summary[\"overall_total_tokens\"] += num_tokens\n",
    "    summary[\"overall_samples\"] += num_sample\n",
    "\n",
    "# Convert defaultdict to dict for saving\n",
    "summary[\"task_type_summary\"] = dict(summary[\"task_type_summary\"])\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"training_data_stats.json\", \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing zero checkpoint 'checkpoints/ganga-2-1b-embeddings-full-mean-16/checkpoint-4489/global_step4489'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00, 3138.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected checkpoint of type zero stage ZeroStageEnum.weights, world_size: 6\n",
      "Parsing checkpoint created by deepspeed==0.16.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering sharded weights: 100%|██████████| 146/146 [00:00<00:00, 1239612.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed Trainable fp32 state dict with 146 params 939591680 elements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving checkpoint shards: 100%|██████████| 1/1 [00:03<00:00,  3.49s/it]\n"
     ]
    }
   ],
   "source": [
    "from deepspeed.utils.zero_to_fp32 import convert_zero_checkpoint_to_fp32_state_dict\n",
    "\n",
    "best_model_dir = \"checkpoints/ganga-2-1b-embeddings-new-equall-finetune-final-3-mean-32-epoch-1/checkpoint-2000\"\n",
    "output_dir = \"checkpoints/ganga-2-1b-embeddings-new-equall-finetune-final-3-mean-32-epoch-1/best_model\"\n",
    "convert_zero_checkpoint_to_fp32_state_dict(best_model_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ganga_modeling import EmbeddingModel\n",
    "from transformers import AutoModel\n",
    "\n",
    "output_dir = \"checkpoints/ganga-2-1b-embeddings-new-equall-finetune-final-mean-32-epoch-1/best_model\"\n",
    "state_dict = torch.load(f\"{output_dir}/pytorch_model.bin\")\n",
    "\n",
    "base_model = AutoModel.from_pretrained(\"LingoIITGN/Ganga-2-1B\")\n",
    "model2 = EmbeddingModel(base_model, 'mean')\n",
    "model2.load_state_dict(state_dict)\n",
    "model2.base_model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "paths = [\"./Processed_data/mtop_intent.jsonl\",\n",
    "         #\"./Processed_data/samanantar_language_classification.jsonl\",\n",
    "         \"./Processed_data/xnli_new.jsonl\"]\n",
    "\n",
    "finetuning_data = []\n",
    "\n",
    "for path in paths:\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        for sample in f:\n",
    "            finetuning_data.append(json.loads(sample))\n",
    "\n",
    "random.shuffle(finetuning_data)\n",
    "\n",
    "train, test = train_test_split(finetuning_data, test_size=0.1)\n",
    "\n",
    "os.makedirs(\"./new_training_data2\", exist_ok=True)\n",
    "\n",
    "with open(\"./new_training_data2/train_data.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in train:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')\n",
    "\n",
    "with open(\"./new_training_data2/val_data.jsonl\", \"w\") as f:\n",
    "\n",
    "    for sample in test:\n",
    "        json.dump(sample, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127998"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./new_training_data/train_data_with_hard_negative.jsonl\", \"r\") as f:\n",
    "    train_data = []\n",
    "    for sample in f:\n",
    "        train_data.append(json.loads(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "807411"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
